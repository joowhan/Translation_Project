{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "554ae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from eunjeon import Mecab\n",
    "from hanspell import spell_checker\n",
    "\n",
    "mec = Mecab()\n",
    "\n",
    "\n",
    "##높임말 리스트. 다음에 해당하면 높임말로 판단한다.\n",
    "H_LIST = ['니다', '니까', '요', '시오', '죠']\n",
    "\n",
    "##높임말로 변환할 때 중성끼리 합치는 경우가 있다. 그러한 경우 합치기 위한 사전이다. \n",
    "con_dict = [\n",
    "    \n",
    "    ['ㅏㅣ','ㅐ'], ['ㅑㅣ','ㅒ'], ['ㅓㅣ','ㅔ'],\n",
    "    ['ㅕㅣ','ㅖ'], ['ㅗㅣ','ㅚ'], ['ㅗㅐ','ㅙ'],\n",
    "    ['ㅜㅓ','ㅝ'], ['ㅜㅔ','ㅞ'], ['ㅡㅣ','ㅢ'],\n",
    "    ['ㅣㅏ','ㅑ'], ['ㅣㅓ','ㅕ'], ['ㅣㅗ','ㅛ'],\n",
    "    ['ㅣㅜ','ㅠ'], ['ㅡㅓ','ㅓ']\n",
    "    \n",
    "]\n",
    "\n",
    "####high -> low Dictionary####\n",
    "\n",
    "##EF(종결어미): 형태소 분류 시 종결어미가 단독으로 분석 되는 경우\n",
    "EF_ONLY = [\n",
    "    \n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['-special']], #ex)'습니다'-> '다'\n",
    "    [['ㄴ','ㅏ','ㅇ','ㅛ'],['ㄴ','ㅏ']],\n",
    "    [['ㄷ','ㅐ','ㅇ','ㅛ'],['ㄷ','ㅐ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄴ','ㅔ','ㅇ','ㅛ'],['ㄷ','ㅏ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅈ','ㅛ'],['ㅈ','ㅣ']],\n",
    "    [['ㅇ','ㅏ','ㅇ','ㅛ'],['ㅇ','ㅏ']],\n",
    "    [['ㅇ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㅇ','ㅡ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ','ㅇ','ㅛ'],['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ']],\n",
    "    #[['ㅎ','ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅎ','ㅇ','ㅏ']],\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅓ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅇ','ㅛ'],['']],\n",
    "    \n",
    "]\n",
    "\n",
    "#EP(선어말어미)+EF(종결어미)로 형태소가 분석될 경우\n",
    "EP_EF = [\n",
    "    \n",
    "    [['ㅅ','ㅔ','ㅇ','ㅛ'],['special']]\n",
    "    #-시오 family\n",
    "    ,[['ㅡ','ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㅓ']]\n",
    "    ,[['ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㄹ', 'ㅏ']],\n",
    "    [['ㅅ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅣ']],\n",
    "    [['ㅅ','ㅣ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ'],['ㄹ','ㄹ','ㅐ']],\n",
    "]\n",
    "\n",
    "#VCP+EF\n",
    "VCP_EF = [\n",
    "    \n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㅇ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅈ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅖ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄱ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ']],\n",
    "    \n",
    "]\n",
    "\n",
    "#XSA+EF\n",
    "XSA_EF = [\n",
    "    [['ㅎ','ㅏ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㅎ','ㅏ','ㄷ','ㅏ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "#XSV+EF\n",
    "XSV_EF = [\n",
    "    [['ㅎ','ㅏ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㅎ','ㅐ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅎ','ㅐ','ㅇ','ㅛ'],['ㅎ','ㅏ','ㅈ','ㅏ']],\n",
    "]\n",
    "\n",
    "#alpha+EF: 위의 경우를 제외한 나머지 경우를 의미한다. \n",
    "A_EF = [\n",
    "    [['ㄱ','ㅓ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㄱ','ㅖ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅆ','ㅇ','ㅓ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "##높임표현이 어말어미가 아닌 경우##\n",
    "# - 기존의 변환 방식이었다. 이제는 쓰지는 않지만, 코드의 오류가 발생할 가능성이 있기에 지우지 않았다. 따로 참고할 필요 없음.\n",
    "EF = [\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [[' ','ㅈ','ㅓ','ㄴ',' '],['ㄴ','ㅏ','_','ㄴ','ㅡ','ㄴ']],\n",
    "    [['ㅇ','ㅓ','_','ㅇ','ㅛ','_'],['ㄷ','ㅏ','_']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    #,[['ㅅ','ㅔ'],['ㅝ'],['ㅘ']]\n",
    "]\n",
    "\n",
    "NP = [\n",
    "    \n",
    "    [['ㅈ','ㅓ','ㄴ'],['special-']],\n",
    "    [['ㅈ','ㅓ'],['ㄴ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "# 보조사\n",
    "JX = [\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "VX = [\n",
    "    \n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']]\n",
    "    \n",
    "]\n",
    "\n",
    "VV = [\n",
    "    \n",
    "    [['ㅇ','ㅗ'],['ㅇ','ㅗ'],['ㅇ','ㅘ']],\n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']],\n",
    "    [['ㅎ','ㅏ'],['ㅎ','ㅏ'],['ㅎ','ㅐ']]\n",
    "    \n",
    "]\n",
    "\n",
    "XR = [\n",
    "    [['ㅈ','ㅚ','ㅅ','ㅗ','ㅇ'],['ㅁ','ㅣ','ㅇ','ㅏ','ㄴ'] ]\n",
    "]\n",
    "\n",
    "NNG = [\n",
    "    [['ㅈ','ㅏ','ㅇ','ㅛ'],['ㅈ','ㅏ']],\n",
    "    [['ㄱ','ㅏ','ㅁ','ㅅ','ㅏ'],['ㅈ','ㅏ']],\n",
    "]\n",
    "\n",
    "NNP =[\n",
    "    [[],[]]\n",
    "]\n",
    "\n",
    "EXC_deal_1 = [\n",
    "    \n",
    "    ['ㅅㅔㅇㅛ', ['ㅏ','ㅣ'],['ㅜ','ㅓ'],['ㅡ','ㅓ']],\n",
    "]\n",
    "\n",
    "EXC_deal_2 = [\n",
    "    \n",
    "    ['ㅈㅓㄴ','ㅈㅓㄴ','ㄴㅏㄴ'],\n",
    "]\n",
    "\n",
    "EXC_deal_3 = [\n",
    "    \n",
    "    ['ㅅㅡㅂㄴㅣㄷㅏ',['ㅆ','ㄷㅏ'],'ㄴㅡㄴㄷㅏ'],\n",
    "    \n",
    "]\n",
    "\n",
    "EXC_tags = [\n",
    "    \n",
    "    'EP',\n",
    "    'EF'\n",
    "    \n",
    "]\n",
    "\n",
    "UNKNOWN = [\n",
    "    [['ㄷ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅡ','ㄴ','ㄷ','ㅏ']],\n",
    "]\n",
    "\n",
    "####End of high -> low Dictionary####\n",
    "\n",
    "\n",
    "#### low -> high Dictionary####\n",
    "## 사전의 순서가 중요하다. 순서를 임의로 바꾸지 말 것\n",
    "## EF solo. EF 앞에 형태소가 결합형이 아닌 홀로 분석 될 경우 ex) /EP, /EF\n",
    "\n",
    "EF_ONLY_4S = [\n",
    "    # -다면서 /EF\n",
    "    [['ㄷ','ㅏ','ㅁ','ㅕ','ㄴ','ㅅ','ㅓ'],['ㄷ','ㅏ','ㅁ','ㅕ','ㄴ','ㅅ','ㅓ','ㅇ','ㅛ']],\n",
    "    # -고 /EF\n",
    "    [['ㄹ','ㅏ','ㄱ','ㅗ'],['ㄹ','ㅏ','ㄱ','ㅗ','ㅇ','ㅛ']], ##-라고-> 라고요\n",
    "    [['ㄷ','ㅓ','ㄹ','ㅏ','ㄱ','ㅗ'],['ㄷ','ㅓ','ㄹ','ㅏ','ㄱ','ㅗ','ㅇ','ㅛ']],\n",
    "    [['ㄷ','ㅏ','ㄱ','ㅗ'],['ㄷ','ㅏ','ㄱ','ㅗ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㄴ','ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㄷ','ㅏ'],['-special']],\n",
    "    [['ㅇ','ㅓ','ㄹ','ㅏ'],['ㅇ','ㅡ','ㅅ','ㅔ','ㅇ','ㅛ']], #add jh_1115\n",
    "    [['ㅇ','ㅓ'],['ㅇ','ㅓ','ㅇ','ㅛ']],\n",
    "    #'-라' /EF\n",
    "    [['ㄷ','ㅓ','ㄹ','ㅏ'],['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅇ','ㅏ','ㄹ','ㅏ'],['ㅇ','ㅏ','ㅇ','ㅛ']],\n",
    "    [['ㄹ','ㅏ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "    # -데 /EF\n",
    "    [['ㅇ','ㅡ','ㄴ','ㄷ','ㅔ'],['ㅇ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ'],['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    # -걸 /EF\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ'],['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ','ㅇ','ㅛ']],\n",
    "    \n",
    "    [['ㅈ','ㅏ','ㄶ','ㅇ','ㅏ'],['ㅈ','ㅏ','ㄶ','ㅇ','ㅏ','ㅇ','ㅛ']], ## -잖아 -> -잖아요\n",
    "    \n",
    "    #-오 /EF\n",
    "    [['ㅇ','ㅗ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    #-자 /EF\n",
    "    [['ㅈ','ㅏ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    #-래 /EF\n",
    "    [['ㅇ''ㅡ','ㄹ','ㄹ','ㅐ'],['ㅇ''ㅡ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ']],\n",
    "    [['ㄹ','ㅐ'],['ㄹ','ㅐ','ㅇ','ㅛ']],\n",
    "    #-니 /EF\n",
    "    [['ㄴ','ㅣ'],['ㄴ','ㅏ','ㅇ','ㅛ']],\n",
    "    \n",
    "    # -거든 /EF\n",
    "    [['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ'],['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ','ㅇ','ㅛ']],\n",
    "    \n",
    "    #-마 /EF\n",
    "    [['ㅁ','ㅏ'],['ㅁ','ㅏ','ㅇ','ㅛ']],\n",
    "    \n",
    "    #-아 /EF\n",
    "    [['ㅇ','ㅏ'],['ㅇ','ㅏ','ㅇ','ㅛ']],\n",
    "    #-지/EF\n",
    "    [['ㅈ','ㅣ'],['ㅈ','ㅛ']],\n",
    "    \n",
    "   \n",
    "    \n",
    "    #[['ㄴ','ㅡ','ㄴ','ㄱ','ㅏ'],['-special']],\n",
    "    \n",
    "    [['ㄴ','ㅡ','ㄴ','ㄱ','ㅏ'],['ㄴ','ㅏ','ㅇ','ㅛ']],\n",
    "    \n",
    "    [['ㅇ''ㅡ','ㄹ','ㄲ','ㅏ'],['ㅇ''ㅡ','ㄹ','ㄲ','ㅏ','ㅇ','ㅛ']],\n",
    "    \n",
    "    [['ㅏ'],['ㅏ','ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "    [['ㅔ'],['ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "## EF 결합형\n",
    "## EF 앞에 형태소가 결합형인 경우 앞의 형태소도 고려해서 처리해야 한다. ex) /EP, /EF\n",
    "EF_ONLY_4C = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅓ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅓ','ㄸ','ㅐ'],['ㅇ','ㅓ','ㄸ','ㅐ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "    # -걸 /EF\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ'],['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅣ'],['-special']],\n",
    "    # -니 /EF\n",
    "    [['ㄴ','ㅣ'],['ㅇ','ㅓ','ㅇ','ㅛ']],\n",
    "    # -거든 /EF\n",
    "    [['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ'],['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ','ㅇ','ㅛ']],\n",
    "    [['ㅈ','ㅣ'],['ㅈ','ㅛ']],\n",
    "    #[['ㄴ','ㅡ','ㄴ','ㄱ','ㅏ'],['-special']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄱ','ㅏ'],['ㄴ','ㅏ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "\n",
    "EP_EF_4 =[\n",
    "    [['ㄴ','ㅔ'],['ㄴ','ㅔ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "#/VCP+EF\n",
    "VCP_EF_4 = [\n",
    "    \n",
    "    [['ㄱ','ㅓ','ㄹ'],['ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅇ','ㅑ'],['ㅇ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄹ','ㅐ'],['ㄹ','ㅐ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅣ'],['ㅇ','ㅔ','ㅇ','ㅛ']], #add jh_1116\n",
    "    [['ㄷ','ㅔ'],['ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄷ','ㅏ'],['-special']]\n",
    "    \n",
    "]\n",
    "\n",
    "#/VA+EF added code_JH\n",
    "VA_EF_4 = [\n",
    "    [['ㅇ','ㅓ','ㄸ','ㅐ'],['ㅇ','ㅓ','ㄸ','ㅐ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅣ'],['-special']],\n",
    "    [['ㅕ'],['ㅕ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "## /VCP, /EF\n",
    "EF_AFTER_VCP_4 = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    #-오 /EF\n",
    "    [['ㅇ','ㅗ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅣ'],['ㅇ','ㅔ','ㅇ','ㅛ']], #add jh_1116\n",
    "    \n",
    "]\n",
    "\n",
    "EF_AFTER_XSA_4 = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    \n",
    "]\n",
    "\n",
    "VV_EF_4 = [\n",
    "    [['ㄱ','ㅓ','ㄹ'],['ㄱ','ㅓ','ㄹ','ㅇ','ㅛ']],\n",
    "    [['ㅎ','ㅐ','ㄹ','ㅏ'],['ㅎ','ㅏ','ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅂ','ㅘ','ㄹ','ㅏ'],['ㅂ','ㅗ','ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅂ','ㅘ'],['ㅂ','ㅘ','ㅇ','ㅛ']],\n",
    "    [['ㅎ','ㅏ','ㄹ','ㄹ','ㅐ'],['ㅎ','ㅏ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ']],\n",
    "    [['ㅈ','ㅜ','ㄹ','ㄹ','ㅐ'],['ㅈ','ㅜ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ']], #add jh_1115\n",
    "    [['ㄷ','ㅙ'],['ㄷ','ㅙ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅣ'],['-special']],\n",
    "    [['ㄷ','ㅡ','ㄹ','ㄹ','ㅕ'],['ㄷ','ㅡ','ㄹ','ㄹ','ㅕ','ㅇ','ㅛ']],\n",
    "    [['ㄷ','ㅏ','ㅁ','ㅕ','ㄴ','ㅅ','ㅓ'],['ㄷ','ㅏ','ㅁ','ㅕ','ㄴ','ㅅ','ㅓ','ㅇ','ㅛ']],\n",
    "    [['ㄹ','ㅐ'],['ㄹ','ㅐ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅕ'],['ㅕ','ㅇ','ㅛ']],\n",
    "    [['ㅊ','ㅝ'],['ㅊ','ㅝ','ㅇ','ㅛ']],\n",
    "    [['ㅔ'],['ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅏ'],['ㅏ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "\n",
    "##added code_JH\n",
    "XSV_EF_4 = [\n",
    "    [['ㄷ','ㅏ'],['special']],\n",
    "    [['ㄹ','ㄲ','ㅏ'],['ㄹ','ㄲ','ㅏ','ㅇ','ㅛ']],\n",
    "    [['ㅏ','ㄴ','ㄷ','ㅏ'],['ㅏ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㄹㅏ'],['special']],\n",
    "    [['ㅎ','ㅐ'],['ㅎ','ㅐ','ㅇ','ㅛ']],\n",
    "]\n",
    "XSA_EF_4 = [\n",
    "    [['ㄷ','ㅏ'],['special']],\n",
    "    [['ㅎ','ㅏ','ㄴ','ㄷ','ㅔ'],['ㅎ','ㅏ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅎ','ㅐ'],['ㅎ','ㅐ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "VX_EF_4 = [\n",
    "    [['ㄷ','ㅏ'],['special']],\n",
    "    [['ㅎ','ㅐ'],['ㅎ','ㅐ','ㅇ','ㅛ']],\n",
    "    [['ㄹ','ㅏ'],['ㅇ','ㅛ']],\n",
    "    [['ㅂ','ㅘ','ㄹ','ㅏ'],['ㅂ','ㅗ','ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅂ','ㅘ'],['ㅂ','ㅘ','ㅇ','ㅛ']],\n",
    "    [['ㅈ','ㅜ','ㄹ','ㄹ','ㅐ'],['ㅈ','ㅜ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ']], #add jh_1115\n",
    "    [['ㅁ','ㅏ'],['ㅁ','ㅏ','ㅇ','ㅛ']],\n",
    "    [['ㄹ','ㄱ','ㅔ'],['ㄹ','ㄱ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅝ'],['ㅝ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "NNB_JKO_4 = [\n",
    "    [['ㄱ','ㅓ','ㄹ'],['specialx']],\n",
    "]\n",
    "\n",
    "EC_4 = [\n",
    "    [['ㄷ','ㅔ'],['specialx']],\n",
    "    #[['ㄷ','ㅔ'],['ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄱ','ㅔ'],['specialx']],\n",
    "    #[['ㄱ','ㅔ'],['ㄱ','ㅔ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "VV_4 = [\n",
    "    \n",
    "    #[['ㄷ','ㅚ'],['ㄷ','ㅚ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "EXC_4_deal_1 = [\n",
    "    \n",
    "    ['ㄹㅏ',['ㅐ','ㅏㅅㅔㅇㅛ'],'ㅇㅛ'],\n",
    "    ['ㄷㅏ',['ㄴ','ㅂㄴㅣㄷㅏ'],'ㅅㅡㅂㄴㅣㄷㅏ'],\n",
    "]\n",
    "\n",
    "EXC_4_deal_2 = [\n",
    "    \n",
    "    ['ㄴㅣ',['ㅆ','ㅇㅓㅇㅛ'],'ㅇㅛ'],\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "EXC_4_deal_3 = [\n",
    "    \n",
    "    ['ㄴㅡㄴㄱㅏ',['ㅗ','ㅗ','ㅏㅇㅛ'],['ㅜ','ㅜ','ㅓㅇㅛ'],['ㅏ','ㅏ','ㅣㅇㅛ'],'ㅇㅓㅇㅛ'],\n",
    "    ['ㄷㅏ',['ㅆ','ㅆ','ㅅㅡㅂㄴㅣㄷㅏ'],['ㄴ','ㅂ','ㄴㅣㄷㅏ'],['ㄹ','ㅂ','ㄴㅣㄷㅏ'],'ㅂㄴㅣㄷㅏ']\n",
    "]\n",
    "\n",
    "EXC_4_deal_4 = [\n",
    "    \n",
    "    ['ㄱㅔ','ㄱㅔㅇㅛ','ㄱㅔ'],\n",
    "    ['ㄷㅔ','ㄷㅔㅇㅛ','ㄷㅔ'],\n",
    "    ['ㄱㅓㄹ','ㄱㅓㄹㅇㅛ','ㄱㅓㄹ']\n",
    "]\n",
    "\n",
    "#도록은 special\n",
    "\n",
    "#### End of low -> high Dictionary####\n",
    "\n",
    "#### Common Dictionary ####\n",
    "#Yes or No\n",
    "IC =[\n",
    "    [['ㄴ','ㅔ'],['ㅇ','ㅡ','ㅇ']],\n",
    "    [['ㅇ','ㅏ','ㄴ','ㅣ','ㅇ','ㅛ'],['ㅇ','ㅏ','ㄴ','ㅣ']],\n",
    "    [['ㄴ','ㅔ'],['ㄱ','ㅡ','ㄹ','ㅐ']],\n",
    "]\n",
    "\n",
    "\n",
    "#### End of Common Dictionary ####\n",
    "def unite(input, dict):\n",
    "    for i in dict:\n",
    "        input = re.sub(i[0],i[1],input)\n",
    "    return input\n",
    "    \n",
    "## 자모 단위로 문장을 나누고 합칠 때 쓰는 class ##\n",
    "class Jamodealer:\n",
    "    jamo = []\n",
    "    pp = ''\n",
    "    #각 단어들을 받아와서 자모단위로 나눈다.\n",
    "    def __init__(self,lis_word):\n",
    "    \n",
    "        self.jamo = []\n",
    "        for i in lis_word:\n",
    "            self.jamo.append(split_syllables(i))\n",
    "    \n",
    "    ##사전에서 변환된 자모단위로 분리된 문장을 합칠 때 쓰는 함수이다.     \n",
    "    def make_one(self):\n",
    "        #list 형태로 저장된 자모들의 집합을 하나의 string pp에 저장한다. \n",
    "        self.pp = ''\n",
    "        for i in self.jamo:\n",
    "             self.pp= self.pp+i\n",
    "        ##종성과 종성을 합쳐야 하는 경우가 있다면 합친다.        \n",
    "        self.pp = unite(self.pp, con_dict)\n",
    "        \n",
    "        #자모 단위의 string에서 자모 단위로 사전을 만들고 거기에 index를 부여한다.        \n",
    "        chars = list(set(self.pp))\n",
    "        char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "        ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "        #자모 단위로 분리되었던 문장을 다시 하나로 합친다.\n",
    "        jamo_numbers = [char_to_ix[x] for x in self.pp]\n",
    "        restored_jamo = ''.join([ix_to_char[x] for x in jamo_numbers])\n",
    "        #합쳐진 문장을 return 한다.\n",
    "        restored_text = join_jamos(restored_jamo)\n",
    "        return restored_text\n",
    "##End of Jamodealer class##\n",
    "\n",
    "def tojamo(korean_word):\n",
    "    r_lst = []\n",
    "    for w in list(korean_word.strip()):\n",
    "        ## 영어인 경우 구분해서 작성함. \n",
    "        if '가'<=w<='힣':\n",
    "            ## 588개 마다 초성이 바뀜. \n",
    "            ch1 = (ord(w) - ord('가'))//588\n",
    "            ## 중성은 총 28가지 종류\n",
    "            ch2 = ((ord(w) - ord('가')) - (588*ch1)) // 28\n",
    "            ch3 = (ord(w) - ord('가')) - (588*ch1) - 28*ch2\n",
    "            r_lst.append([CHOSUNG_LIST[ch1], JUNGSUNG_LIST[ch2], JONGSUNG_LIST[ch3]])\n",
    "        else:\n",
    "            r_lst.append([w])\n",
    "    return r_lst\n",
    "\n",
    "#Use in makestrdict\n",
    "#Convert list to String\n",
    "def li2str(input):\n",
    "    st = \"\"\n",
    "    for i in input:\n",
    "        st = st+i\n",
    "    return st\n",
    "\n",
    "##Used when make dictionaries\n",
    "def makestrdict(input):\n",
    "    result = []\n",
    "    for i in input:\n",
    "        bullet = []\n",
    "        for j in range(len(i)):\n",
    "            gre = li2str(i[j])\n",
    "            bullet.append(gre)\n",
    "        result.append(bullet)\n",
    "    return result\n",
    "\n",
    "### *추가한 사전에 대한 str 사전을 생성, mapping 시키는 부분* ###\n",
    "\n",
    "# * 기존의 방식은 다음과 같다. 어말어미는 어말어미 변환 방식 코드를 참고하면 된다.\n",
    "# - 앞으로  사전을 추가하고 싶으면 여기서 코드를 추가하고 수정하면 된다.\n",
    "# - dictionary를 만들고 해당 형태소에 해당하는 dictionary를 추가하면 된다.\n",
    "#   예를 들어, EP(선어말어미)에 대한 사전을 만들고 싶다면 EP_dict = makestrdict(EP)를 선언하고\n",
    "#   Dict_list에 'EP'를 추가하면 된다. 그 후 Mapping이 되도록 Dict_map에도 생성한 EP_dict를 추가하면 된다.\n",
    "\n",
    "#EP_dict = makestrdict(EP)\n",
    "EF_dict = makestrdict(EF)\n",
    "NP_dict = makestrdict(NP)\n",
    "JX_dict = makestrdict(JX)\n",
    "VX_dict = makestrdict(VX)\n",
    "VV_dict = makestrdict(VV)\n",
    "XR_dict = makestrdict(XR)\n",
    "NNG_dict = makestrdict(NNG)\n",
    "NNP_dict = makestrdict(NNP)\n",
    "UNKNOWN_dict = makestrdict(UNKNOWN)\n",
    "\n",
    "Dict_list=['NNP','NP','JX','VX','VV','XR','NNG', 'UNKNOWN']\n",
    "\n",
    "Dict_map = [NNP_dict,NP_dict,JX_dict,VX_dict, VV_dict, XR_dict, NNG_dict, UNKNOWN_dict]\n",
    "\n",
    "##현재의 어말어미 변환방식은 밑에 코드를 추가, 변경하면 된다. \n",
    "#high->low of string dictionary\n",
    "EF_ONLY_dict = makestrdict(EF_ONLY)\n",
    "EP_EF_dict = makestrdict(EP_EF)\n",
    "VCP_EF_dict = makestrdict(VCP_EF)\n",
    "A_EF_dict = makestrdict(A_EF)\n",
    "XSA_EF_dict = makestrdict(XSA_EF)\n",
    "XSV_EF_dict = makestrdict(XSV_EF)\n",
    "\n",
    "\n",
    "#low->high of string dictionary\n",
    "EF_ONLY_4S_dict = makestrdict(EF_ONLY_4S)\n",
    "EF_ONLY_4C_dict = makestrdict(EF_ONLY_4C)\n",
    "EP_EF_4_dict = makestrdict(EP_EF_4)\n",
    "EF_AFTER_VCP_4_dict = makestrdict(EF_AFTER_VCP_4)\n",
    "VCP_EF_4_dict = makestrdict(VCP_EF_4)\n",
    "EF_AFTER_XSA_4_dict = makestrdict(EF_AFTER_XSA_4) ## add code_JM\n",
    "VA_EF_4_dict = makestrdict(VA_EF_4)\n",
    "VV_EF_4_dict = makestrdict(VV_EF_4)\n",
    "VX_EF_4_dict = makestrdict(VX_EF_4)\n",
    "XSV_EF_4_dict = makestrdict(XSV_EF_4)\n",
    "NNB_JKO_4_dict = makestrdict(NNB_JKO_4)##add code_JH\n",
    "EC_4_dict = makestrdict(EC_4)\n",
    "VV_4_dict = makestrdict(VV_4)\n",
    "\n",
    "##Use in Changer\n",
    "def to2lists(input):\n",
    "    lis_word = []\n",
    "    lis_tag = []\n",
    "    #data = han.pos(input,ntags=22,flatten=True, join=False)\n",
    "    data = mec.pos(input)\n",
    "    for i in data:\n",
    "        lis_word.append(i[0])\n",
    "        lis_tag.append(i[1])\n",
    "    return lis_word, lis_tag\n",
    "\n",
    "#add in 2021.09.26\n",
    "\n",
    "#space의 index 찾는다.\n",
    "#rememberSpace와 convertSpace는 문장의 space를 찾아 변환하고 그 위치에 다시 space를 넣기 위한 함수이다.\n",
    "def rememberSpace(lis, input):\n",
    "    \n",
    "    rlis = []\n",
    "    \n",
    "    for i in range(len(lis)):\n",
    "        if lis[i]==input:\n",
    "            rlis.append(i)\n",
    "            \n",
    "    for i in range(len(rlis)):\n",
    "        rlis[i] = rlis[i]-i      \n",
    "    return rlis\n",
    "\n",
    "def convertSpace(lis_space,lis_lis):\n",
    "    \n",
    "    rlis = []\n",
    "    k=0\n",
    "    for i in range(len(lis_lis)):\n",
    "        \n",
    "        if k in lis_space:\n",
    "            rlis.append(i)\n",
    "            \n",
    "        k = k+len(lis_lis[i])\n",
    "        \n",
    "    #print(rlis)  \n",
    "    return rlis\n",
    "\n",
    "def union(lis, lis_lis):\n",
    "    \n",
    "    k = 0\n",
    "    for i in lis:\n",
    "        lis_lis.insert(i+k,' ')\n",
    "        k = k+1\n",
    "        \n",
    "##특정 형태소를 찾는다. 종결어미(EF)를 찾아서 높임말 반말 변환 시 사용된다.         \n",
    "def findTargetMorphology(input, word):\n",
    "    \n",
    "    i=0\n",
    "    lis = []\n",
    "    for j in range(len(input)):\n",
    "        if word in input[j]:\n",
    "            lis.append(j)\n",
    "            \n",
    "    return lis\n",
    "\n",
    "def del_over(input):\n",
    "    \n",
    "    res = set(input) #집합set으로 변환\n",
    "    result = list(res) #list로 변환\n",
    "    return result\n",
    "\n",
    "\n",
    "## Main Class ## \n",
    "class Changer(object):\n",
    "    \n",
    "    ## High -> Low ##    \n",
    "    def high_low(self, stc):\n",
    "        result = stc\n",
    "        \n",
    "        space_list = rememberSpace(stc,' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = convertSpace(space_list, lis_word)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        lis = []\n",
    "        key = -1\n",
    "        for i in H_LIST:\n",
    "            if i in lis_word[-2]:\n",
    "                key = 1\n",
    "        #if key>0:\n",
    "        if key>0 or key<0:     \n",
    "            for i in range(len(lis_tag)):\n",
    "                res = jam.jamo[i]\n",
    "                dic = []\n",
    "                if 'EF' in lis_tag[i]:\n",
    "                    if 'EF' == lis_tag[i]:\n",
    "                        dic = EF_ONLY_dict\n",
    "                    elif 'EP' in lis_tag[i]:\n",
    "                        dic = EP_EF_dict\n",
    "                    elif 'VCP' in lis_tag[i]:\n",
    "                        dic = VCP_EF_dict\n",
    "                    elif 'XSA' in lis_tag[i]:\n",
    "                        dic = XSA_EF_dict\n",
    "                    else:\n",
    "                        dic = A_EF_dict\n",
    "                        \n",
    "                #else Dict_list[k] in lis_tag[i]:\n",
    "                else:\n",
    "                    for k in range(len(Dict_list)):\n",
    "                        if Dict_list[k] in lis_tag[i]:\n",
    "                            dic = Dict_map[Dict_list.index(Dict_list[k])]\n",
    "                            break\n",
    "                        \n",
    "                flag = 0    \n",
    "                for j in range(len(dic)):\n",
    "                    if dic[j][0] in res:\n",
    "                        flag = 1\n",
    "                            \n",
    "                        if self.isExcept(dic[j])==1:\n",
    "                            for q in range(len(EXC_deal_1)):\n",
    "                                if dic[j][0]==EXC_deal_1[q][0]:\n",
    "                                    for r in range(1,len(EXC_deal_1[q])):\n",
    "                                        if jam.jamo[i-1][-1]==EXC_deal_1[q][r][0]:\n",
    "                                            res = re.sub(dic[j][0],EXC_deal_1[q][r][1],res)\n",
    "                                        \n",
    "                        elif self.isExcept(dic[j])==2:\n",
    "                            for q in range(len(EXC_deal_2)):\n",
    "                                if dic[j][0]==EXC_deal_2[q][0]:\n",
    "                                    if i+1 in space_location:\n",
    "                                        res = re.sub(dic[j][0], EXC_deal_2[q][2], res)\n",
    "                                    else:\n",
    "                                        res = re.sub(dic[j][0], EXC_deal_2[q][1], res)\n",
    "                                    \n",
    "                        elif self.isExcept(dic[j])==3:\n",
    "                            for q in range(len(EXC_deal_3)):\n",
    "                                if dic[j][0]==EXC_deal_3[q][0]:\n",
    "                                    if jam.jamo[i-1][-1]==EXC_deal_3[q][1][0]:\n",
    "                                        res = re.sub(dic[j][0],EXC_deal_3[q][1][1],res)\n",
    "                                    else:\n",
    "                                        res = re.sub(dic[j][0],EXC_deal_3[q][2],res)\n",
    "                                    \n",
    "                        else:\n",
    "                            res = re.sub(dic[j][0],dic[j][1],res)\n",
    "                            \n",
    "                        if flag==1:\n",
    "                            break\n",
    "                            \n",
    "                        #jam.jamo[i] = res\n",
    "                lis.append(res)\n",
    "            \n",
    "            \n",
    "            #print(jam.jamo[i])\n",
    "        \n",
    "        union(space_location, lis)\n",
    "        jam.jamo = []\n",
    "        for i in range(len(lis)):\n",
    "            jam.jamo.append(lis[i])\n",
    "            #print(lis[i])\n",
    "        \n",
    "        #union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "    \n",
    "    def low_high(self, stc):\n",
    "        result = stc\n",
    "        \n",
    "        space_list = rememberSpace(stc, ' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = convertSpace(space_list, lis_word)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        #print(jam.jamo)\n",
    "        lis = []\n",
    "        \n",
    "        ## 종결어미만을 변경\n",
    "        ind_trans_ef = findTargetMorphology(lis_tag, 'EF')\n",
    "        ind_trans_jko = findTargetMorphology(lis_tag, 'JKO')\n",
    "        ind_trans_ec = findTargetMorphology(lis_tag, 'EC')\n",
    "        ind_trans_vv = findTargetMorphology(lis_tag, 'VV')\n",
    "        \n",
    "        ind_union = ind_trans_ef + ind_trans_jko + ind_trans_ec + ind_trans_vv\n",
    "        ind_union = del_over(ind_union)\n",
    "        \n",
    "        for ind in ind_union:  #modified_2021.10.31\n",
    "            key = -1\n",
    "\n",
    "            for i in H_LIST:\n",
    "                if i not in lis_word[ind]:\n",
    "                    key = 1\n",
    "                else:\n",
    "                    key = -1\n",
    "                if key==-1:\n",
    "                    break\n",
    "            if key >0:\n",
    "                res = jam.jamo[ind]\n",
    "                dic = []\n",
    "                #EF\n",
    "                if 'EF' in lis_tag[ind]:\n",
    "\n",
    "                    if 'EF' == lis_tag[ind]:\n",
    "                        if '+' in lis_tag[ind-1]:\n",
    "                            dic = EF_ONLY_4C_dict\n",
    "                        elif lis_tag[ind-1]=='VCP':\n",
    "                            dic = EF_AFTER_VCP_4_dict\n",
    "                        elif lis_tag[ind-1]=='XSA':\n",
    "                            dic = EF_AFTER_XSA_4_dict\n",
    "                        else:\n",
    "                            dic = EF_ONLY_4S_dict\n",
    "\n",
    "                    elif 'EP' in lis_tag[ind]:\n",
    "                        dic = EP_EF_4_dict\n",
    "                    elif 'VCP' in lis_tag[ind]:\n",
    "                        dic = VCP_EF_4_dict\n",
    "                    elif 'VA' in lis_tag[ind]:\n",
    "                        dic = VA_EF_4_dict\n",
    "                    elif 'VV' in lis_tag[ind]:\n",
    "                        dic = VV_EF_4_dict\n",
    "                    elif 'VX' in lis_tag[ind]:\n",
    "                        dic = VX_EF_4_dict\n",
    "                    elif 'XSV' in lis_tag[ind]:\n",
    "                        dic = XSV_EF_4_dict\n",
    "                    else:\n",
    "                        dic = A_EF_dict\n",
    "                #JKO      \n",
    "                elif 'JKO' in lis_tag[ind]:\n",
    "                    dic = NNB_JKO_4_dict\n",
    "                    \n",
    "\n",
    "                elif 'EC' in lis_tag[ind]:\n",
    "                    dic = EC_4_dict\n",
    "            \n",
    "                ##added by JM\n",
    "                flag = 0        \n",
    "                for j in range(len(dic)):\n",
    "                    if dic[j][0] in res:\n",
    "                        flag = 1\n",
    "                        \n",
    "                        if self.isExcept(dic[j])==1:\n",
    "                            for q in range(len(EXC_4_deal_1)):\n",
    "                                if dic[j][0]==EXC_4_deal_1[q][0]:\n",
    "                                    flag_1=0\n",
    "                                    for r in range(1,len(EXC_4_deal_1[q])-1):\n",
    "                                        if flag_1==1:\n",
    "                                            break\n",
    "                                        if EXC_4_deal_1[q][r][0] in jam.jamo[ind]:\n",
    "                                            res = re.sub(EXC_4_deal_1[q][r][0]+dic[j][0],EXC_4_deal_1[q][r][1],res)\n",
    "                                            flag_1=1\n",
    "                                    if flag_1==0:\n",
    "                                        res = re.sub(dic[j][0],EXC_4_deal_1[q][-1],res)\n",
    "\n",
    "                        elif self.isExcept(dic[j])==2:\n",
    "                            for q in range(len(EXC_4_deal_2)):\n",
    "                                if dic[j][0]==EXC_4_deal_2[q][0]:\n",
    "                                    if ind+1 in space_location:\n",
    "                                        res = re.sub(dic[j][0], EXC_4_deal_2[q][2], res)\n",
    "                                    else:\n",
    "                                        res = re.sub(dic[j][0], EXC_4_deal_2[q][1], res)\n",
    "                                        \n",
    "                        elif self.isExcept(dic[j])==3:\n",
    "                            for q in range(len(EXC_4_deal_3)):\n",
    "                                if dic[j][0]==EXC_4_deal_3[q][0]:\n",
    "                                    flag_1 = 0\n",
    "                                    for r in range(1,len(EXC_4_deal_3[q])-1):\n",
    "                                        if flag_1==1:\n",
    "                                            break\n",
    "                                        if jam.jamo[ind-1][-1]==EXC_4_deal_3[q][r][0]:\n",
    "                                            flag_1=1\n",
    "                                            li_1 = list(jam.jamo[ind-1])\n",
    "                                            li_1[-1] = EXC_4_deal_3[q][r][1]\n",
    "                                            jam.jamo[ind-1] = ''.join(li_1)\n",
    "                                            res = re.sub(dic[j][0],EXC_4_deal_3[q][r][2],res)\n",
    "                                    if flag_1==0:\n",
    "                                            res = re.sub(dic[j][0],EXC_4_deal_3[q][-1],res)\n",
    "                                            \n",
    "                        elif self.isExcept(dic[j])==4:\n",
    "                            for q in range(len(EXC_4_deal_4)):\n",
    "                                if dic[j][0]==EXC_4_deal_4[q][0]:\n",
    "                                    if ind ==len(lis_tag)-1:\n",
    "                                        res = re.sub(dic[j][0],EXC_4_deal_4[q][1],res)\n",
    "                                    else:\n",
    "                                        res = re.sub(dic[j][0],EXC_4_deal_4[q][2],res)\n",
    "                    \n",
    "                        else:\n",
    "                            res = re.sub(dic[j][0],dic[j][1],res)\n",
    "\n",
    "                        \n",
    "                        if flag==1:\n",
    "                            break\n",
    "                        \n",
    "                jam.jamo[ind] = res\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "            \n",
    "          \n",
    "    def isExcept(self, input):\n",
    "        if input[1]=='special':\n",
    "            return 1\n",
    "        elif input[1]=='special-':\n",
    "            return 2\n",
    "        elif input[1]=='-special':\n",
    "            return 3\n",
    "        elif input[1]=='specialx':\n",
    "            return 4\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def indicator(self, ind, lis, tag, ex_word, exc_tags):\n",
    "        re = 1\n",
    "        for j in range(len(ex_word)):\n",
    "            if exc_tags[j] in tag[ind+1]:\n",
    "                for i in range(len(ex_word)):\n",
    "                    if ex_word[i][0] in lis[ind+1]:\n",
    "                       \n",
    "                        re = ex_word[i][1]\n",
    "                        break\n",
    "                        \n",
    "                        print(lis[ind-1])\n",
    "        return re\n",
    "        \n",
    "        \n",
    "#     def processText(self,stc):\n",
    "#         result = stc\n",
    "#         res = self.high_low(result)\n",
    "#         #spacing = Spacing()\n",
    "#         #res = spacing(res)\n",
    "#         return res\n",
    "#     ##change function name\n",
    "#     def processText_convertHigh(self,stc):\n",
    "#         result = stc\n",
    "#         res = self.low_high(result)\n",
    "#         return res\n",
    "    def processText(self,stc):\n",
    "        result = stc\n",
    "        \n",
    "        flag = 0\n",
    "        if result[-1]=='\\n':\n",
    "            result = result.replace('\\n','')\n",
    "        if result[-1] =='?' or result[-1] =='.' or result[-1] =='!' or result[-1] =='\\\"':\n",
    "            result = result\n",
    "        else:\n",
    "            result = result+'.'\n",
    "            flag = 1\n",
    "        \n",
    "        res = self.high_low(result)\n",
    "        \n",
    "        if flag ==1:\n",
    "            res = res[:-1]\n",
    "        \n",
    "        #spacing = Spacing()\n",
    "        #res = spacing(res)\n",
    "        return res\n",
    "    \n",
    "    def processText_convertHigh(self,stc):\n",
    "        result = stc\n",
    "        \n",
    "        flag = 0\n",
    "        if result[-1]=='\\n':\n",
    "            result = result.replace('\\n','')\n",
    "        if result[-1] =='?' or result[-1] =='.' or result[-1] =='!' or result[-1] =='\\\"':\n",
    "            result = result\n",
    "        else:\n",
    "            result = result+'.'\n",
    "            flag = 1\n",
    "        \n",
    "        res = self.low_high(result)\n",
    "        \n",
    "        if flag ==1:\n",
    "            res = res[:-1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58fa16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "큽니다. 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "#txt = '전 그것이 맞다고 생각합니다.'\n",
    "tx = '크다. 아니다.'\n",
    "ch = Changer()\n",
    "#tt = ch.processText(tx)\n",
    "ttt = ch.processText_convertHigh(tx)\n",
    "#print(tt)\n",
    "print(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73576f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

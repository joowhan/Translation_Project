{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519281d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from konlpy.tag import Hannanum, Mecab\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "from tqdm.auto import tqdm\n",
    "from kiwipiepy import Kiwi\n",
    "import re\n",
    "from pykospacing import Spacing\n",
    "#if you use window, import eungeon instand of konlpy\n",
    "#from eunjeon import Mecab\n",
    "\n",
    "#import sys\n",
    "#import io\n",
    "#sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding = 'utf-8')\n",
    "#sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding = 'utf-8')\n",
    "\n",
    "han = Hannanum()\n",
    "mec = Mecab()\n",
    "\n",
    "number = 100\n",
    "\n",
    "# 초성 리스트. 00 ~ 18\n",
    "CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "# 중성 리스트. 00 ~ 20\n",
    "JUNGSUNG_LIST = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "# 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "JONGSUNG_LIST = ['_', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "##높임말 리스트. 다음에 해당하면 높임말로 판단한다.\n",
    "H_LIST = ['니다', '니까', '요', '시오', '죠']\n",
    "\n",
    "##높임말로 변환할 때 중성끼리 합치는 경우가 있다. 그러한 경우 합치기 위한 사전이다. \n",
    "con_dict = [\n",
    "    \n",
    "    ['ㅏㅣ','ㅐ'], ['ㅑㅣ','ㅒ'], ['ㅓㅣ','ㅔ'],\n",
    "    ['ㅕㅣ','ㅖ'], ['ㅗㅣ','ㅚ'], ['ㅗㅐ','ㅙ'],\n",
    "    ['ㅜㅓ','ㅝ'], ['ㅜㅔ','ㅞ'], ['ㅡㅣ','ㅢ'],\n",
    "    ['ㅣㅏ','ㅑ'], ['ㅣㅓ','ㅕ'], ['ㅣㅗ','ㅛ'],\n",
    "    ['ㅣㅜ','ㅠ'], ['ㅡㅓ','ㅓ']\n",
    "    \n",
    "]\n",
    "\n",
    "####high -> low Dictionary####\n",
    "\n",
    "##EF(종결어미): 형태소 분류 시 종결어미가 단독으로 분석 되는 경우\n",
    "EF_ONLY = [\n",
    "    \n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']], #ex)'습니다'-> '다'\n",
    "    [['ㄴ','ㅏ','ㅇ','ㅛ'],['ㄴ','ㅏ']],\n",
    "    [['ㄷ','ㅐ','ㅇ','ㅛ'],['ㄷ','ㅐ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄴ','ㅔ','ㅇ','ㅛ'],['ㄷ','ㅏ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅈ','ㅛ'],['ㅈ','ㅣ']],\n",
    "    [['ㅇ','ㅏ','ㅇ','ㅛ'],['ㅇ','ㅏ']],\n",
    "    [['ㅇ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㅇ','ㅡ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ','ㅇ','ㅛ'],['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ']],\n",
    "    #[['ㅎ','ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅎ','ㅇ','ㅏ']],\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅓ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅇ','ㅛ'],['']],\n",
    "    \n",
    "]\n",
    "\n",
    "#EP(선어말어미)+EF(종결어미)로 형태소가 분석될 경우\n",
    "EP_EF = [\n",
    "    \n",
    "    [['ㅅ','ㅔ','ㅇ','ㅛ'],['special']]\n",
    "    #-시오 family\n",
    "    ,[['ㅡ','ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㅓ']]\n",
    "    ,[['ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㄹ', 'ㅏ']],\n",
    "    [['ㅅ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅣ']],\n",
    "    [['ㅅ','ㅣ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ'],['ㄹ','ㄹ','ㅐ']],\n",
    "]\n",
    "\n",
    "#VCP+EF\n",
    "VCP_EF = [\n",
    "    \n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㅇ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅈ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅖ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄱ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ']],\n",
    "    \n",
    "]\n",
    "\n",
    "#XSA+EF\n",
    "XSA_EF = [\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "#XSV+EF\n",
    "XSV_EF = [\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅎ','ㅐ','ㅇ','ㅛ'],['ㅎ','ㅏ','ㅈ','ㅏ']],\n",
    "]\n",
    "\n",
    "#alpha+EF: 위의 경우를 제외한 나머지 경우를 의미한다. \n",
    "A_EF = [\n",
    "    [['ㄱ','ㅓ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㄱ','ㅖ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅆ','ㅇ','ㅓ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "##높임표현이 어말어미가 아닌 경우##\n",
    "# - 기존의 변환 방식이었다. 이제는 쓰지는 않지만, 코드의 오류가 발생할 가능성이 있기에 지우지 않았다. 따로 참고할 필요 없음.\n",
    "EF = [\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [[' ','ㅈ','ㅓ','ㄴ',' '],['ㄴ','ㅏ','_','ㄴ','ㅡ','ㄴ']],\n",
    "    [['ㅇ','ㅓ','_','ㅇ','ㅛ','_'],['ㄷ','ㅏ','_']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    #,[['ㅅ','ㅔ'],['ㅝ'],['ㅘ']]\n",
    "]\n",
    "\n",
    "NP = [\n",
    "    \n",
    "    [['ㅈ','ㅓ','ㄴ'],['ㄴ','ㅏ','ㄴ']],\n",
    "    [['ㅈ','ㅓ'],['ㄴ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "# 보조사\n",
    "JX = [\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "VX = [\n",
    "    \n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']]\n",
    "    \n",
    "]\n",
    "\n",
    "VV = [\n",
    "    \n",
    "    [['ㅇ','ㅗ'],['ㅇ','ㅗ'],['ㅇ','ㅘ']],\n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']],\n",
    "    [['ㅎ','ㅏ'],['ㅎ','ㅏ'],['ㅎ','ㅐ']]\n",
    "    \n",
    "]\n",
    "\n",
    "XR = [\n",
    "    [['ㅈ','ㅚ','ㅅ','ㅗ','ㅇ'],['ㅁ','ㅣ','ㅇ','ㅏ','ㄴ'] ]\n",
    "]\n",
    "\n",
    "NNG = [\n",
    "    [['ㅈ','ㅏ','ㅇ','ㅛ'],['ㅈ','ㅏ']]\n",
    "]\n",
    "\n",
    "#Not Use\n",
    "EXC = [\n",
    "    \n",
    "    ['ㅜ',1],\n",
    "    ['ㅗ',2],\n",
    "    ['ㅏ',3]\n",
    "    \n",
    "]\n",
    "\n",
    "EXC_word = [\n",
    "    \n",
    "    ['ㅅㅔ',2]\n",
    "    ,['ㅅㅣㅂ',2]\n",
    "    \n",
    "]\n",
    "\n",
    "EXC_deal = [\n",
    "    \n",
    "    ['ㅅㅔㅇㅛ', ['ㅏ','ㅣ'],['ㅜ','ㅓ'],['ㅡ','ㅓ']]\n",
    "    \n",
    "]\n",
    "\n",
    "EXC_tags = [\n",
    "    \n",
    "    'EP',\n",
    "    'EF'\n",
    "    \n",
    "]\n",
    "\n",
    "####End of high -> low Dictionary####\n",
    "\n",
    "\n",
    "#### low -> high Dictionary####\n",
    "\n",
    "EF_ONLY_4S = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['special']]\n",
    "    \n",
    "]\n",
    "\n",
    "EF_ONLY_4C = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "    ,[['ㅇ','ㅓ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "VCP_EF_4 = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "EF_AFTER_VCP_4 = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "#### End of low -> high Dictionary####\n",
    "\n",
    "def unite(input, dict):\n",
    "    for i in dict:\n",
    "        input = re.sub(i[0],i[1],input)\n",
    "    return input\n",
    "    \n",
    "## 자모 단위로 문장을 나누고 합칠 때 쓰는 class ##\n",
    "class Jamodealer:\n",
    "    jamo = []\n",
    "    pp = ''\n",
    "    #각 단어들을 받아와서 자모단위로 나눈다.\n",
    "    def __init__(self,lis_word):\n",
    "    \n",
    "        self.jamo = []\n",
    "        for i in lis_word:\n",
    "            self.jamo.append(split_syllables(i))\n",
    "    \n",
    "    ##사전에서 변환된 자모단위로 분리된 문장을 합칠 때 쓰는 함수이다.     \n",
    "    def make_one(self):\n",
    "        #list 형태로 저장된 자모들의 집합을 하나의 string pp에 저장한다. \n",
    "        self.pp = ''\n",
    "        for i in self.jamo:\n",
    "             self.pp= self.pp+i\n",
    "        ##종성과 종성을 합쳐야 하는 경우가 있다면 합친다.        \n",
    "        self.pp = unite(self.pp, con_dict)\n",
    "        \n",
    "        #자모 단위의 string에서 자모 단위로 사전을 만들고 거기에 index를 부여한다.        \n",
    "        chars = list(set(self.pp))\n",
    "        char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "        ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "        #자모 단위로 분리되었던 문장을 다시 하나로 합친다.\n",
    "        jamo_numbers = [char_to_ix[x] for x in self.pp]\n",
    "        restored_jamo = ''.join([ix_to_char[x] for x in jamo_numbers])\n",
    "        #합쳐진 문장을 return 한다.\n",
    "        restored_text = join_jamos(restored_jamo)\n",
    "        return restored_text\n",
    "##End of Jamodealer class##\n",
    "\n",
    "def tojamo(korean_word):\n",
    "    r_lst = []\n",
    "    for w in list(korean_word.strip()):\n",
    "        ## 영어인 경우 구분해서 작성함. \n",
    "        if '가'<=w<='힣':\n",
    "            ## 588개 마다 초성이 바뀜. \n",
    "            ch1 = (ord(w) - ord('가'))//588\n",
    "            ## 중성은 총 28가지 종류\n",
    "            ch2 = ((ord(w) - ord('가')) - (588*ch1)) // 28\n",
    "            ch3 = (ord(w) - ord('가')) - (588*ch1) - 28*ch2\n",
    "            r_lst.append([CHOSUNG_LIST[ch1], JUNGSUNG_LIST[ch2], JONGSUNG_LIST[ch3]])\n",
    "        else:\n",
    "            r_lst.append([w])\n",
    "    return r_lst\n",
    "\n",
    "##Not Use\n",
    "# def to1dim(input):\n",
    "#     result=[]\n",
    "#     for i in input:\n",
    "#         for j in i:\n",
    "#             result.append(j)\n",
    "#     return result\n",
    "\n",
    "##Not Use\n",
    "# def to2dim(input):\n",
    "#     result = []\n",
    "#     li = []\n",
    "#     for i in input:\n",
    "#         if i == ' ':\n",
    "#             result.append([' '])\n",
    "#         else:\n",
    "#             li.append(i)\n",
    "#         if len(li)==3:\n",
    "#             result.append(li)\n",
    "#             li = []\n",
    "#     return result\n",
    "\n",
    "##Not Use\n",
    "# def makeone(input):\n",
    "#     result = ''\n",
    "#     li = ''\n",
    "#     for i in input:\n",
    "#         if i[0]==' ':\n",
    "#             result = result+' '\n",
    "#         else:\n",
    "#             ind = ord('가')\n",
    "#             ind +=CHOSUNG_LIST.index(i[0])*588\n",
    "#             ind +=JUNGSUNG_LIST.index(i[1])*28\n",
    "#             ind +=JONGSUNG_LIST.index(i[2])\n",
    "#             result = result+chr(ind)\n",
    "#     return result\n",
    "\n",
    "#Use in makestrdict\n",
    "def li2str(input):\n",
    "    st = \"\"\n",
    "    for i in input:\n",
    "        st = st+i\n",
    "    return st\n",
    "\n",
    "##Not Use\n",
    "# def str2li(input):\n",
    "#     li = []\n",
    "#     for i in range(len(input)):\n",
    "#         li.append(input[i])\n",
    "#     return li\n",
    "\n",
    "##Not Use\n",
    "# def makejamodict(input):\n",
    "#     result = []\n",
    "#     for i in input:\n",
    "#         bullet = []\n",
    "#         one = []\n",
    "#         two = []\n",
    "#         gre1 = tojamo(i[0])\n",
    "#         for j in gre1:\n",
    "#             for k in j:\n",
    "#                 one.append(k)\n",
    "#         bullet.append(one)\n",
    "#         gre2 = tojamo(i[1])\n",
    "#         for j in gre2:\n",
    "#             for k in j:\n",
    "#                 two.append(k)\n",
    "#         bullet.append(two)\n",
    "#         result.append(bullet)\n",
    "#     return result\n",
    "\n",
    "##Used when make dictionaries\n",
    "def makestrdict(input):\n",
    "    result = []\n",
    "    for i in input:\n",
    "        bullet = []\n",
    "        for j in range(len(i)):\n",
    "            gre = li2str(i[j])\n",
    "            bullet.append(gre)\n",
    "        result.append(bullet)\n",
    "    return result\n",
    "\n",
    "#추가한 사전에 대한 str 사전을 생성, mapping 시키는 부분\n",
    "#EP_dict = makestrdict(EP)\n",
    "EF_dict = makestrdict(EF)\n",
    "NP_dict = makestrdict(NP)\n",
    "JX_dict = makestrdict(JX)\n",
    "VX_dict = makestrdict(VX)\n",
    "VV_dict = makestrdict(VV)\n",
    "XR_dict = makestrdict(XR)\n",
    "NNG_dict = makestrdict(NNG)\n",
    "\n",
    "Dict_list=['EF','NP','JX','VX','VV','XR','NNG']\n",
    "\n",
    "Dict_map = [EF_dict,NP_dict,JX_dict,VX_dict, VV_dict, XR_dict, NNG_dict]\n",
    "\n",
    "EF_ONLY_dict = makestrdict(EF_ONLY)\n",
    "EP_EF_dict = makestrdict(EP_EF)\n",
    "VCP_EF_dict = makestrdict(VCP_EF)\n",
    "A_EF_dict = makestrdict(A_EF)\n",
    "XSA_EF_dict = makestrdict(XSA_EF)\n",
    "XSV_EF_dict = makestrdict(XSV_EF)\n",
    "\n",
    "#여기까지\n",
    "\n",
    "#str dict의 low->high \n",
    "EF_ONLY_4S_dict = makestrdict(EF_ONLY_4S)\n",
    "EF_ONLY_4C_dict = makestrdict(EF_ONLY_4C)\n",
    "EF_AFTER_VCP_4_dict = makestrdict(EF_AFTER_VCP_4)\n",
    "VCP_EF_4_dict = makestrdict(VCP_EF_4)\n",
    "\n",
    "##Use in Changer\n",
    "def to2lists(input):\n",
    "    lis_word = []\n",
    "    lis_tag = []\n",
    "    #data = han.pos(input,ntags=22,flatten=True, join=False)\n",
    "    data = mec.pos(input)\n",
    "    for i in data:\n",
    "        lis_word.append(i[0])\n",
    "        lis_tag.append(i[1])\n",
    "    return lis_word, lis_tag\n",
    "\n",
    "#add in 2021.09.26\n",
    "\n",
    "def indee(lis, input):\n",
    "    \n",
    "    rlis = []\n",
    "    \n",
    "    for i in range(len(lis)):\n",
    "        if lis[i]==input:\n",
    "            rlis.append(i)\n",
    "            \n",
    "    for i in range(len(rlis)):\n",
    "        rlis[i] = rlis[i]-i\n",
    "            \n",
    "    return rlis\n",
    "\n",
    "def ind_lili(lis_space,lis_lis):\n",
    "    \n",
    "    rlis = []\n",
    "    k=0\n",
    "    for i in range(len(lis_lis)):\n",
    "        \n",
    "        if k in lis_space:\n",
    "            rlis.append(i)\n",
    "            \n",
    "        k = k+len(lis_lis[i])\n",
    "        \n",
    "    \n",
    "    return rlis\n",
    "\n",
    "def union(lis, lis_lis):\n",
    "    \n",
    "    k = 0\n",
    "    for i in lis:\n",
    "        lis_lis.insert(i+k,' ')\n",
    "        k = k+1\n",
    "\n",
    "## Main Class ## \n",
    "class Changer(object):\n",
    "    ## High -> Low ##    \n",
    "    def high_low(self, stc):\n",
    "        result = stc\n",
    "        \n",
    "        space_list = indee(stc,' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = ind_lili(space_list, lis_word)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        lis = []\n",
    "        key = -1\n",
    "        for i in H_LIST:\n",
    "            if i in lis_word[-2]:\n",
    "                key = 1\n",
    "        #if key>0:\n",
    "        if key>0 or key<0:     \n",
    "            for i in range(len(lis_tag)):\n",
    "                res = jam.jamo[i]\n",
    "                for k in range(len(Dict_list)):\n",
    "                    dic = []\n",
    "                    if 'EF' in lis_tag[i]:\n",
    "                        if 'EF' == lis_tag[i]:\n",
    "                            dic = EF_ONLY_dict\n",
    "                        elif 'EP' in lis_tag[i]:\n",
    "                            dic = EP_EF_dict\n",
    "                        elif 'VCP' in lis_tag[i]:\n",
    "                            dic = VCP_EF_dict\n",
    "                        else:\n",
    "                            dic = A_EF_dict\n",
    "                        \n",
    "                    elif Dict_list[k] in lis_tag[i]:\n",
    "                        dic = Dict_map[Dict_list.index(Dict_list[k])]\n",
    "                        #res = jam.jamo[i]\n",
    "                    for j in range(len(dic)):\n",
    "                        if self.isExcept(dic[j])==1:\n",
    "                            #ind = self.indicator(i,jam.jamo,lis_tag,EXC_word, EXC_tags)\n",
    "                            for q in range(len(EXC_deal)):\n",
    "                                if dic[j][0]==EXC_deal[q][0]:\n",
    "                                    for r in range(1,len(EXC_deal[q])):\n",
    "                                        if jam.jamo[i-1][-1]==EXC_deal[q][r][0]:\n",
    "                                            res = re.sub(dic[j][0],EXC_deal[q][r][1],res);\n",
    "                            #res = re.sub(dic[j][0],dic[j][ind],res)\n",
    "                        else:\n",
    "                            #print('tt')\n",
    "                            res = re.sub(dic[j][0],dic[j][1],res)\n",
    "                            \n",
    "                        #jam.jamo[i] = res\n",
    "                lis.append(res)\n",
    "            \n",
    "            \n",
    "            #print(jam.jamo[i])\n",
    "        \n",
    "        union(space_location, lis)\n",
    "        jam.jamo = []\n",
    "        for i in range(len(lis)):\n",
    "            jam.jamo.append(lis[i])\n",
    "            #print(lis[i])\n",
    "        \n",
    "        #union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "    \n",
    "    def low_high(self, stc):\n",
    "        result = stc\n",
    "        \n",
    "        space_list = indee(stc, ' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = ind_lili(space_list, lis_word)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        lis = []\n",
    "        key = -1\n",
    "        \n",
    "        for i in H_LIST:\n",
    "            if i not in lis_word[-2]:\n",
    "                \n",
    "                key = 1\n",
    "        #if key>0:\n",
    "        if key>0 or key<0:    \n",
    "            res = jam.jamo[-2]\n",
    "            dic = []\n",
    "            if 'EF' in lis_tag[-2]:\n",
    "                \n",
    "                if 'EF' == lis_tag[-2]:\n",
    "                    if '+' in lis_tag[-3]:\n",
    "                        dic = EF_ONLY_4C_dict\n",
    "                    elif lis_tag[-3]=='VCP':\n",
    "                        dic = EF_AFTER_VCP_4_dict\n",
    "                    else:\n",
    "                        dic = EF_ONLY_4S_dict\n",
    "                elif 'EP' in lis_tag[-2]:\n",
    "                    dic = EP_EF_dict\n",
    "                elif 'VCP' in lis_tag[-2]:\n",
    "                    dic = VCP_EF_4_dict\n",
    "                else:\n",
    "                    dic = A_EF_dict\n",
    "            for i in range(len(dic)):\n",
    "                if len(dic[i])>2:\n",
    "                    res = re.sub(dic[i][0],dic[i][1],res)\n",
    "                else:\n",
    "                    res = re.sub(dic[i][0],dic[i][1],res)\n",
    "            jam.jamo[-2] = res\n",
    "            \n",
    "        union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    def isExcept(self, input):\n",
    "        if input[1]=='special':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def indicator(self, ind, lis, tag, ex_word, exc_tags):\n",
    "        re = 1\n",
    "        for j in range(len(ex_word)):\n",
    "            if exc_tags[j] in tag[ind+1]:\n",
    "                for i in range(len(ex_word)):\n",
    "                    if ex_word[i][0] in lis[ind+1]:\n",
    "                       \n",
    "                        re = ex_word[i][1]\n",
    "                        break\n",
    "                        \n",
    "                        print(lis[ind-1])\n",
    "        return re\n",
    "        \n",
    "        \n",
    "    def processText(self,stc):\n",
    "        result = stc\n",
    "        res = self.high_low(result)\n",
    "        #spacing = Spacing()\n",
    "        #res = spacing(res)\n",
    "        return res\n",
    "    \n",
    "    def processText_0(self,stc):\n",
    "        result = stc\n",
    "        res = self.low_high(result)\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df86f61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "밥 먹어.\n"
     ]
    }
   ],
   "source": [
    "#txt = '전 그것이 맞다고 생각합니다.'\n",
    "tx = '밥 먹으세요.'\n",
    "ch = Changer()\n",
    "#tt = ch.processText(txt)\n",
    "ttt = ch.processText(tx)\n",
    "#print(tt)\n",
    "print(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89c4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 1858355\n",
    "texts = pd.read_table('./data/hgu_clean.kr', sep ='\\n')\n",
    "\n",
    "new_data = {\n",
    "    \n",
    "    '26일이요?':'26일이요?'\n",
    "    \n",
    "}\n",
    "\n",
    "idx = 0\n",
    "\n",
    "temp1 = texts[texts.index < idx]\n",
    "temp2 = texts[texts.index>= idx]\n",
    "\n",
    "texts = temp1.append(new_data,ignore_index=True).append(temp2, ignore_index=True)\n",
    "\n",
    "texts = texts['26일이요?']\n",
    "\n",
    "num = len(texts)\n",
    "\n",
    "ch = Changer()\n",
    "f = open('./hgu_clean.low.kr', 'w',encoding = 'utf-8')\n",
    "for i in range(0,num):\n",
    "    if texts[i][-1] !='?'and texts[i][-1] !='.' and texts[i][-1] !='!':\n",
    "        texts[i] = texts[i]+'.'\n",
    "    tt = ch.processText(texts[i])\n",
    "    f.write(tt)\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b63d5401",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2812b5e44662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;32mand\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ec5bb257d1b4>\u001b[0m in \u001b[0;36mprocessText\u001b[0;34m(self, stc)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocessText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_low\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0;31m#spacing = Spacing()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m#res = spacing(res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ec5bb257d1b4>\u001b[0m in \u001b[0;36mhigh_low\u001b[0;34m(self, stc)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mlis_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto2lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mspace_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_lili\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mjam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJamodealer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0mlis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ec5bb257d1b4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lis_word)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjamo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlis_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jh/lib/python3.9/site-packages/hangul_utils/unicode.py\u001b[0m in \u001b[0;36msplit_syllables\u001b[0;34m(s, ignore_err, pad)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jh/lib/python3.9/site-packages/hangul_utils/unicode.py\u001b[0m in \u001b[0;36mtry_split\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtry_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msplit_syllable_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mignore_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jh/lib/python3.9/site-packages/hangul_utils/unicode.py\u001b[0m in \u001b[0;36msplit_syllable_char\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mFINAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCHAR_INDICES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINITIAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "texts1 = pd.read_table('./data/hgu_clean.kr.shuf', sep ='\\n')\n",
    "\n",
    "new_data = {\n",
    "    \n",
    "    '그것은 가솔린 수소 또는 전기 모터로 움직일 수 있다':'그것은 가솔린 수소 또는 전기 모터로 움직일 수 있다'\n",
    "    \n",
    "}\n",
    "\n",
    "idx = 0\n",
    "\n",
    "temp1 = texts1[texts1.index < idx]\n",
    "temp2 = texts1[texts1.index>= idx]\n",
    "\n",
    "texts1 = temp1.append(new_data,ignore_index=True).append(temp2, ignore_index=True)\n",
    "\n",
    "texts1 = texts1['그것은 가솔린 수소 또는 전기 모터로 움직일 수 있다']\n",
    "\n",
    "num = len(texts1)\n",
    "a = len(texts1)\n",
    "#print(a)\n",
    "ch = Changer()\n",
    "f = open('./hgu_clean.low.kr.shuf', 'w',encoding = 'utf-8')\n",
    "for i in range(0,num):\n",
    "    if texts1[i][-1] !='?'and texts1[i][-1] !='.' and texts1[i][-1] !='!':\n",
    "        texts1[i] = texts1[i]+'.'\n",
    "    tt = ch.processText(texts1[i])\n",
    "    f.write(tt)\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98918efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

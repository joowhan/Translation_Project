{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a459b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "#from eunjeon import Mecab\n",
    "from konlpy.tag import Mecab\n",
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b811007",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_dict = [\n",
    "    \n",
    "    ['ㅏㅣ','ㅐ'], ['ㅑㅣ','ㅒ'], ['ㅓㅣ','ㅔ'],\n",
    "    ['ㅕㅣ','ㅖ'], ['ㅗㅣ','ㅚ'], ['ㅗㅐ','ㅙ'],\n",
    "    ['ㅜㅓ','ㅝ'], ['ㅜㅔ','ㅞ'], ['ㅡㅣ','ㅢ'],\n",
    "    ['ㅣㅏ','ㅑ'], ['ㅣㅓ','ㅕ'], ['ㅣㅗ','ㅛ'],\n",
    "    ['ㅣㅜ','ㅠ'], ['ㅡㅓ','ㅓ'], ['ㅗㅏ','ㅘ']\n",
    "    \n",
    "]\n",
    "\n",
    "jongsung_list = [ 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "\n",
    "#lis_beta = ['EP+EF', 'VCP+EF', 'B+EF', 'B+EP+EF', 'B+VCP+EF', 'EF','EP']\n",
    "\n",
    "lis_beta = ['EP+EF', 'EF', 'B+EF', 'B+EP+EF']\n",
    "\n",
    "#어말을 처리해 주기 위한 것으로, 나중에 EC등이 필요해 진다면 이 부분에 EC 등을 집어넣어준다. 참고로 말하자면 이는 마지막에 위치해야한다.\n",
    "#특이 바로 밑의 이 부분은 형태소 태그가 이 리스트 안의 것과 일치하는 경우 단순 삭제를 하는 것이고\n",
    "lis_beta_ef = ['EP+EF', 'EF', 'UNKNOWN']\n",
    "\n",
    "#이 부분 같은 경우는 마지막에 오는 것을 처리하는 것으로 단독으로만 들어가는게 좋겠지?\n",
    "lis_tag_last = ['EF', 'UNKNOWN']\n",
    "\n",
    "lis_end = [\n",
    "    \n",
    "    'ㅂㄴㅣㄷㅏ',\n",
    "    'ㅅㅔㅇㅛ', 'ㄷㅔㅇㅛ', 'ㅇㅔㅇㅛ', 'ㅇㅖㅇㅛ', 'ㄴㅏㅇㅛ', 'ㅇㅡㄹㄲㅏㅇㅛ', 'ㅇㅣㄹㄲㅏㅇㅛ', 'ㄹㄲㅏㅇㅛ', 'ㅇㅡㄴㄱㅏㅇㅛ', 'ㅇㅣㄴㄱㅏㅇㅛ','ㅇㅛ',\n",
    "    'ㅈㅛ',\n",
    "    'ㅅㅣㅂㅅㅣㅇㅗ', 'ㅅㅣㅇㅗ', 'ㅇㅗ',\n",
    "    'ㅂㄴㅣㄲㅏ', 'ㅅㅡㅂㄴㅣㄷㅏ', 'ㄴㅣㄲㅏ', 'ㄲㅏ', \n",
    "    \n",
    "]\n",
    "\n",
    "lis_end_2low = [\n",
    "    \n",
    "    'ㄷㅓㄹㅏ','ㄴㄷㅏ', 'ㅆㄷㅏ', 'ㄹㅗㄷㅏ', 'ㄷㅏ', \n",
    "    'ㄹㅏ',\n",
    "    'ㅇㅑ', \n",
    "    'ㄲㅏ', \n",
    "    'ㄴㅣ', \n",
    "    'ㅇㅏ', \n",
    "    \n",
    "]\n",
    "\n",
    "# lis_end_2low = [\n",
    "    \n",
    "#     'ㄷㅓㄹㅏ','ㄴㄷㅏ', 'ㅆㄷㅏ', 'ㄷㅏ', \n",
    "#     'ㄹㅏ',\n",
    "#     'ㅇㅑ', \n",
    "    \n",
    "# ]\n",
    "\n",
    "P_LIST = ['.', '?', '!']\n",
    "\n",
    "SV_LIST = ['\\'', '\\\"', ':', ';']\n",
    "\n",
    "lis_plus = [\n",
    "    \n",
    "    'EP', 'VCP', \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe259ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mec = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f377fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite(input, dict):\n",
    "    for i in dict:\n",
    "        input = re.sub(i[0],i[1],input)\n",
    "    return input\n",
    "    \n",
    "## 자모 단위로 문장을 나누고 합칠 때 쓰는 class ##\n",
    "class Jamodealer:\n",
    "    jamo = []\n",
    "    pp = ''\n",
    "    #각 단어들을 받아와서 자모단위로 나눈다.\n",
    "    def __init__(self,lis_word):\n",
    "    \n",
    "        self.jamo = []\n",
    "        for i in lis_word:\n",
    "            self.jamo.append(split_syllables(i))\n",
    "    \n",
    "    ##사전에서 변환된 자모단위로 분리된 문장을 합칠 때 쓰는 함수이다.     \n",
    "    def make_one(self):\n",
    "        #list 형태로 저장된 자모들의 집합을 하나의 string pp에 저장한다. \n",
    "        self.pp = ''\n",
    "        for i in self.jamo:\n",
    "             self.pp= self.pp+i\n",
    "        ##종성과 종성을 합쳐야 하는 경우가 있다면 합친다.        \n",
    "        self.pp = unite(self.pp, con_dict)\n",
    "        \n",
    "        #자모 단위의 string에서 자모 단위로 사전을 만들고 거기에 index를 부여한다.        \n",
    "        chars = list(set(self.pp))\n",
    "        char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "        ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "        #자모 단위로 분리되었던 문장을 다시 하나로 합친다.\n",
    "        jamo_numbers = [char_to_ix[x] for x in self.pp]\n",
    "        restored_jamo = ''.join([ix_to_char[x] for x in jamo_numbers])\n",
    "        #합쳐진 문장을 return 한다.\n",
    "        restored_text = join_jamos(restored_jamo)\n",
    "        return restored_text\n",
    "\n",
    "def to2lists(input):\n",
    "    lis_word = []\n",
    "    lis_tag = []\n",
    "    #data = han.pos(input,ntags=22,flatten=True, join=False)\n",
    "    data = mec.pos(input)\n",
    "    for i in data:\n",
    "        lis_word.append(i[0])\n",
    "        lis_tag.append(i[1])\n",
    "    return lis_word, lis_tag\n",
    "\n",
    "def rememberSpace(lis, input):\n",
    "    \n",
    "    rlis = []\n",
    "    \n",
    "    for i in range(len(lis)):\n",
    "        if lis[i]==input:\n",
    "            rlis.append(i)\n",
    "            \n",
    "    for i in range(len(rlis)):\n",
    "        rlis[i] = rlis[i]-i      \n",
    "    return rlis\n",
    "\n",
    "def convertSpace(lis_space,lis_lis):\n",
    "    \n",
    "    rlis = []\n",
    "    k=0\n",
    "    for i in range(len(lis_lis)):\n",
    "        \n",
    "        if k in lis_space:\n",
    "            rlis.append(i)\n",
    "            \n",
    "        k = k+len(lis_lis[i])\n",
    "        \n",
    "    #print(rlis)  \n",
    "    return rlis\n",
    "\n",
    "def union(lis, lis_lis):\n",
    "    \n",
    "    k = 0\n",
    "    for i in lis:\n",
    "        lis_lis.insert(i+k,' ')\n",
    "        k = k+1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6e5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_t(lis_lis):\n",
    "    \n",
    "    for i in range(len(lis_lis)-1):\n",
    "        if lis_lis[i+1] != ' ' and lis_lis[i+1] !='SF' and lis_lis[i] != ' ' and lis_lis[i] !='SF':\n",
    "            lis_lis[i] = lis_lis[i]+'/'\n",
    "        if lis_lis[i+1]=='SF':\n",
    "            lis_lis[i+1] = ' '+lis_lis[i+1]\n",
    "            \n",
    "def union_w(lis_w, lis_tag):\n",
    "    \n",
    "    for i in range(len(lis_w)-1):\n",
    "        if lis_tag[i+1]==' SF':\n",
    "            lis_w[i+1] = ' '+lis_w[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e6d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_t_03(lis_tag):\n",
    "    \n",
    "    for i in range(1, len(lis_tag)):\n",
    "        if lis_tag[i-1] ==' ' or lis_tag[i]==' ':\n",
    "            lis_tag[i] = lis_tag[i]\n",
    "        else:\n",
    "            lis_tag[i] = '/'+lis_tag[i]\n",
    "            \n",
    "def union_w_03(lis_w, lis_tag):\n",
    "    \n",
    "    for i in range(1, len(lis_w)):\n",
    "        if lis_tag[i]==' SF':\n",
    "            lis_w[i] = ' '+lis_w[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5275dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(input):\n",
    "    lis_w, lis_t = to2lists(input)\n",
    "\n",
    "    space_list = rememberSpace(input,' ')\n",
    "    space_location = convertSpace(space_list, lis_w)\n",
    "    union(space_location, lis_w)\n",
    "    union(space_location, lis_t)\n",
    "    union_t_03(lis_t)\n",
    "    union_w_03(lis_w, lis_t)\n",
    "    \n",
    "    str_w = ''\n",
    "    str_t = ''\n",
    "    for i in range(len(lis_w)):\n",
    "        str_w = str_w + lis_w[i]\n",
    "        str_t = str_t + lis_t[i]\n",
    "    \n",
    "    data_w = str_w.split(' ')\n",
    "    data_t = str_t.split(' ')\n",
    "    \n",
    "    lis_word, lis_tag = to2lists(input)\n",
    "    \n",
    "    lis_ind = []\n",
    "    t_ind = 0\n",
    "    jam1 = Jamodealer(lis_word)\n",
    "    jam2 = Jamodealer(data_w)\n",
    "    for i in range(len(data_w)):\n",
    "        element = []\n",
    "        leng = len(data_t[i].split('/'))\n",
    "        res = jam2.jamo[i]\n",
    "        ind = 0\n",
    "        lenlen = 0\n",
    "        #element.append(0)\n",
    "        for j in range(leng):\n",
    "            element.append(ind)\n",
    "            ind = ind + len(jam1.jamo[t_ind])\n",
    "            res = res[len(jam1.jamo[t_ind]):]\n",
    "            \n",
    "            lenlen = len(jam1.jamo[t_ind])+lenlen\n",
    "            t_ind = t_ind+1\n",
    "\n",
    "        element.append(len(jam2.jamo[i]))\n",
    "        lis_ind.append(element)\n",
    "        \n",
    "    return data_w, data_t, lis_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbce944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['백화점은', '문을', '닫았고', '일자리는', '구하기', '힘들어', '젔다?'],\n",
       " ['NNG/JX', 'NNG/JKO', 'VV/EP/EC', 'NNG/JX', 'VV/ETN', 'VA/EC', 'UNKNOWN/SF'],\n",
       " [[0, 8, 11],\n",
       "  [0, 3, 6],\n",
       "  [0, 3, 6, 8],\n",
       "  [0, 7, 10],\n",
       "  [0, 4, 6],\n",
       "  [0, 6, 8],\n",
       "  [0, 5, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro('백화점은 문을 닫았고 일자리는 구하기 힘들어 젔다? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f37e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effa142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_beta(input, lis_ef, tag_last, lis_w_last):\n",
    "    data_w, data_t, lis_ind = prepro(input)\n",
    "    \n",
    "    last_words = []\n",
    "    \n",
    "    data_w_jamo = []\n",
    "    \n",
    "    data_t_after = []\n",
    "    \n",
    "    for i in data_w:\n",
    "        jam_ele = Jamodealer(i)\n",
    "        ele = ''\n",
    "        for j in jam_ele.jamo:\n",
    "            ele = ele+j\n",
    "        data_w_jamo.append(ele)\n",
    "    \n",
    "    for i in range(len(data_t)):\n",
    "        #if i<len(data_t)-1:\n",
    "        if i<len(data_t):\n",
    "            lis_res = []\n",
    "            for ind in range(len(lis_ind[i])-1):\n",
    "                lis_res.append(data_w_jamo[i][lis_ind[i][ind]:lis_ind[i][ind+1]])\n",
    "\n",
    "        if 'EF' in data_t[i] or 'UNKNOWN' in data_t[i]:\n",
    "            elements = data_t[i].split('/')\n",
    "            \n",
    "            flag = 0\n",
    "            print(elements)\n",
    "            for j in range(len(elements)):\n",
    "                \n",
    "                if elements[j] in lis_ef: #and j == len(elements)-1:\n",
    "                    \n",
    "                    elements[j] = 'NULL'\n",
    "                    \n",
    "                    last_words.append(data_w_jamo[i][lis_ind[i][j]:lis_ind[i][j+1]])\n",
    "                    #lis_res[j] = data_w_jamo[i][:lis_ind[i][j]]\n",
    "                    lis_res[j]=''\n",
    "                    \n",
    "                elif 'EF' in elements[j]:# + EF를 처리하는 부분이므로 + EF 만을 마지막에서 처리한다.\n",
    "#                     res1 = data_w_jamo[i][:lis_ind[i][j+1]]\n",
    "#                     res2 = data_w_jamo[i][lis_ind[i][j+1]:]\n",
    "#                     print(res2)\n",
    "#                     print(lis_ind[i][j+1])\n",
    "                    for jam in lis_w_last:\n",
    "#                         print('ㅈㅈ')\n",
    "                        if len(lis_res[j])>=len(jam):\n",
    "                            #if jam in lis_res[j]:\n",
    "#                             print(jam)\n",
    "                            print('ㅈㅈㅈㅈ')\n",
    "                            if lis_res[j].find(jam)!=-1:\n",
    "                                last_words.append(jam)\n",
    "                                lis_res[j] = lis_res[j].replace(jam, '', 1)\n",
    "\n",
    "                                for k in tag_last:\n",
    "\n",
    "                                    if k in elements[j] and j==len(elements)-1:\n",
    "                                        if '+' in elements[j]:\n",
    "                                            ind = elements[j].index('+'+k)\n",
    "                                            elements[j] = elements[j][:ind]\n",
    "                                break\n",
    "\n",
    "            data_w_jamo[i] = ''.join(lis_res)\n",
    "\n",
    "            elements_post = '/'.join(elements)\n",
    "            data_t_after.append(elements_post)\n",
    "            \n",
    "        else:\n",
    "            data_t_after.append(data_t[i])\n",
    "        \n",
    "    return data_w, data_t, lis_ind, data_w_jamo, data_t_after, last_words\n",
    "                        \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41414a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNG', 'VCP', 'EP', 'EF', 'SF']\n"
     ]
    }
   ],
   "source": [
    "t1, t2, t3, t4, t5, t6 = prepro_beta('그게 천재이시다.', lis_beta_ef, lis_tag_last, lis_end_2low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21083768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NP+JKS', 'NNG/VCP/EP/NULL/SF']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78def20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'VCP/NULL' in t5[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e57f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f79253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VV', 'EC', 'VV', 'EF', 'SF']\n",
      "(['짜요짜요.'], ['VV/EC/VV/EF/SF'], [[0, 2, 4, 6, 8, 9]], ['ㅉㅏㅇㅛㅉㅏ.'], ['VV/EC/VV/NULL/SF'], ['ㅇㅛ'])\n"
     ]
    }
   ],
   "source": [
    "print(prepro_beta('짜요짜요.', lis_beta_ef, lis_tag_last, lis_end_2low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f03ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8092428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49471032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_beta_02(input, lis_ef, tag_last, lis_w_last, lis_w_last_not):\n",
    "    data_w, data_t, lis_ind = prepro(input)\n",
    "    \n",
    "    last_words = []\n",
    "\n",
    "    data_w_jamo = []\n",
    "\n",
    "    data_t_after = []\n",
    "    \n",
    "    lis_target_ind = []\n",
    "    \n",
    "    for i in data_w:\n",
    "        jam_ele = Jamodealer(i)\n",
    "        ele = ''\n",
    "        for j in jam_ele.jamo:\n",
    "            ele = ele+j\n",
    "        data_w_jamo.append(ele)\n",
    "    \n",
    "    for i in range(len(data_t)):\n",
    "        #if i<len(data_t)-1:\n",
    "        if i<len(data_t):\n",
    "            lis_res = []\n",
    "            for ind in range(len(lis_ind[i])-1):\n",
    "                lis_res.append(data_w_jamo[i][lis_ind[i][ind]:lis_ind[i][ind+1]])\n",
    "\n",
    "        \n",
    "        \n",
    "                \n",
    "        if 'EF' in data_t[i] or 'UNKNOWN' in data_t[i]:\n",
    "            elements = data_t[i].split('/')\n",
    "            \n",
    "            flag = 0\n",
    "\n",
    "            for j in range(len(elements)):\n",
    "                \n",
    "                flag_end = 0\n",
    "                \n",
    "                for end in lis_w_last_not:\n",
    "                    if end in lis_res[j]:\n",
    "                        flag_end = 1\n",
    "                        break\n",
    "                \n",
    "                \n",
    "                \n",
    "                if elements[j] in lis_ef and flag_end==0: #and j == len(elements)-1:\n",
    "                    elements[j] = 'NULL'\n",
    "                    \n",
    "                    last_words.append(data_w_jamo[i][lis_ind[i][j]:lis_ind[i][j+1]])\n",
    "                    lis_res[j]=''\n",
    "                    \n",
    "                    lis_target_ind.append(i)\n",
    "                    \n",
    "                elif 'EF' in elements[j] and flag_end==0:# + EF를 처리하는 부분이므로 + EF 만을 마지막에서 처리한다.\n",
    "\n",
    "                    for jam in lis_w_last:\n",
    "                        if len(lis_res[j])>=len(jam):\n",
    "                            print(lis_res)\n",
    "\n",
    "                            res_out_punc = lis_res[:lis_ind[i][-2]][0]\n",
    "\n",
    "                            #if lis_res[j].find(jam)!=-1:\n",
    "                            if res_out_punc[-len(jam):]==jam:\n",
    "                                \n",
    "                                lis_target_ind.append(i)\n",
    "                                \n",
    "                                last_words.append(jam)\n",
    "                                lis_res[j] = lis_res[j].replace(jam, '', 1)\n",
    "\n",
    "                                for k in tag_last:\n",
    "\n",
    "                                    if k in elements[j]:\n",
    "                                        \n",
    "                                        if '+' in elements[j]:\n",
    "                                            \n",
    "                                            ind = elements[j].index('+'+k)\n",
    "                                            elements[j] = elements[j][:ind]\n",
    "                                break\n",
    "                                \n",
    "                            elif lis_w_last.index(jam)==len(lis_w_last)-1:#new\n",
    "                                for k in tag_last:\n",
    "\n",
    "                                    if k in elements[j]:\n",
    "                                        \n",
    "                                        if '+' in elements[j]:\n",
    "                                            \n",
    "                                            ind = elements[j].index('+'+k)\n",
    "                                            elements[j] = elements[j][:ind]\n",
    "                                            \n",
    "                                lis_target_ind.append(i)\n",
    "                                last_words.append('')\n",
    "                                break\n",
    "\n",
    "            data_w_jamo[i] = ''.join(lis_res)\n",
    "\n",
    "            elements_post = '/'.join(elements)\n",
    "            data_t_after.append(elements_post)\n",
    "            \n",
    "        elif 'EC/SF' in data_t[i]:\n",
    "            \n",
    "            elements = data_t[i].split('/')\n",
    "            \n",
    "            flag = 0\n",
    "            for j in range(len(elements)):\n",
    "                \n",
    "                flag_end = 0\n",
    "                \n",
    "                for end in lis_w_last_not:\n",
    "                    if end in lis_res[j]:\n",
    "                        flag_end = 1\n",
    "                        break\n",
    "                        \n",
    "                if flag_end==0 and i not in lis_target_ind:\n",
    "                    lis_target_ind.append(i)\n",
    "                    last_words.append('')\n",
    "                \n",
    "            data_t_after.append(data_t[i])\n",
    "            \n",
    "        else:\n",
    "            data_t_after.append(data_t[i])\n",
    "            \n",
    "        \n",
    "        #################################################################\n",
    "        \n",
    "        \n",
    "        lis_normal = []\n",
    "    \n",
    "        for i in data_w_jamo:\n",
    "            jam_n = Jamodealer(i)\n",
    "            lis_normal.append(jam_n.make_one())\n",
    "    \n",
    "#         lis_target_ind = []\n",
    "\n",
    "#         word_test_pre, tag_test_pre, ind_test_pre = prepro(input)\n",
    "    \n",
    "    \n",
    "#         for i in range(len(lis_normal)):\n",
    "#             if lis_normal[i]!=data_w[i]:\n",
    "#                 lis_target_ind.append(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return data_w, data_t, lis_ind, data_w_jamo, data_t_after, last_words, lis_target_ind\n",
    "                        \n",
    "                    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870375f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb9e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_beta_03(input, lis_ef, tag_last, lis_w_last, lis_w_last_not):\n",
    "    data_w, data_t, lis_ind = prepro(input)\n",
    "    \n",
    "    last_words = []\n",
    "\n",
    "    data_w_jamo = []\n",
    "\n",
    "    data_t_after = []\n",
    "    \n",
    "    lis_target_ind = []\n",
    "    \n",
    "    for i in data_w:\n",
    "        jam_ele = Jamodealer(i)\n",
    "        ele = ''\n",
    "        for j in jam_ele.jamo:\n",
    "            ele = ele+j\n",
    "        data_w_jamo.append(ele)\n",
    "    \n",
    "    for i in range(len(data_t)):\n",
    "        #if i<len(data_t)-1:\n",
    "        if i<len(data_t):\n",
    "            lis_res = []\n",
    "            for ind in range(len(lis_ind[i])-1):\n",
    "                lis_res.append(data_w_jamo[i][lis_ind[i][ind]:lis_ind[i][ind+1]])\n",
    "\n",
    "        \n",
    "        if '/SF' in data_t[i] or '/SV' in data_t[i]:\n",
    "            if 'EF' in data_t[i] or 'UNKNOWN' in data_t[i]:\n",
    "                elements = data_t[i].split('/')\n",
    "            \n",
    "                flag = 0\n",
    "\n",
    "                for j in range(len(elements)):\n",
    "                \n",
    "                    flag_end = 0\n",
    "                \n",
    "                    for end in lis_w_last_not:\n",
    "                        if end in lis_res[j]:\n",
    "                            flag_end = 1\n",
    "                            break\n",
    "                \n",
    "                \n",
    "                \n",
    "                    if elements[j] in lis_ef and flag_end==0: #and j == len(elements)-1:\n",
    "                        elements[j] = 'NULL'\n",
    "                    \n",
    "                        last_words.append(data_w_jamo[i][lis_ind[i][j]:lis_ind[i][j+1]])\n",
    "                        lis_res[j]=''\n",
    "                    \n",
    "                        lis_target_ind.append(i)\n",
    "                    \n",
    "                    elif 'EF' in elements[j] and flag_end==0:# + EF를 처리하는 부분이므로 + EF 만을 마지막에서 처리한다.\n",
    "\n",
    "                        for jam in lis_w_last:\n",
    "                            if len(lis_res[j])>=len(jam):\n",
    "                                print(lis_res)\n",
    "\n",
    "                                res_out_punc = lis_res[:lis_ind[i][-2]][0]\n",
    "\n",
    "                                #if lis_res[j].find(jam)!=-1:\n",
    "                                if res_out_punc[-len(jam):]==jam:\n",
    "                                \n",
    "                                    lis_target_ind.append(i)\n",
    "                                \n",
    "                                    last_words.append(jam)\n",
    "                                    lis_res[j] = lis_res[j].replace(jam, '', 1)\n",
    "\n",
    "                                    for k in tag_last:\n",
    "\n",
    "                                        if k in elements[j]:\n",
    "                                        \n",
    "                                            if '+' in elements[j]:\n",
    "                                            \n",
    "                                                ind = elements[j].index('+'+k)\n",
    "                                                elements[j] = elements[j][:ind]\n",
    "                                    break\n",
    "                                \n",
    "                                elif lis_w_last.index(jam)==len(lis_w_last)-1:#new\n",
    "                                    for k in tag_last:\n",
    "\n",
    "                                        if k in elements[j]:\n",
    "                                        \n",
    "                                            if '+' in elements[j]:\n",
    "                                            \n",
    "                                                ind = elements[j].index('+'+k)\n",
    "                                                elements[j] = elements[j][:ind]\n",
    "                                            \n",
    "                                    lis_target_ind.append(i)\n",
    "                                    last_words.append('')\n",
    "                                    break\n",
    "\n",
    "                data_w_jamo[i] = ''.join(lis_res)\n",
    "\n",
    "                elements_post = '/'.join(elements)\n",
    "                data_t_after.append(elements_post)\n",
    "            #######################################\n",
    "            \n",
    "            data_t_after.append(data_t[i])\n",
    "            \n",
    "        elif 'EC/SF' in data_t[i]:\n",
    "            \n",
    "            elements = data_t[i].split('/')\n",
    "            \n",
    "            flag = 0\n",
    "            for j in range(len(elements)):\n",
    "                \n",
    "                flag_end = 0\n",
    "                \n",
    "                for end in lis_w_last_not:\n",
    "                    if end in lis_res[j]:\n",
    "                        flag_end = 1\n",
    "                        break\n",
    "                        \n",
    "                if flag_end==0 and i not in lis_target_ind:\n",
    "                    lis_target_ind.append(i)\n",
    "                    last_words.append('')\n",
    "                \n",
    "            data_t_after.append(data_t[i])\n",
    "            \n",
    "        else:\n",
    "            data_t_after.append(data_t[i])\n",
    "            \n",
    "        \n",
    "        #################################################################\n",
    "        \n",
    "        \n",
    "        lis_normal = []\n",
    "    \n",
    "        for i in data_w_jamo:\n",
    "            jam_n = Jamodealer(i)\n",
    "            lis_normal.append(jam_n.make_one())\n",
    "    \n",
    "#         lis_target_ind = []\n",
    "\n",
    "#         word_test_pre, tag_test_pre, ind_test_pre = prepro(input)\n",
    "    \n",
    "    \n",
    "#         for i in range(len(lis_normal)):\n",
    "#             if lis_normal[i]!=data_w[i]:\n",
    "#                 lis_target_ind.append(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return data_w, data_t, lis_ind, data_w_jamo, data_t_after, last_words, lis_target_ind\n",
    "                        \n",
    "                    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a66bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae801118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c0b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_beta_04(input, lis_ef, tag_last, lis_w_last, lis_w_last_not):\n",
    "    data_w, data_t, lis_ind = prepro(input)\n",
    "    \n",
    "    last_words = []\n",
    "\n",
    "    data_w_jamo = []\n",
    "\n",
    "    data_t_after = []\n",
    "    \n",
    "    lis_target_ind = []\n",
    "    \n",
    "    for i in data_w:\n",
    "        jam_ele = Jamodealer(i)\n",
    "        ele = ''\n",
    "        for j in jam_ele.jamo:\n",
    "            ele = ele+j\n",
    "        data_w_jamo.append(ele)\n",
    "    \n",
    "    for i in range(len(data_t)):\n",
    "        #if i<len(data_t)-1:\n",
    "        if i<len(data_t):\n",
    "            lis_res = []\n",
    "            for ind in range(len(lis_ind[i])-1):\n",
    "                lis_res.append(data_w_jamo[i][lis_ind[i][ind]:lis_ind[i][ind+1]])\n",
    "\n",
    "        \n",
    "        if 'EF/SF' in data_t[i] or 'EF/SV' in data_t[i] or 'UNKNOWN/SF' in data_t[i] or 'UNKNOWN/SV' in data_t[i]:\n",
    "            if 'EF/SF' in data_t[i] or 'UNKNOWN' in data_t[i]:\n",
    "                elements = data_t[i].split('/')\n",
    "            \n",
    "                flag = 0\n",
    "\n",
    "                for j in range(len(elements)):\n",
    "                \n",
    "                    flag_end = 0\n",
    "                \n",
    "                    for end in lis_w_last_not:\n",
    "                        if end in lis_res[j]:\n",
    "                            flag_end = 1\n",
    "                            break\n",
    "                \n",
    "                \n",
    "                \n",
    "                    if elements[j] in lis_ef and flag_end==0: #and j == len(elements)-1:\n",
    "                        elements[j] = 'NULL'\n",
    "                    \n",
    "                        last_words.append(data_w_jamo[i][lis_ind[i][j]:lis_ind[i][j+1]])\n",
    "                        lis_res[j]=''\n",
    "                    \n",
    "                        lis_target_ind.append(i)\n",
    "                    \n",
    "#                         elements_post = '/'.join(elements)\n",
    "#                         data_t_after.append(elements_post)\n",
    "                        \n",
    "                    elif 'EF' in elements[j] and flag_end==0:# + EF를 처리하는 부분이므로 + EF 만을 마지막에서 처리한다.\n",
    "\n",
    "                        for jam in lis_w_last:\n",
    "                            if len(lis_res[j])>=len(jam):\n",
    "                                \n",
    "                                res_out_punc = lis_res[:lis_ind[i][-2]][j]\n",
    "\n",
    "                                if res_out_punc[-len(jam):]==jam:\n",
    "                                \n",
    "                                    lis_target_ind.append(i)\n",
    "                                \n",
    "                                    last_words.append(jam)\n",
    "                                    lis_res[j] = lis_res[j].replace(jam, '', 1)\n",
    "\n",
    "                                    for k in tag_last:\n",
    "\n",
    "                                        if k in elements[j]:\n",
    "                                        \n",
    "                                            if '+' in elements[j]:\n",
    "                                            \n",
    "                                                ind = elements[j].index('+'+k)\n",
    "                                                elements[j] = elements[j][:ind]\n",
    "                                    break\n",
    "                                \n",
    "                                elif lis_w_last.index(jam)==len(lis_w_last)-1:#new\n",
    "                                    for k in tag_last:\n",
    "\n",
    "                                        if k in elements[j]:\n",
    "                                        \n",
    "                                            if '+' in elements[j]:\n",
    "                                            \n",
    "                                                ind = elements[j].index('+'+k)\n",
    "                                                elements[j] = elements[j][:ind]\n",
    "                                            \n",
    "                                    lis_target_ind.append(i)\n",
    "                                    last_words.append('')\n",
    "                                    break\n",
    "\n",
    "                \n",
    "                elements_post = '/'.join(elements)\n",
    "                data_t_after.append(elements_post)\n",
    "                \n",
    "                data_w_jamo[i] = ''.join(lis_res)\n",
    "\n",
    "                #elements_post = '/'.join(elements)\n",
    "                #data_t_after.append(elements_post)\n",
    "                    \n",
    "            #######################################\n",
    "            \n",
    "            #data_t_after.append(data_t[i])\n",
    "            \n",
    "        elif 'EC/SF' in data_t[i]:\n",
    "            \n",
    "            elements = data_t[i].split('/')\n",
    "            \n",
    "            flag = 0\n",
    "            for j in range(len(elements)):\n",
    "                \n",
    "                flag_end = 0\n",
    "                \n",
    "                for end in lis_w_last_not:\n",
    "                    if end in lis_res[j]:\n",
    "                        flag_end = 1\n",
    "                        break\n",
    "                        \n",
    "                if flag_end==0 and i not in lis_target_ind:\n",
    "                    lis_target_ind.append(i)\n",
    "                    last_words.append('')\n",
    "            print(data_t[i])\n",
    "            data_t_after.append(data_t[i])\n",
    "            \n",
    "        else:\n",
    "            data_t_after.append(data_t[i])\n",
    "            \n",
    "        \n",
    "        #################################################################\n",
    "        \n",
    "        \n",
    "        lis_normal = []\n",
    "    \n",
    "        for i in data_w_jamo:\n",
    "            jam_n = Jamodealer(i)\n",
    "            lis_normal.append(jam_n.make_one())\n",
    "    \n",
    "#         lis_target_ind = []\n",
    "\n",
    "#         word_test_pre, tag_test_pre, ind_test_pre = prepro(input)\n",
    "    \n",
    "    \n",
    "#         for i in range(len(lis_normal)):\n",
    "#             if lis_normal[i]!=data_w[i]:\n",
    "#                 lis_target_ind.append(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return data_w, data_t, lis_ind, data_w_jamo, data_t_after, last_words, lis_target_ind\n",
    "                        \n",
    "                    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcdd2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb5460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f57513b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['백화점은', '문을', '닫았고', '일자리는', '구하기', '힘들어졌다.'], ['NNG/JX', 'NNG/JKO', 'VV/EP/EC', 'NNG/JX', 'VV/ETN', 'VA/EC/VX+EP/EF/SF'], [[0, 8, 11], [0, 3, 6], [0, 3, 6, 8], [0, 7, 10], [0, 4, 6], [0, 6, 8, 11, 13, 14]], ['ㅂㅐㄱㅎㅘㅈㅓㅁㅇㅡㄴ', 'ㅁㅜㄴㅇㅡㄹ', 'ㄷㅏㄷㅇㅏㅆㄱㅗ', 'ㅇㅣㄹㅈㅏㄹㅣㄴㅡㄴ', 'ㄱㅜㅎㅏㄱㅣ', 'ㅎㅣㅁㄷㅡㄹㅇㅓㅈㅕㅆ.'], ['NNG/JX', 'NNG/JKO', 'VV/EP/EC', 'NNG/JX', 'VV/ETN', 'VA/EC/VX+EP/NULL/SF', 'VA/EC/VX+EP/EF/SF'], ['ㄷㅏ'], [5])\n"
     ]
    }
   ],
   "source": [
    "print(prepro_beta_03('백화점은 문을 닫았고 일자리는 구하기 힘들어졌다.', lis_beta_ef, lis_tag_last, lis_end_2low, lis_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c30e03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_w,origin_t, origin_ind, cont_w, con_t, ending, i = prepro_beta_04('어디서 노세요?', lis_beta_ef, lis_tag_last, lis_end, lis_end_2low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dae6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_w[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffa0039b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ㅇㅓㄷㅣㅅㅓ', 'ㄴㅗ?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7a3709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅇㅓㄷㅣㅅㅓ', 'ㄴㅗ']\n",
      "['ㅅㅔㅇㅛ']\n",
      "['ㅇㅓㄷㅣㅅㅓ', 'ㄴㅗ']\n",
      "ㄹㅇㅏ\n",
      "ㄹㅇㅏ\n",
      "어디서 놀아?\n"
     ]
    }
   ],
   "source": [
    "######높임말 -> 반말\n",
    "#현재 만들어진 것은 EF만 잘라낼 것이다. \n",
    "#원래 ef사전에 mapping 되는 것을 찾아낸다.\n",
    "# EF_1 = {\n",
    "#     ['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']:['ㄷ','ㅏ'],\n",
    "#     ['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']:['ㄷ','ㅏ']\n",
    "# }\n",
    "#python dictionary로 접근\n",
    "#종결어미 처리\n",
    "EF = {\n",
    "    ###하십시오체###\n",
    "    #평서문\n",
    "    'ㅂㄴㅣㄷㅏ': 'ㄷㅏ',\n",
    "    'ㅅㅡㅂㄴㅣㄷㅏ':'special',\n",
    "    'ㅇㅗㄹㅅㅣㄷㅏ':'ㄷㅏ', #**\n",
    "    'ㅂㅈㅣㅇㅛ':'지', #**\n",
    "    #의문문\n",
    "    'ㅅㅡㅂㄴㅣㄲㅏ':'special',\n",
    "    'ㅅㅣㅂㄴㅣㄲㅏ':'special1', #EP+EF\n",
    "    #명령법\n",
    "    'ㅇㅡㅅㅔㅇㅛ': 'special',\n",
    "    'ㅅㅔㅇㅛ':'special1',\n",
    "    #청유법\n",
    "    \n",
    "    #명령인용법\n",
    "    \n",
    "    ###하오체###\n",
    "    \n",
    "    ###해요체###\n",
    "    'ㅇㅓㅇㅛ':'ㅇㅓ',\n",
    "    'ㅇㅏㅇㅛ':'ㅇㅏ',\n",
    "    \n",
    "}\n",
    "#'ㄹ'규칙 활용 -> ㄹ 규칙 활용이 일어나는 동사들을 최대한 모아두고, 만약 하나의 단어에 여러 의미가 담긴다면?\n",
    "EF_SaeYo_R= {\n",
    "    'ㄱㅜ':'ㄹ',\n",
    "    'ㄴㅗ':'ㄹ',\n",
    "    'ㄴㅏ':'ㄹ',\n",
    "    'ㄷㅗ':'ㄹ',\n",
    "    'ㄷㅡ':'ㄹ',\n",
    "    'ㄷㅏ':'ㄹ',\n",
    "    'ㄷㅜ':'ㄹ',\n",
    "    'ㅂㅜ':'ㄹ',\n",
    "    'ㄲㅗ':'ㄹ',\n",
    "    'ㅁㅣ':'ㄹ',\n",
    "    'ㅁㅜ':'ㄹ',\n",
    "    #'ㅂㅗㅍㅜ':'ㄹ', #error predicate 수정\n",
    "    'ㅂㅜ':'ㄹ',\n",
    "    'ㅅㅡ':'ㄹ',\n",
    "    'ㄸㅓ':'ㄹ',\n",
    "    \n",
    "}\n",
    "\n",
    "####EXAMPLE####\n",
    "tag = 'ㅅㅔㅇㅛ'\n",
    "# sentence = ['ㄱㅡㄴㅡㄴ', 'ㅅㅏㄴㅇㅡㄹ', 'ㅇㅗㄹㅡ']\n",
    "# tagList = ['NP/JX', 'NNG/JKO', 'VV/']\n",
    "\n",
    "# tag2 = 'ㅅㅔㅇㅛ'\n",
    "# sentence2 = ['ㄱㅡㄴㅡㄴ', 'ㅂㅐㄹㄱㅗㅍㅡ']\n",
    "# tagList2 = ['NP/JX', 'VA/']\n",
    "\n",
    "####EXAMPLE####\n",
    "\n",
    "## 'ㅏ', 'ㅗ' 처리\n",
    "def convertSpecialCase_AhOh(sentence):\n",
    "    #print(sentence[-1][-2:])\n",
    "    print(sentence)\n",
    "    ## 수정할 필요 있음!\n",
    "    if sentence[-1][-2:] == 'ㅍㅡ' or sentence[-1][-2:] == 'ㅃㅡ':\n",
    "        if sentence[-1][-4:-2].find('ㅏ') !=-1 or sentence[-1][-4:-2].find('ㅗ')!=-1:\n",
    "            return 'ㅏ'\n",
    "        else:\n",
    "            return 'ㅓ'\n",
    "    elif sentence[-1][-2:].find('ㅏ') !=-1 or sentence[-1][-2:].find('ㅗ') !=-1:\n",
    "        return 'ㅇㅏ'\n",
    "    else:\n",
    "        return 'ㅇㅓ'\n",
    "\n",
    "def convertSpecialCase_SaeYo(sentence, tag):\n",
    "    result = ''\n",
    "    end_EF=''\n",
    "    final=''\n",
    "    predicate = sentence[-1][-2:]\n",
    "    #print(predicate)\n",
    "    # 'ㄹ'규칙 활용\n",
    "    if predicate in EF_SaeYo_R:\n",
    "        result= EF_SaeYo_R[predicate]\n",
    "        #sentence[-1] += result\n",
    "        ##'아' 또는 '어' 로 처리\n",
    "        end_EF = convertSpecialCase_AhOh(sentence)\n",
    "        #sentence.append(end_EF)\n",
    "        final = result +end_EF\n",
    "        print(final)\n",
    "    #'르' 불규칙 활용\n",
    "    elif predicate =='ㄹㅡ':\n",
    "        # 용언 종성에 ㄹ이 있다면\n",
    "        sentence[-1] = sentence[-1].replace('ㄹㅡ','')\n",
    "        end_EF = convertSpecialCase_AhOh(sentence)\n",
    "        end_EF = end_EF[-1]\n",
    "        if sentence[-1].find('ㄹ') != -1:\n",
    "            final = 'ㄹ'+end_EF\n",
    "        else:\n",
    "            final  = 'ㄹㄹ'+end_EF\n",
    "        \n",
    "    #'우' 불규칙 활용\n",
    "    # '푸'를 제외한 다른 'ㅜ'는 'ㅓ'와 결합\n",
    "    elif predicate.find('ㅍㅜ') !=-1:\n",
    "        #sentence[-1] = sentence[-1].replace('ㅜ','ㅓ')\n",
    "        sentence[-1] = sentence[-1].replace('ㅜ','')\n",
    "        final = 'ㅓ'\n",
    "        #final = sentence[-1][-1:]\n",
    "    #'오' 불규칙 활용(고려하지 않을 수 있음)\n",
    "    #'하' 불규칙 활용\n",
    "    elif predicate.find('ㅎㅏ') !=-1:\n",
    "        #sentence[-1] = sentence[-1].replace('ㅏ','ㅐ')\n",
    "        sentence[-1] = sentence[-1].replace('ㅏ','')\n",
    "        final = 'ㅐ'\n",
    "    #활용이 안되었던 용언 처리\n",
    "    else:\n",
    "        if predicate.find('ㅡ') !=-1:\n",
    "            end_EF = convertSpecialCase_AhOh(sentence)\n",
    "            #sentence[-1] = sentence[-1].replace('ㅡ',end_EF)\n",
    "            sentence[-1] = sentence[-1].replace('ㅡ','')\n",
    "            final = end_EF[-1]\n",
    "        ## 수정할 필요 있음!!\n",
    "        elif predicate.find('ㅗ') !=-1:\n",
    "            #sentence[-1] = sentence[-1].replace('ㅗ','ㅘ')\n",
    "            sentence[-1] = sentence[-1].replace('ㅗ','')\n",
    "            final = 'ㅘ'\n",
    "        elif predicate.find('ㅜ') !=-1:\n",
    "            #sentence[-1] = sentence[-1].replace('ㅜ','ㅝ')\n",
    "            sentence[-1] = sentence[-1].replace('ㅜ','') \n",
    "            final = 'ㅝ'\n",
    "        elif predicate.find('ㅣ') !=-1:\n",
    "            #sentence[-1] = sentence[-1].replace('ㅣ','ㅕ')\n",
    "            sentence[-1] = sentence[-1].replace('ㅣ','')\n",
    "            final = 'ㅕ'\n",
    "        else:\n",
    "            final = convertSpecialCase_AhOh(sentence)\n",
    "            #sentence = sentence.append(final)\n",
    "            if  predicate.find('ㅏ') !=-1:\n",
    "                final = ''\n",
    "                return final\n",
    "            return final\n",
    "    return final\n",
    "    \n",
    "\n",
    "##if Verb & adjective\n",
    "def treatVerb_Adjective(sentence, ending):\n",
    "    re_value =''\n",
    "    for key in EF:\n",
    "        if ending == key:\n",
    "            re_value = EF[key]\n",
    "            #습니다, 나요, 으세요 case\n",
    "            if re_value == 'special':\n",
    "                re_value = convertSpecialCase_AhOh(sentence)\n",
    "                #ㅗ,ㅜ 이면 ㅘ, ㅝ로 결합할 것\n",
    "                #print(re_value)\n",
    "            #-세요\n",
    "            elif re_value == 'special1':\n",
    "                #print(sentence)\n",
    "                re_value = convertSpecialCase_SaeYo(sentence, ending)\n",
    "    # print(sentence)\n",
    "    return re_value\n",
    "\n",
    "punc = cont_w[-1][-1]\n",
    "cont_w[-1] = cont_w[-1][:-1]\n",
    "print(cont_w)\n",
    "print(ending)\n",
    "end = ''.join(ending)\n",
    "re_value = treatVerb_Adjective(cont_w, end)\n",
    "print(re_value)\n",
    "cont_w[-1] += re_value\n",
    "#print(sentence)\n",
    "\n",
    "res_space = []\n",
    "for i in range(len(cont_w)):\n",
    "    res_space.append(cont_w[i])\n",
    "    if i==len(cont_w)-1:\n",
    "        break\n",
    "    res_space.append(' ')\n",
    "jam_q = Jamodealer(res_space)\n",
    "\n",
    "result = jam_q.make_one()\n",
    "print(result + punc)\n",
    "#VX는 따로 처리해야 함\n",
    "\n",
    "# # key_list[0]\n",
    "# def ChangeMorphemeToLow(tag, sentence):\n",
    "#     #for문으로 ef list 탐색 후 일치한다면 변환 후 return \n",
    "#     #key_list = EF_1.keys()\n",
    "#     for key in EF:\n",
    "#         if tag == key:\n",
    "#             if EF\n",
    "#             tag = EF_1[key]\n",
    "#     print(tag)\n",
    "#     return tag\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0df23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5eade5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3be99409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_an(stc, tag, ex):\n",
    "    \n",
    "    ind_point = -1\n",
    "    point = ''\n",
    "\n",
    "#     for i in P_LIST:\n",
    "#         if stc.find(i) !=-1:\n",
    "#             point = i\n",
    "#             break\n",
    "            \n",
    "    for i in range(len(stc)):\n",
    "        if stc[i] in P_LIST:\n",
    "            point = stc[i]\n",
    "            break\n",
    "            \n",
    "    if point in P_LIST:\n",
    "        ind_point = stc.index(point)\n",
    "    \n",
    "    r_word = ''\n",
    "    r_pun = ''\n",
    "    \n",
    "    if ind_point!=-1:\n",
    "        r_word = stc[:ind_point]\n",
    "        r_pun = stc[ind_point:]\n",
    "    else:\n",
    "        r_word = stc\n",
    "    \n",
    "    if ex=='ㄹㅏ':\n",
    "        return r_word+'ㅇㅛ'+r_pun\n",
    "    elif ex=='ㄷㅏㄷㅓㄹㅏ':\n",
    "        return r_word+'ㄷㅐㅇㅛ'+r_pun\n",
    "    elif ex=='ㄷㅓㄹㅏ':\n",
    "        wd = ''\n",
    "        if 'ㄷㅏ' in r_word:\n",
    "#             print('dd')\n",
    "            return r_word[:-1]+'ㅐㅇㅛ'+r_pun\n",
    "        if r_word[-1] in jongsung_list:\n",
    "            wd = r_word[-2]\n",
    "        else:\n",
    "            wd = r_word[-1]\n",
    "        if wd=='ㅗ':\n",
    "            return r_word+'ㅏㅇㅛ'+r_pun\n",
    "        elif wd=='ㅜ':\n",
    "            return r_word+'ㅓㅇㅛ'+r_pun\n",
    "        elif wd=='ㅏ':\n",
    "            return r_word+'ㅇㅏㅇㅛ'+r_pun\n",
    "        else:\n",
    "            return r_word+'ㅇㅓㅇㅛ'+r_pun\n",
    "    elif ex=='ㄴㅣ' or ex =='ㄴㅡㄴㄱㅏ' or ex =='ㅇㅡㄴㄱㅏ':\n",
    "        return r_word+'ㄴㅏㅇㅛ'+r_pun\n",
    "    elif ex=='ㅇㅑ':\n",
    "        return r_word+'ㅇㅔㅇㅛ'+r_pun\n",
    "#     elif ex=='ㄷㅓㄹㅏ':\n",
    "#         if 'ㄷㅏ' in stc:\n",
    "#             return stc[:-1]+'ㅔㅇㅛ'\n",
    "#         return stc+'ㄷㅔㅇㅛ'\n",
    "    elif ex=='ㅈㅣ':\n",
    "        return r_word+'ㅈㅛ'+r_pun\n",
    "    else:\n",
    "        return r_word+ex+'ㅇㅛ'+r_pun\n",
    "    \n",
    "def convert_da(stc, tag, ex):\n",
    "    #print(tag)\n",
    "    isVcp = tag[-6:]\n",
    "#     print(isVcp)\n",
    "    ind_point = -1\n",
    "    point = ''\n",
    "    for i in range(len(stc)):\n",
    "        if stc[i] in P_LIST:\n",
    "            point = stc[i]\n",
    "            break\n",
    "            \n",
    "    if point in P_LIST:\n",
    "        ind_point = stc.index(point)\n",
    "    \n",
    "    r_word = ''\n",
    "    r_pun = ''\n",
    "    \n",
    "    if ind_point!=-1:\n",
    "        r_word = stc[:ind_point]\n",
    "        r_pun = stc[ind_point:]\n",
    "    else:\n",
    "        r_word = stc\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        jongsung = r_word[-1]\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return ex\n",
    "        \n",
    "    if jongsung in jongsung_list:\n",
    "        final = r_word +'ㅅㅡㅂㄴㅣㄷㅏ'+r_pun\n",
    "    else:\n",
    "        if isVcp.find('VCP') != -1:\n",
    "            print('what the')\n",
    "            final = r_word +'ㅇㅣㅂㄴㅣㄷㅏ'+r_pun\n",
    "        else:\n",
    "            final = r_word +'ㅂㄴㅣㄷㅏ'+r_pun\n",
    "    #print(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3977a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Changer(object):\n",
    "    \n",
    "    def make_end_h(self, stc, tag, ex):\n",
    "\n",
    "#         print(ex)\n",
    "        if 'ㄷㅏ'== ex[-2:]:\n",
    "            return convert_da(stc, tag, ex)\n",
    "        else:\n",
    "            return convert_an(stc, tag, ex)\n",
    "    \n",
    "\n",
    "    \n",
    "    def to_high(self, input):\n",
    "        result = input\n",
    "        space_list = rememberSpace(input,' ')\n",
    "        \n",
    "        test_w, test_t = to2lists(result)\n",
    "        pre_w, pre_t, pre_ind = prepro(result)\n",
    "        \n",
    "        data_w, data_t, lis_i, lis_w, lis_t, off_word, lis_target_ind = prepro_beta_04(result, lis_beta_ef, lis_tag_last, lis_end_2low, lis_end)\n",
    "\n",
    "        \n",
    "#         lis_w, lis_t, lis_i, w_last, t_last, off_word, lis_normal, lis_target_ind = prepro_after(result, lis_end_2low)\n",
    "#         space_location = convertSpace(space_list, pre_w)\n",
    "        space_location = convertSpace(space_list, data_w)\n",
    "#         lis_target_final = []\n",
    "        \n",
    "        if len(lis_target_ind)!=0:\n",
    "\n",
    "            jam = Jamodealer(data_w)\n",
    "\n",
    "            for i in range(len(lis_target_ind)):\n",
    "#                 print(lis_target_ind)\n",
    "#                 print(i)\n",
    "#                 print(lis_w[10])\n",
    "#                 print(lis_t[10])\n",
    "#                 print(off_word)\n",
    "#                 print(lis_target_ind[0])\n",
    "                new_end = self.make_end_h(lis_w[lis_target_ind[i]], lis_t[lis_target_ind[i]], off_word[i])\n",
    "                jam.jamo[lis_target_ind[i]] = new_end\n",
    "            \n",
    "            \n",
    "#             jam.jamo.append(w_last)\n",
    "            union(space_location, jam.jamo)\n",
    "            return jam.make_one()\n",
    "\n",
    "        return input\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    def processText(self,stc):\n",
    "        result = stc\n",
    "        \n",
    "        flag = 0\n",
    "        if result[-1]=='\\n':\n",
    "            result = result.replace('\\n','')\n",
    "        \n",
    "        num = 0\n",
    "        while 1:\n",
    "            if result[-1-num]!=' ':\n",
    "                break\n",
    "            else:\n",
    "                num = num+1\n",
    "                \n",
    "        \n",
    "                \n",
    "        if num==0:\n",
    "            rere = result\n",
    "        else:\n",
    "            rere = result[:-num]\n",
    "            \n",
    "        \n",
    "        r_pun = ''\n",
    "        r_word = rere\n",
    "        while True:\n",
    "            if r_word[-1] in SV_LIST:\n",
    "                r_pun = r_pun+r_word[-1]\n",
    "                r_word = r_word[:-1]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        num_space = 0\n",
    "        for i in r_word:\n",
    "            if i==' ':\n",
    "                num_space = num_space+1\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        if num_space!=0:\n",
    "            r_word = r_word[num_space:]\n",
    "\n",
    "#         cc = ch.processText(line)\n",
    "    \n",
    "        plus = ''\n",
    "        for s in range(num_space):\n",
    "            plus = plus+' '\n",
    "    \n",
    "        if r_word[-1] =='?' or r_word[-1] =='.' or r_word[-1] =='!' or r_word[-1] =='\\\"':\n",
    "            r_word = r_word\n",
    "        else:\n",
    "            r_word = r_word+'.'\n",
    "            flag = 1\n",
    "        \n",
    "        res = self.to_high(r_word)\n",
    "        \n",
    "        r_word = plus+r_word\n",
    "        res = plus+res\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if r_word[-1] =='?' or r_word[-1] =='.' or r_word[-1] =='!' or r_word[-1] =='\\\"':\n",
    "#             r_word = r_word\n",
    "#         else:\n",
    "#             r_word = r_word+'.'\n",
    "#             flag = 1\n",
    "        \n",
    "#         res = self.to_high(r_word)\n",
    "        \n",
    "        if flag ==1:\n",
    "            res = res[:-1]\n",
    "        \n",
    "        #spacing = Spacing()\n",
    "        #res = spacing(res)\n",
    "        return res+r_pun[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36637238",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = Changer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0fafb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9시? 9시 15분에 병원 예약이 있는데요. 좀 태워다 줄 수 있겠죠?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.to_high('9시? 9시 15분에 병원 예약이 있는데. 좀 태워다 줄 수 있겠지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b76750ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './hgu_clean.kr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e3c9f2b24eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./hgu_clean.kr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./new_high_01.kr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './hgu_clean.kr'"
     ]
    }
   ],
   "source": [
    "f0 = open('./hgu_clean.kr', 'r', encoding = 'utf-8')\n",
    "f1 = open('./new_high_01.kr', 'w',encoding = 'utf-8')\n",
    "\n",
    "flag = 0\n",
    "\n",
    "num = 0\n",
    "number = 0\n",
    "ch = Changer()\n",
    "\n",
    "while True:\n",
    "    flag = 0\n",
    "    line = f0.readline()\n",
    "    if not line: break\n",
    "    if line[-1]=='\\n':\n",
    "        line = line.replace('\\n','')\n",
    "    \n",
    "    num_space = 0\n",
    "    for i in line:\n",
    "        if i==' ':\n",
    "            num_space = num_space+1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if num_space!=0:\n",
    "        line = line[num_space:]\n",
    "\n",
    "    cc = ch.processText(line)\n",
    "    \n",
    "    plus = ''\n",
    "    for s in range(num_space):\n",
    "        plus = plus+' '\n",
    "    \n",
    "    line = plus+line\n",
    "    cc = plus+cc\n",
    "    \n",
    "    if number<100000:\n",
    "        if line!=cc:\n",
    "            f1.write(line)\n",
    "            f1.write('\\n')\n",
    "            f1.write(cc)\n",
    "            f1.write('\\n\\n')\n",
    "        num = num+1\n",
    "    else:\n",
    "        break\n",
    "    print(number)\n",
    "    number = number+1\n",
    "f0.close()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291d4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe84cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bce81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05197e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "35d9c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VX+EP+EC/SF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'걱정 말아요. 내가 비디오 녹화해 놨으니까요.'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.processText('걱정 말아요. 내가 비디오 녹화해 놨으니까.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eae5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b33182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "#from eunjeon import Mecab\n",
    "from konlpy.tag import Mecab\n",
    "from khaiii import KhaiiiApi\n",
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "693e64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_dict = [\n",
    "    \n",
    "    ['ㅏㅣ','ㅐ'], ['ㅑㅣ','ㅒ'], ['ㅓㅣ','ㅔ'],\n",
    "    ['ㅕㅣ','ㅖ'], ['ㅗㅣ','ㅚ'], ['ㅗㅐ','ㅙ'],\n",
    "    ['ㅜㅓ','ㅝ'], ['ㅜㅔ','ㅞ'], ['ㅡㅣ','ㅢ'],\n",
    "    ['ㅣㅏ','ㅑ'], ['ㅣㅓ','ㅕ'], ['ㅣㅗ','ㅛ'],\n",
    "    ['ㅣㅜ','ㅠ'], ['ㅡㅓ','ㅓ'], ['ㅗㅏ','ㅘ']\n",
    "    \n",
    "]\n",
    "\n",
    "jongsung_list = [ 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "\n",
    "#lis_beta = ['EP+EF', 'VCP+EF', 'B+EF', 'B+EP+EF', 'B+VCP+EF', 'EF','EP']\n",
    "\n",
    "lis_beta = ['EP+EF', 'EF', 'B+EF', 'B+EP+EF']\n",
    "\n",
    "#어말을 처리해 주기 위한 것으로, 나중에 EC등이 필요해 진다면 이 부분에 EC 등을 집어넣어준다. 참고로 말하자면 이는 마지막에 위치해야한다.\n",
    "#특이 바로 밑의 이 부분은 형태소 태그가 이 리스트 안의 것과 일치하는 경우 단순 삭제를 하는 것이고\n",
    "lis_beta_ef = ['EP+EP+EF', 'EP+EF', 'EF', 'UNKNOWN']\n",
    "\n",
    "lis_beta_ef_h = ['EF', 'UNKNOWN']\n",
    "\n",
    "#이 부분 같은 경우는 마지막에 오는 것을 처리하는 것으로 단독으로만 들어가는게 좋겠지?\n",
    "lis_tag_last = ['EF', 'UNKNOWN']\n",
    "\n",
    "lis_end = [\n",
    "    \n",
    "    'ㅅㅡㅂㄴㅣㄷㅏ',\n",
    "    'ㅂㄴㅣㄷㅏ', 'ㄴㅣㄷㅏ', 'ㅂㅅㅣㄷㅏ', 'ㅅㅣㄷㅏ', 'ㄹㄹㅐㅇㅛ',\n",
    "    'ㅅㅔㅇㅛ', 'ㄷㅔㅇㅛ', 'ㅇㅔㅇㅛ', 'ㅇㅖㅇㅛ', 'ㄴㅏㅇㅛ', 'ㅇㅡㄹㄲㅏㅇㅛ', 'ㅇㅣㄹㄲㅏㅇㅛ', 'ㄹㄲㅏㅇㅛ', 'ㅇㅡㄴㄱㅏㅇㅛ', 'ㅇㅣㄴㄱㅏㅇㅛ','ㅇㅛ',\n",
    "    'ㅈㅛ',\n",
    "    'ㅅㅣㅂㅅㅣㅇㅗ', 'ㅅㅣㅇㅗ', 'ㅇㅗ',\n",
    "    'ㅂㄴㅣㄲㅏ',  \n",
    "    \n",
    "]\n",
    "\n",
    "lis_end_2low = [\n",
    "    \n",
    "    'ㄷㅓㄹㅏ','ㄴㄷㅏ', 'ㅆㄷㅏ', 'ㄹㅗㄷㅏ', 'ㄷㅏ', 'ㄱㅔ', 'ㅈㅣ', 'ㅈㅏ', \n",
    "    'ㄹㅏ',\n",
    "    'ㅇㅑ', \n",
    "    'ㄴㅣㄲㅏ', \n",
    "    'ㄲㅏ', \n",
    "    'ㄴㅣ', \n",
    "    'ㅇㅏ', \n",
    "    'ㄷㅔ', \n",
    "    \n",
    "]\n",
    "\n",
    "lis_wk = [\n",
    "    \n",
    "    ['ㄱㅖ', 'ㅇㅣㅆㅇㅡ'], ['ㅈㅜㅁㅜ','ㅈㅏ'], ['ㅈㅏㅂㅅㅜ','ㅁㅓㄱㅇㅡ']\n",
    "    \n",
    "]\n",
    "\n",
    "# lis_end_2low = [\n",
    "    \n",
    "#     'ㄷㅓㄹㅏ','ㄴㄷㅏ', 'ㅆㄷㅏ', 'ㄷㅏ', \n",
    "#     'ㄹㅏ',\n",
    "#     'ㅇㅑ', \n",
    "    \n",
    "# ]\n",
    "\n",
    "P_LIST = ['.', '?', '!', '\\'', '\\\"', 'ᆞ', 'ᆢ', 'ㆍ',  '”', '’',')', '(', ',', '”']\n",
    "\n",
    "SV_LIST = ['\\'', '\\\"', ':', ';']\n",
    "\n",
    "lis_plus = [\n",
    "    \n",
    "    'EP', 'VCP', \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7875687",
   "metadata": {},
   "outputs": [],
   "source": [
    "mec = Mecab()\n",
    "khai = KhaiiiApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8a0be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_h(input, lis_end_h, lis_end_l):\n",
    "    for i in lis_end_h:\n",
    "        if len(input)>=len(i):\n",
    "            if input[-len(i):]==i:\n",
    "                return 1\n",
    "            \n",
    "    for i in lis_end_l:\n",
    "        if len(input)>=len(i):\n",
    "            if input[-len(i):]==i:\n",
    "                return 0\n",
    "            \n",
    "    return -1\n",
    "\n",
    "def unite(input, dict):\n",
    "    for i in dict:\n",
    "        input = re.sub(i[0],i[1],input)\n",
    "    return input\n",
    "    \n",
    "## 자모 단위로 문장을 나누고 합칠 때 쓰는 class ##\n",
    "class Jamodealer:\n",
    "    jamo = []\n",
    "    pp = ''\n",
    "    #각 단어들을 받아와서 자모단위로 나눈다.\n",
    "    def __init__(self,lis_word):\n",
    "    \n",
    "        self.jamo = []\n",
    "        for i in lis_word:\n",
    "            self.jamo.append(split_syllables(i))\n",
    "    \n",
    "    ##사전에서 변환된 자모단위로 분리된 문장을 합칠 때 쓰는 함수이다.     \n",
    "    def make_one(self):\n",
    "        #list 형태로 저장된 자모들의 집합을 하나의 string pp에 저장한다. \n",
    "        self.pp = ''\n",
    "        for i in self.jamo:\n",
    "             self.pp= self.pp+i\n",
    "        ##종성과 종성을 합쳐야 하는 경우가 있다면 합친다.        \n",
    "        self.pp = unite(self.pp, con_dict)\n",
    "        \n",
    "        #자모 단위의 string에서 자모 단위로 사전을 만들고 거기에 index를 부여한다.        \n",
    "        chars = list(set(self.pp))\n",
    "        char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "        ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "        #자모 단위로 분리되었던 문장을 다시 하나로 합친다.\n",
    "        jamo_numbers = [char_to_ix[x] for x in self.pp]\n",
    "        restored_jamo = ''.join([ix_to_char[x] for x in jamo_numbers])\n",
    "        #합쳐진 문장을 return 한다.\n",
    "        restored_text = join_jamos(restored_jamo)\n",
    "        return restored_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b30f4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_ch01(input, lis_ef, tag_last, lis_w_last, lis_w_last_not):\n",
    "    \n",
    "    lis_res_word = []\n",
    "    \n",
    "    lis_input = input.split()\n",
    "    lis_word = []\n",
    "    lis_tag = []\n",
    "    lis_last_word = []\n",
    "    lis_ind = []\n",
    "    \n",
    "    lis_result = []\n",
    "    \n",
    "    for i in range(len(lis_input)):\n",
    "        ele_w = []\n",
    "        ele_t = []\n",
    "        \n",
    "        an = mec.pos(lis_input[i])\n",
    "        for j in range(len(an)):\n",
    "            ele_w.append(an[j][0])\n",
    "            ele_t.append(an[j][1])\n",
    "        elem_w = ' '.join(ele_w)\n",
    "        elem_t = '/'.join(ele_t)\n",
    "        \n",
    "        jam_pre = Jamodealer(elem_w)\n",
    "        lis_word.append(''.join(jam_pre.jamo))\n",
    "        lis_tag.append(elem_t)\n",
    "    \n",
    "    for i in range(len(lis_tag)):\n",
    "        \n",
    "        if 'EF/SF' in lis_tag[i] or 'EF/SV' in lis_tag[i]:\n",
    "            elemen_t = lis_tag[i].split('/')\n",
    "            elemen_w = lis_word[i].split(' ')\n",
    "            flag = 0\n",
    "            \n",
    "            \n",
    "            for j in range(len(elemen_t)):\n",
    "\n",
    "                flag_end = detect_h(elemen_w[j], lis_w_last_not, lis_w_last)\n",
    "\n",
    "                \n",
    "                if flag_end == 0 and 'EF' in elemen_t[j]:\n",
    "                    \n",
    "                    for jam in lis_w_last:\n",
    "                        \n",
    "                        if len(elemen_w[j])>=len(jam):\n",
    "                            \n",
    "                            if elemen_w[j][-len(jam):]==jam:\n",
    "                                \n",
    "                                \n",
    "                                lis_ind.append(i)\n",
    "                                lis_last_word.append(jam)\n",
    "                                elemen_w[j] = elemen_w[j][:-len(jam)]\n",
    "                                \n",
    "                                break\n",
    "                                \n",
    "            res_w = ''.join(elemen_w)\n",
    "            lis_result.append(res_w)\n",
    "                                \n",
    "        else:\n",
    "            \n",
    "            rere = lis_word[i].split(' ')\n",
    "            \n",
    "            resres = ''.join(rere)\n",
    "            \n",
    "            lis_result.append(resres)\n",
    "            \n",
    "            \n",
    "    return lis_result, lis_tag, lis_ind, lis_last_word\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60e7f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['ㅇㅣㅂㅓㄴㅈㅜ', 'ㄱㅡㅁㅇㅛㅇㅣㄹㅇㅔ', 'ㄱㅡㄱㅗㅅㅇㅔ', 'ㄱㅏㄹ', 'ㄱㅓㅅㅇㅣ.'], ['NNG/NNG', 'NNG/JKB', 'NP/JKB', 'VV+ETM', 'NNB/VCP/EF/SF'], [4], ['ㄷㅏ'])\n"
     ]
    }
   ],
   "source": [
    "print(prepro_ch01('이번주 금요일에 그곳에 갈 것이다.', lis_beta_ef, lis_tag_last, lis_end_2low, lis_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "616ada45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatSF(stc, ex):\n",
    "    ind_point = -1\n",
    "    point = ''          \n",
    "    for i in range(len(stc)):\n",
    "        if stc[i] in P_LIST:\n",
    "            point = stc[i]\n",
    "            break\n",
    "            \n",
    "    if point in P_LIST:\n",
    "        ind_point = stc.index(point)\n",
    "    \n",
    "    r_word = ''\n",
    "    r_pun = ''\n",
    "    \n",
    "    if ind_point!=-1:\n",
    "        r_word = stc[:ind_point]\n",
    "        r_pun = stc[ind_point:]\n",
    "    else:\n",
    "        r_word = stc\n",
    "    return r_word+ex+r_pun\n",
    "\n",
    "def convert_not(stc, tag, ex):\n",
    "    return treatSF(stc, ex)\n",
    "\n",
    "def convert_an(stc, tag, ex):\n",
    "    \n",
    "    ind_point = -1\n",
    "    point = ''\n",
    "            \n",
    "    for i in range(len(stc)):\n",
    "        if stc[len(stc) - i] in P_LIST:\n",
    "            point = stc[len(stc) - i]\n",
    "            break\n",
    "            \n",
    "    if point in P_LIST:\n",
    "        ind_point = stc.index(point)\n",
    "    \n",
    "    r_word = ''\n",
    "    r_pun = ''\n",
    "    \n",
    "    if ind_point!=-1:\n",
    "        r_word = stc[:ind_point]\n",
    "        r_pun = stc[ind_point:]\n",
    "    else:\n",
    "        r_word = stc\n",
    "    \n",
    "    if ex=='ㄹㅏ':\n",
    "        \n",
    "        if len(r_word)!=0:\n",
    "            if 'ㅗ'==stc[-2]:\n",
    "                return r_word+'ㅏㅇㅛ'+r_pun\n",
    "            elif 'ㅎㅏ'==stc[-3:-1]:\n",
    "                return r_word+'ㅣㅇㅛ'+r_pun\n",
    "            elif 'ㄷㅏㄹ' in stc:\n",
    "                return r_word+'ㄹㅏ'+r_pun\n",
    "                if 'VA' not in tag:\n",
    "                    return r_word+'ㄹㅏㅇㅛ'+r_pun\n",
    "                return r_word[:-3]+'ㅈㅜㅅㅔㅇㅛ'+r_pun\n",
    "            elif 'ㅗㄹ' == r_word[-2:]:\n",
    "                return r_word+'ㄹㅏㅇㅛ'+r_pun\n",
    "            else:\n",
    "\n",
    "                return r_word+'ㅇㅛ'+r_pun\n",
    "        else:\n",
    "            return r_word+ex+r_pun\n",
    "\n",
    "        #return r_word+'ㅇㅛ'+r_pun\n",
    "    elif ex=='ㄱㅜㄴㅏ':\n",
    "        return r_word+'ㄱㅜㄴㅇㅛ'+r_pun\n",
    "    elif ex=='ㅈㅏㄶㄴㅣ':\n",
    "        return r_word+'ㅈㅏㄶㅇㅏㅇㅛ'+r_pun\n",
    "    elif ex=='ㄱㅔ':###############################\n",
    "        print(r_word)\n",
    "        if 2<=len(r_word) and r_word[-2:]=='ㅎㅏ':\n",
    "            return r_word+'ㅣㅇㅛ'+r_pun\n",
    "        elif 2<=len(r_word) and r_word[-2:]=='ㅅㅣ':\n",
    "            return r_word+'ㅓㅇㅛ'+r_pun\n",
    "        return r_word+'ㄱㅔㅇㅛ'+r_pun\n",
    "        \n",
    "    elif ex=='ㅇㅓㄹㅏ':\n",
    "        return r_word+'ㅇㅓㅇㅛ'+r_pun\n",
    "    elif ex=='ㅇㅏㄹㅏ':\n",
    "        return r_word+'ㅇㅏㅇㅛ'+r_pun\n",
    "    elif ex=='ㄴㅗㄹㅏ':\n",
    "        if stc[-3:-1]=='ㅎㅏ':\n",
    "            return r_word+'ㅣㅇㅛ'+r_pun\n",
    "        else:\n",
    "            return r_word+'ㅇㅓㅇㅛ'+r_pun\n",
    "    elif ex=='ㄷㅏㄷㅓㄹㅏ':\n",
    "        return r_word+'ㄷㅐㅇㅛ'+r_pun\n",
    "    elif ex=='ㄷㅓㄹㅏ':\n",
    "        wd = ''\n",
    "        if 'ㄷㅏ' in r_word:\n",
    "#             print('dd')\n",
    "            return r_word[:-1]+'ㅐㅇㅛ'+r_pun\n",
    "        if r_word[-1] in jongsung_list:\n",
    "            wd = r_word[-2]\n",
    "        else:\n",
    "            wd = r_word[-1]\n",
    "        if wd=='ㅗ':\n",
    "            return r_word+'ㅏㅇㅛ'+r_pun\n",
    "        elif wd=='ㅜ':\n",
    "            return r_word+'ㅓㅇㅛ'+r_pun\n",
    "        elif wd=='ㅏ':\n",
    "            return r_word+'ㅇㅏㅇㅛ'+r_pun\n",
    "        else:\n",
    "            return r_word+'ㅇㅓㅇㅛ'+r_pun\n",
    "    elif ex=='ㄴㅣ' or ex =='ㄴㅡㄴㄱㅏ' or ex =='ㅇㅡㄴㄱㅏ':\n",
    "        \n",
    "        isVcp = tag[-11:-3]\n",
    "        \n",
    "        if isVcp =='VCP' or isVcp =='/VCP' or isVcp =='NNG/VCP':\n",
    "            return r_word + 'ㅇㅖㅇㅛ' + r_pun\n",
    "        elif isVcp == 'VCP/NULL':\n",
    "            return r_word + 'ㅇㅔㅇㅛ' + r_pun\n",
    "        \n",
    "        \n",
    "        if ex=='ㄴㅣ' and stc[-3:-1]=='ㅌㅔ':\n",
    "            return r_word+'ㄴㅣㅇㅛ'+r_pun\n",
    "        \n",
    "        if ex=='ㄴㅣ' and 'NNG' in tag:\n",
    "            return r_word+'ㅇㅖㅇㅛ'+r_pun\n",
    "        \n",
    "        return r_word+'ㄴㅏㅇㅛ'+r_pun\n",
    "    elif ex=='ㅇㅑ':\n",
    "        return r_word+'ㅇㅔㅇㅛ'+r_pun\n",
    "#     elif ex=='ㄷㅓㄹㅏ':\n",
    "#         if 'ㄷㅏ' in stc:\n",
    "#             return stc[:-1]+'ㅔㅇㅛ'\n",
    "#         return stc+'ㄷㅔㅇㅛ'\n",
    "    elif ex=='ㅈㅣ':\n",
    "        return r_word+'ㅈㅛ'+r_pun\n",
    "    elif ex=='ㅈㅏ':\n",
    "        return r_word+'ㅈㅛ'+r_pun\n",
    "    else:\n",
    "        return r_word+ex+'ㅇㅛ'+r_pun\n",
    "    \n",
    "def convert_da(stc, tag, ex):\n",
    "    #print(tag)\n",
    "    if 'UNKNOWN/' in tag:\n",
    "        isVcp = tag[-17:]\n",
    "    else:\n",
    "        isVcp = tag[-9:]\n",
    "\n",
    "    isETM = tag[-12:]\n",
    "\n",
    "\n",
    "    ind_point = -1\n",
    "    point = ''\n",
    "\n",
    "    for i in range(len(stc)):\n",
    "        if len(stc)-i-1==0:\n",
    "            point = stc[0]\n",
    "            ind_pont = -1\n",
    "        if stc[len(stc) - i-1] not in P_LIST:\n",
    "            point = stc[len(stc) - i-1]\n",
    "            ind_point = len(stc)-i\n",
    "\n",
    "            break\n",
    "    \n",
    "#     print(ind_point)\n",
    "    \n",
    "#     if point in P_LIST:\n",
    "#         ind_point = stc.index(point)\n",
    "    \n",
    "    r_word = ''\n",
    "    r_pun = ''\n",
    "\n",
    "    if ind_point!=-1:\n",
    "        r_word = stc[:ind_point]\n",
    "        r_pun = stc[ind_point:]\n",
    "    else:\n",
    "        r_word = ''\n",
    "        r_pun = stc[0]\n",
    "    \n",
    "    try:\n",
    "        jongsung = r_word[-1]\n",
    "    \n",
    "    except:\n",
    "        return ex+r_pun\n",
    "        \n",
    "    if jongsung in jongsung_list:\n",
    "        if  isETM.find('+ETM') != -1:\n",
    "            r_word = r_word[:-1]\n",
    "            final = r_word +'ㅂㄴㅣㄷㅏ'+r_pun\n",
    "        else:\n",
    "            final = r_word +'ㅅㅡㅂㄴㅣㄷㅏ'+r_pun\n",
    "    else:\n",
    "        if isVcp.find('VCP') != -1:\n",
    "            if len(r_word)>=2:\n",
    "                if 'ㅇㅣ' in r_word:\n",
    "                    return r_word +'ㅂㄴㅣㄷㅏ'+r_pun\n",
    "            final = r_word +'ㅇㅣㅂㄴㅣㄷㅏ'+r_pun\n",
    "        elif 'SN/NULL' in tag:\n",
    "            final = r_word +'ㅇㅣㅂㄴㅣㄷㅏ'+r_pun\n",
    "        else:\n",
    "            final = r_word +'ㅂㄴㅣㄷㅏ'+r_pun\n",
    "    #print(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eb9ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Changer(object):\n",
    "    \n",
    "    def make_end_h(self, stc, tag, ex):\n",
    "\n",
    "#         print(ex)\n",
    "        if 'ㄷㅏ'== ex[-2:]:\n",
    "\n",
    "            return convert_da(stc, tag, ex)\n",
    "            #return convert_not(stc, tag, ex)\n",
    "        else:\n",
    "            return convert_not(stc, tag, ex)\n",
    "            #return convert_an(stc, tag, ex)\n",
    "\n",
    "    \n",
    "    def to_high(self, input):\n",
    "        \n",
    "        if '  ' in input:\n",
    "            return input\n",
    "        \n",
    "        result = input\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        lis_w, lis_t, lis_target_ind, off_word = prepro_ch01(result, lis_beta_ef, lis_tag_last, lis_end_2low, lis_end)\n",
    "\n",
    "        \n",
    "        if len(lis_target_ind)!=0:\n",
    "\n",
    "            for i in range(len(lis_target_ind)):\n",
    "\n",
    "                new_end = self.make_end_h(lis_w[lis_target_ind[i]], lis_t[lis_target_ind[i]], off_word[i])\n",
    "                lis_w[lis_target_ind[i]] = new_end\n",
    "            \n",
    "            \n",
    "#             jam.jamo.append(w_last)\n",
    "            \n",
    "            res = ' '.join(lis_w)\n",
    "            jam = Jamodealer(res)\n",
    "            \n",
    "            \n",
    "            return jam.make_one()\n",
    "\n",
    "        return input\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    def processText(self,stc):\n",
    "        result = stc\n",
    "        \n",
    "        flag = 0\n",
    "        if result[-1]=='\\n':\n",
    "            result = result.replace('\\n','')\n",
    "        \n",
    "        num = 0\n",
    "        while 1:\n",
    "            if result[-1-num]!=' ':\n",
    "                break\n",
    "            else:\n",
    "                num = num+1\n",
    "                \n",
    "        \n",
    "                \n",
    "        if num==0:\n",
    "            rere = result\n",
    "        else:\n",
    "            rere = result[:-num]\n",
    "            \n",
    "        \n",
    "        r_pun = ''\n",
    "        r_word = rere\n",
    "        while True:\n",
    "            if r_word[-1] in SV_LIST:\n",
    "                r_pun = r_pun+r_word[-1]\n",
    "                r_word = r_word[:-1]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        num_space = 0\n",
    "        for i in r_word:\n",
    "            if i==' ':\n",
    "                num_space = num_space+1\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        if num_space!=0:\n",
    "            r_word = r_word[num_space:]\n",
    "\n",
    "#         cc = ch.processText(line)\n",
    "    \n",
    "        plus = ''\n",
    "        for s in range(num_space):\n",
    "            plus = plus+' '\n",
    "    \n",
    "        if r_word[-1] =='?' or r_word[-1] =='.' or r_word[-1] =='!' or r_word[-1] =='\\\"':\n",
    "            r_word = r_word\n",
    "        else:\n",
    "            r_word = r_word+'.'\n",
    "            flag = 1\n",
    "            \n",
    "        try:\n",
    "            res = self.to_high(r_word)\n",
    "        except:\n",
    "            res = r_word\n",
    "            \n",
    "        r_word = plus+r_word\n",
    "        res = plus+res\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if r_word[-1] =='?' or r_word[-1] =='.' or r_word[-1] =='!' or r_word[-1] =='\\\"':\n",
    "#             r_word = r_word\n",
    "#         else:\n",
    "#             r_word = r_word+'.'\n",
    "#             flag = 1\n",
    "        \n",
    "#         res = self.to_high(r_word)\n",
    "        \n",
    "        if flag ==1:\n",
    "            res = res[:-1]\n",
    "        \n",
    "        #spacing = Spacing()\n",
    "        #res = spacing(res)\n",
    "        return res+r_pun[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da8a1e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'올라.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = Changer()\n",
    "ch.to_high('올라.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e64c4f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './아카이브/aihub.kr.shuf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4126fc8cefd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./아카이브/aihub.kr.shuf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./aihub.mecab_speed_test_01.shuf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './아카이브/aihub.kr.shuf'"
     ]
    }
   ],
   "source": [
    "f0 = open('./아카이브/aihub.kr.shuf', 'r', encoding = 'utf-8')\n",
    "f1 = open('./aihub.mecab_speed_test_01.shuf', 'w',encoding = 'utf-8')\n",
    "\n",
    "\n",
    "\n",
    "flag = 0\n",
    "\n",
    "num = 0\n",
    "number = 0\n",
    "ch = Changer()\n",
    "\n",
    "while True:\n",
    "    flag = 0\n",
    "    line = f0.readline()\n",
    "    if not line: break\n",
    "    if line[-1]=='\\n':\n",
    "        line = line.replace('\\n','')\n",
    "    \n",
    "    num_space = 0\n",
    "    for i in line:\n",
    "        if i==' ':\n",
    "            num_space = num_space+1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if num_space!=0:\n",
    "        line = line[num_space:]\n",
    "    \n",
    "#     try:\n",
    "    cc = ch.processText(line)\n",
    "#     except:\n",
    "#         cc = line\n",
    "    \n",
    "    plus = ''\n",
    "    for s in range(num_space):\n",
    "        plus = plus+' '\n",
    "    \n",
    "    line = plus+line\n",
    "    cc = plus+cc\n",
    "    f1.write(cc)\n",
    "    f1.write('\\n')\n",
    "    num = num+1\n",
    "    if cc!=line:\n",
    "        number = number+1\n",
    "    print(num)\n",
    "#     else:\n",
    "#         break\n",
    "#    print(number)\n",
    "\n",
    "f0.close()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c9534b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“가난한 사람이 경작한 밭에서는 많은 소출이 날 수도 있으나 불의가 판을 치면 그에게 돌아갈 몫이 없.”(13:23ㅂ니다, 새번역) 정규직을 꿈꾸며 열심히 일하던 비정규직 청년이 불의한 구조로 모든 것을 잃게 된 것입니다.\n",
      "“가난한 사람이 경작한 밭에서는 많은 소출이 날 수도 있으나 불의가 판을 치면 그에게 돌아갈 몫이 없다.”(13:23, 새번역) 정규직을 꿈꾸며 열심히 일하던 비정규직 청년이 불의한 구조로 모든 것을 잃게 된 것이다.\n",
      "1\n",
      "스타벅스 국내 매장이 1년간 사용하는 플라스틱 빨대(길이 21㎝)만 약 1억8000만개로 이를 연결하면 지구를 한 바퀴 감쌀 정도의 길이(3만8700㎞ㅂ니다).\n",
      "스타벅스 국내 매장이 1년간 사용하는 플라스틱 빨대(길이 21㎝)만 약 1억8000만개로 이를 연결하면 지구를 한 바퀴 감쌀 정도의 길이(3만8700㎞)다.\n",
      "2\n",
      "그중 대표적인 작품이 2017년 고야 단편 애니메이션 상을 수상한 ‘짧은 하루:어라이크(ALIKEㅂ니다)’.\n",
      "그중 대표적인 작품이 2017년 고야 단편 애니메이션 상을 수상한 ‘짧은 하루:어라이크(ALIKE)’다.\n",
      "3\n",
      "내 생각에 최고의 티브이 프로그램은 리얼리티 2ㅂ니다.\n",
      "내 생각에 최고의 티브이 프로그램은 리얼리티 2다.\n",
      "4\n",
      "이 조례에 따라 구세를 감면받고자 하는 자는 「지방세특례제한법 시행규칙」 별지 제1호 서식에 따른 지방세 감면신청서 및 그 사실을 증명할 수 있는 서류를 갖추어 구청장에게 신청하여야 합니다. 다만, 구청장이 감면대상임을 알 수 있는 때에는 신청이 없는 경우라도 직권으로 감면할 수 있.②ㅂ니다 구청장이 제1항에 따른 신청을 받은 때에는 감면여부를 조사·결정하고 그 내용을 「지방세특례제한법 시행규칙」 별지 제2호 서식에 따라 신청인에게 통지하여야 합니다.\n",
      "이 조례에 따라 구세를 감면받고자 하는 자는 「지방세특례제한법 시행규칙」 별지 제1호 서식에 따른 지방세 감면신청서 및 그 사실을 증명할 수 있는 서류를 갖추어 구청장에게 신청하여야 한다. 다만, 구청장이 감면대상임을 알 수 있는 때에는 신청이 없는 경우라도 직권으로 감면할 수 있다.② 구청장이 제1항에 따른 신청을 받은 때에는 감면여부를 조사·결정하고 그 내용을 「지방세특례제한법 시행규칙」 별지 제2호 서식에 따라 신청인에게 통지하여야 한다.\n",
      "5\n",
      "회의의 목적은 새로운 마케팅에 대한 토의 2ㅂ니다.\n",
      "회의의 목적은 새로운 마케팅에 대한 토의 2다.\n",
      "6\n",
      "이런 그의 정치철학 연구가 집약된 저서가 바로 <정의의 아이디어>ㅂ니다.\n",
      "이런 그의 정치철학 연구가 집약된 저서가 바로 <정의의 아이디어>다.\n",
      "7\n",
      "2차 투표가 성사될 경우 에르도안을 일대일로 상대할 유력 야권 후보는 최대 야당 공화인민당(CHP) 소속 무하렘 인제이(54ㅂ니다).\n",
      "2차 투표가 성사될 경우 에르도안을 일대일로 상대할 유력 야권 후보는 최대 야당 공화인민당(CHP) 소속 무하렘 인제이(54)다.\n",
      "8\n",
      "국제 선박정보업체 플릿몬 홈페이지에 따르면 루니스는 1999년 건조된 길이 104m, 폭 19m의 선박으로 국제해사기구가 부여한 식별번호는 9200859ㅂ니다.\n",
      "국제 선박정보업체 플릿몬 홈페이지에 따르면 루니스는 1999년 건조된 길이 104m, 폭 19m의 선박으로 국제해사기구가 부여한 식별번호는 9200859다.\n",
      "9\n",
      "경찰은 지난 7월부터 100일 동안 우월적 지위를 이용한 인격침해, 갑질 성범죄, 인허가 비리 등 갑질 범죄 특별단속을 통해 183건, 485명을 입건했.C30C19:C33D15C19:C26C19:C36D15C19:C26C19:C39D15C19:C26C19:C42D15C19:C26C19:C45DC19:C26ㅂ니다.\n",
      "경찰은 지난 7월부터 100일 동안 우월적 지위를 이용한 인격침해, 갑질 성범죄, 인허가 비리 등 갑질 범죄 특별단속을 통해 183건, 485명을 입건했다.C30C19:C33D15C19:C26C19:C36D15C19:C26C19:C39D15C19:C26C19:C42D15C19:C26C19:C45DC19:C26.\n",
      "10\n",
      "초등학생을 대상으로 한 ‘나는 CEOㅂ니다!’ 수업에서는 아이들이 직접 사업 아이템과 홍보물을 만들어 어른들에게 물건을 판매했습니다.\n",
      "초등학생을 대상으로 한 ‘나는 CEO다!’ 수업에서는 아이들이 직접 사업 아이템과 홍보물을 만들어 어른들에게 물건을 판매했다.\n",
      "11\n",
      "「서울특별시 도시 및 주거환경 정비조례」에 따른 보상금 지급대상인 무허가건물이 철거되는 경우에는 해당 연도의 재산세를 면제하.②ㅂ니다 제1항에 따른 무허가건물에 대하여는 재산세를 부과한 후에 그 무허가건물이 철거되는 경우에는 해당 부과처분을 취소합니다.\n",
      "「서울특별시 도시 및 주거환경 정비조례」에 따른 보상금 지급대상인 무허가건물이 철거되는 경우에는 해당 연도의 재산세를 면제한다.② 제1항에 따른 무허가건물에 대하여는 재산세를 부과한 후에 그 무허가건물이 철거되는 경우에는 해당 부과처분을 취소한다.\n",
      "12\n",
      "그 회사의 주요 생산품은 레이저 장비 2ㅂ니다.\n",
      "그 회사의 주요 생산품은 레이저 장비 2다.\n",
      "13\n",
      "불이 났을 때만 119가 아니라 물난리가 나도 119ㅂ니다.\n",
      "불이 났을 때만 119가 아니라 물난리가 나도 119다.\n",
      "14\n",
      "현재 중국이 가장 관심을 기울이는 것은 C919ㅂ니다.\n",
      "현재 중국이 가장 관심을 기울이는 것은 C919다.\n",
      "15\n",
      "우리나라 모든 행정 기관 중 인기 1위가 119ㅂ니다.\n",
      "우리나라 모든 행정 기관 중 인기 1위가 119다.\n",
      "16\n",
      "그 대표적인 것이 4년전 출간한 <예수냐 바울이냐>ㅂ니다.\n",
      "그 대표적인 것이 4년전 출간한 <예수냐 바울이냐>다.\n",
      "17\n",
      "줌인터넷이 금융감독원 전자공시를 통해 18일 공시한 보고서에 따르면, 이번 합병 비율은 미래에셋제5호스팩 1대 줌인터넷 1.7505ㅂ니다.\n",
      "줌인터넷이 금융감독원 전자공시를 통해 18일 공시한 보고서에 따르면, 이번 합병 비율은 미래에셋제5호스팩 1대 줌인터넷 1.7505다.\n",
      "18\n",
      "세금중에서 부동산 거래세, 취득세 세수가 우리 세수의 2/3ㅂ니다.\n",
      "세금중에서 부동산 거래세, 취득세 세수가 우리 세수의 2/3다.\n",
      "19\n",
      "「지방세특례제한법」제92조의2제1항 각 호의 구분에 따른 세액공제금액은 다음과 같.1ㅂ니다. 자동계좌이체 방식에 의한 납부만을 신청한 경우 : 고지서 1장당 150원\n",
      "「지방세특례제한법」제92조의2제1항 각 호의 구분에 따른 세액공제금액은 다음과 같다.1. 자동계좌이체 방식에 의한 납부만을 신청한 경우 : 고지서 1장당 150원\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "kr = open('./aihub.mecab_speed_test_01.shuf', \"r\" , encoding = \"utf-8\")\n",
    "origin = open('./아카이브/aihub.kr.shuf', \"r\" , encoding = \"utf-8\")\n",
    "\n",
    "\n",
    "부호 = ['.', '?', '!', ')', '\"', '…', '”', '．', ':', '~', ']', '┃', ',', '」']\n",
    "\n",
    "요 = 0\n",
    "다 = 0\n",
    "까 = 0\n",
    "나머지 = 0\n",
    "count = 0\n",
    "\n",
    "result=kr.readline()\n",
    "ori = origin.readline()\n",
    "\n",
    "\n",
    "    \n",
    "while True:\n",
    "\n",
    "    \n",
    "    \n",
    "    result = result.replace('\\n','')\n",
    "    ori = ori.replace('\\n','')\n",
    "    if not result: break\n",
    "    \n",
    "    if 'ㅂ니다' in result:\n",
    "        count = count+1\n",
    "        print(result)\n",
    "        print(ori)\n",
    "        print(count)\n",
    "        \n",
    "        \n",
    "    result=kr.readline()\n",
    "    ori = origin.readline()\n",
    "\n",
    "kr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa9534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24e1d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_ch02(input, lis_ef, tag_last, lis_w_last, lis_w_last_not):\n",
    "    \n",
    "    lis_res_word = []\n",
    "    \n",
    "    lis_input = input.split()\n",
    "    lis_word = []\n",
    "    lis_tag = []\n",
    "    lis_last_word = []\n",
    "    lis_ind = []\n",
    "    \n",
    "    lis_result = []\n",
    "    \n",
    "    for i in range(len(lis_input)):\n",
    "        ele_w = []\n",
    "        ele_t = []\n",
    "        \n",
    "        an = mec.pos(lis_input[i])\n",
    "        for j in range(len(an)):\n",
    "            ele_w.append(an[j][0])\n",
    "            ele_t.append(an[j][1])\n",
    "        elem_w = ' '.join(ele_w)\n",
    "        elem_t = '/'.join(ele_t)\n",
    "        \n",
    "        jam_pre = Jamodealer(elem_w)\n",
    "        lis_word.append(''.join(jam_pre.jamo))\n",
    "        lis_tag.append(elem_t)\n",
    "    \n",
    "    for i in range(len(lis_tag)):\n",
    "        \n",
    "        if 'EF/SF' in lis_tag[i] or 'EF/SV' in lis_tag[i]:\n",
    "            elemen_t = lis_tag[i].split('/')\n",
    "            elemen_w = lis_word[i].split(' ')\n",
    "            flag = 0\n",
    "            \n",
    "            \n",
    "            for j in range(len(elemen_t)):\n",
    "\n",
    "                flag_end = detect_h(elemen_w[j], lis_w_last_not, lis_w_last)\n",
    "\n",
    "                \n",
    "                if flag_end == 1 and 'EF' in elemen_t[j]:\n",
    "                    \n",
    "                    for jam in lis_w_last_not:\n",
    "                        \n",
    "                        if len(elemen_w[j])>=len(jam):\n",
    "                            \n",
    "                            if elemen_w[j][-len(jam):]==jam:\n",
    "                                \n",
    "                                \n",
    "                                lis_ind.append(i)\n",
    "                                lis_last_word.append(jam)\n",
    "                                elemen_w[j] = elemen_w[j][:-len(jam)]\n",
    "                                \n",
    "                                break\n",
    "                                \n",
    "            res_w = ''.join(elemen_w)\n",
    "            lis_result.append(res_w)\n",
    "                                \n",
    "        else:\n",
    "            \n",
    "            rere = lis_word[i].split(' ')\n",
    "            \n",
    "            resres = ''.join(rere)\n",
    "            \n",
    "            lis_result.append(resres)\n",
    "            \n",
    "            \n",
    "    return lis_result, lis_tag, lis_ind, lis_last_word\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5f7ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['ㅇㅣㅂㅓㄴㅈㅜ', 'ㄱㅡㅁㅇㅛㅇㅣㄹㅇㅔ', 'ㄱㅡㄱㅗㅅㅇㅔ', 'ㄱㅏㄹ', 'ㄱㅓㅅㅇㅣ.'], ['NNG/NNG', 'NNG/JKB', 'NP/JKB', 'VV+ETM', 'NNB/VCP+EF/SF'], [4], ['ㅂㄴㅣㄷㅏ'])\n"
     ]
    }
   ],
   "source": [
    "print(prepro_ch02('이번주 금요일에 그곳에 갈 것입니다.', lis_beta_ef, lis_tag_last, lis_end_2low, lis_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91584773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ba968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

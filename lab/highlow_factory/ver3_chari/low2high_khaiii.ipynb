{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b5d451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"split_syllable_char\", \"split_syllables\",\n",
    "           \"join_jamos\", \"join_jamos_char\",\n",
    "           \"CHAR_INITIALS\", \"CHAR_MEDIALS\", \"CHAR_FINALS\"]\n",
    "\n",
    "import itertools\n",
    "\n",
    "INITIAL = 0x001\n",
    "MEDIAL = 0x010\n",
    "FINAL = 0x100\n",
    "CHAR_LISTS = {\n",
    "    INITIAL: list(map(chr, [\n",
    "        0x3131, 0x3132, 0x3134, 0x3137, 0x3138, 0x3139,\n",
    "        0x3141, 0x3142, 0x3143, 0x3145, 0x3146, 0x3147,\n",
    "        0x3148, 0x3149, 0x314a, 0x314b, 0x314c, 0x314d,\n",
    "        0x314e\n",
    "    ])),\n",
    "    MEDIAL: list(map(chr, [\n",
    "        0x314f, 0x3150, 0x3151, 0x3152, 0x3153, 0x3154,\n",
    "        0x3155, 0x3156, 0x3157, 0x3158, 0x3159, 0x315a,\n",
    "        0x315b, 0x315c, 0x315d, 0x315e, 0x315f, 0x3160,\n",
    "        0x3161, 0x3162, 0x3163\n",
    "    ])),\n",
    "    FINAL: list(map(chr, [\n",
    "        0x3131, 0x3132, 0x3133, 0x3134, 0x3135, 0x3136,\n",
    "        0x3137, 0x3139, 0x313a, 0x313b, 0x313c, 0x313d,\n",
    "        0x313e, 0x313f, 0x3140, 0x3141, 0x3142, 0x3144,\n",
    "        0x3145, 0x3146, 0x3147, 0x3148, 0x314a, 0x314b,\n",
    "        0x314c, 0x314d, 0x314e\n",
    "    ]))\n",
    "}\n",
    "CHAR_INITIALS = CHAR_LISTS[INITIAL]\n",
    "CHAR_MEDIALS = CHAR_LISTS[MEDIAL]\n",
    "CHAR_FINALS = CHAR_LISTS[FINAL]\n",
    "CHAR_SETS = {k: set(v) for k, v in CHAR_LISTS.items()}\n",
    "CHARSET = set(itertools.chain(*CHAR_SETS.values()))\n",
    "CHAR_INDICES = {k: {c: i for i, c in enumerate(v)}\n",
    "                for k, v in CHAR_LISTS.items()}\n",
    "\n",
    "\n",
    "def is_hangul_syllable(c):\n",
    "    return 0xac00 <= ord(c) <= 0xd7a3  # Hangul Syllables\n",
    "\n",
    "\n",
    "def is_hangul_jamo(c):\n",
    "    return 0x1100 <= ord(c) <= 0x11ff  # Hangul Jamo\n",
    "\n",
    "\n",
    "def is_hangul_compat_jamo(c):\n",
    "    return 0x3130 <= ord(c) <= 0x318f  # Hangul Compatibility Jamo\n",
    "\n",
    "\n",
    "def is_hangul_jamo_exta(c):\n",
    "    return 0xa960 <= ord(c) <= 0xa97f  # Hangul Jamo Extended-A\n",
    "\n",
    "\n",
    "def is_hangul_jamo_extb(c):\n",
    "    return 0xd7b0 <= ord(c) <= 0xd7ff  # Hangul Jamo Extended-B\n",
    "\n",
    "\n",
    "def is_hangul(c):\n",
    "    return (is_hangul_syllable(c) or\n",
    "            is_hangul_jamo(c) or\n",
    "            is_hangul_compat_jamo(c) or\n",
    "            is_hangul_jamo_exta(c) or\n",
    "            is_hangul_jamo_extb(c))\n",
    "\n",
    "\n",
    "def is_supported_hangul(c):\n",
    "    return is_hangul_syllable(c) or is_hangul_compat_jamo(c)\n",
    "\n",
    "\n",
    "def check_hangul(c, jamo_only=False):\n",
    "    if not ((jamo_only or is_hangul_compat_jamo(c)) or is_supported_hangul(c)):\n",
    "        raise ValueError(f\"'{c}' is not a supported hangul character. \"\n",
    "                         f\"'Hangul Syllables' (0xac00 ~ 0xd7a3) and \"\n",
    "                         f\"'Hangul Compatibility Jamos' (0x3130 ~ 0x318f) are \"\n",
    "                         f\"supported at the moment.\")\n",
    "\n",
    "\n",
    "def get_jamo_type(c):\n",
    "    check_hangul(c)\n",
    "    assert is_hangul_compat_jamo(c), f\"not a jamo: {ord(c):x}\"\n",
    "    return sum(t for t, s in CHAR_SETS.items() if c in s)\n",
    "\n",
    "\n",
    "def split_syllable_char(c):\n",
    "    \"\"\"\n",
    "    Splits a given korean syllable into its components. Each component is\n",
    "    represented by Unicode in 'Hangul Compatibility Jamo' range.\n",
    "\n",
    "    Arguments:\n",
    "        c: A Korean character.\n",
    "\n",
    "    Returns:\n",
    "        A triple (initial, medial, final) of Hangul Compatibility Jamos.\n",
    "        If no jamo corresponds to a position, `None` is returned there.\n",
    "\n",
    "    Example:\n",
    "        >>> split_syllable_char(\"안\")\n",
    "        (\"ㅇ\", \"ㅏ\", \"ㄴ\")\n",
    "        >>> split_syllable_char(\"고\")\n",
    "        (\"ㄱ\", \"ㅗ\", None)\n",
    "        >>> split_syllable_char(\"ㅗ\")\n",
    "        (None, \"ㅗ\", None)\n",
    "        >>> split_syllable_char(\"ㅇ\")\n",
    "        (\"ㅇ\", None, None)\n",
    "    \"\"\"\n",
    "    check_hangul(c)\n",
    "    if len(c) != 1:\n",
    "        raise ValueError(\"Input string must have exactly one character.\")\n",
    "\n",
    "    init, med, final = None, None, None\n",
    "    if is_hangul_syllable(c):\n",
    "        offset = ord(c) - 0xac00\n",
    "        x = (offset - offset % 28) // 28\n",
    "        init, med, final = x // 21, x % 21, offset % 28\n",
    "        if not final:\n",
    "            final = None\n",
    "        else:\n",
    "            final -= 1\n",
    "    else:\n",
    "        pos = get_jamo_type(c)\n",
    "        if pos & INITIAL == INITIAL:\n",
    "            pos = INITIAL\n",
    "        elif pos & MEDIAL == MEDIAL:\n",
    "            pos = MEDIAL\n",
    "        elif pos & FINAL == FINAL:\n",
    "            pos = FINAL\n",
    "        idx = CHAR_INDICES[pos][c]\n",
    "        if pos == INITIAL:\n",
    "            init = idx\n",
    "        elif pos == MEDIAL:\n",
    "            med = idx\n",
    "        else:\n",
    "            final = idx\n",
    "    return tuple(CHAR_LISTS[pos][idx] if idx is not None else None\n",
    "                 for pos, idx in\n",
    "                 zip([INITIAL, MEDIAL, FINAL], [init, med, final]))\n",
    "\n",
    "\n",
    "def split_syllables(s, ignore_err=True, pad= '_'):\n",
    "    \"\"\"\n",
    "    Performs syllable-split on a string.\n",
    "\n",
    "    Arguments:\n",
    "        s (str): A string (possibly mixed with non-Hangul characters).\n",
    "        ignore_err (bool): If set False, it ensures that all characters in\n",
    "            the string are Hangul-splittable and throws a ValueError otherwise.\n",
    "            (default: True)\n",
    "        pad (str): Pad empty jamo positions (initial, medial, or final) with\n",
    "            `pad` character. This is useful for cases where fixed-length\n",
    "            strings are needed. (default: None)\n",
    "\n",
    "    Returns:\n",
    "        Hangul-split string\n",
    "\n",
    "    Example:\n",
    "        >>> split_syllables(\"안녕하세요\")\n",
    "        \"ㅇㅏㄴㄴㅕㅇㅎㅏㅅㅔㅇㅛ\"\n",
    "        >>> split_syllables(\"안녕하세요~~\", ignore_err=False)\n",
    "        ValueError: encountered an unsupported character: ~ (0x7e)\n",
    "        >>> split_syllables(\"안녕하세요ㅛ\", pad=\"x\")\n",
    "        'ㅇㅏㄴㄴㅕㅇㅎㅏxㅅㅔxㅇㅛxxㅛx'\n",
    "    \"\"\"\n",
    "\n",
    "    def try_split(c):\n",
    "        try:\n",
    "            return split_syllable_char(c)\n",
    "        except ValueError:\n",
    "            if ignore_err:\n",
    "                return (c,)\n",
    "            raise ValueError(f\"encountered an unsupported character: \"\n",
    "                             f\"{c} (0x{ord(c):x})\")\n",
    "\n",
    "    s = map(try_split, s)\n",
    "    if pad is not None:\n",
    "        tuples = map(lambda x: tuple(pad if y is None else y for y in x), s)\n",
    "    else:\n",
    "        tuples = map(lambda x: filter(None, x), s)\n",
    "    return \"\".join(itertools.chain(*tuples))\n",
    "\n",
    "\n",
    "def join_jamos_char(init, med, final=None):\n",
    "    \"\"\"\n",
    "    Combines jamos into a single syllable.\n",
    "\n",
    "    Arguments:\n",
    "        init (str): Initial jao.\n",
    "        med (str): Medial jamo.\n",
    "        final (str): Final jamo. If not supplied, the final syllable is made\n",
    "            without the final. (default: None)\n",
    "\n",
    "    Returns:\n",
    "        A Korean syllable.\n",
    "    \"\"\"\n",
    "    chars = (init, med, final)\n",
    "    for c in filter(None, chars):\n",
    "        check_hangul(c, jamo_only=True)\n",
    "\n",
    "    idx = tuple(CHAR_INDICES[pos][c] if c is not None else c\n",
    "                for pos, c in zip((INITIAL, MEDIAL, FINAL), chars))\n",
    "    init_idx, med_idx, final_idx = idx\n",
    "    # final index must be shifted once as\n",
    "    # final index with 0 points to syllables without final\n",
    "    final_idx = 0 if final_idx is None else final_idx + 1\n",
    "    return chr(0xac00 + 28 * 21 * init_idx + 28 * med_idx + final_idx)\n",
    "\n",
    "\n",
    "def join_jamos(s, ignore_err=True):\n",
    "    \"\"\"\n",
    "    Combines a sequence of jamos to produce a sequence of syllables.\n",
    "\n",
    "    Arguments:\n",
    "        s (str): A string (possible mixed with non-jamo characters).\n",
    "        ignore_err (bool): If set False, it will ensure that all characters\n",
    "            will be consumed for the making of syllables. It will throw a\n",
    "            ValueError when it fails to do so. (default: True)\n",
    "\n",
    "    Returns:\n",
    "        A string\n",
    "\n",
    "    Example:\n",
    "        >>> join_jamos(\"ㅇㅏㄴㄴㅕㅇㅎㅏㅅㅔㅇㅛ\")\n",
    "        \"안녕하세요\"\n",
    "        >>> join_jamos(\"ㅇㅏㄴㄴㄴㅕㅇㅎㅏㅅㅔㅇㅛ\")\n",
    "        \"안ㄴ녕하세요\"\n",
    "        >>> join_jamos()\n",
    "    \"\"\"\n",
    "    last_t = 0\n",
    "    queue = []\n",
    "    new_string = \"\"\n",
    "\n",
    "    def flush(n=0):\n",
    "        new_queue = []\n",
    "        while len(queue) > n:\n",
    "            new_queue.append(queue.pop())\n",
    "        if len(new_queue) == 1:\n",
    "            if not ignore_err:\n",
    "                raise ValueError(f\"invalid jamo character: {new_queue[0]}\")\n",
    "            result = new_queue[0]\n",
    "        elif len(new_queue) >= 2:\n",
    "            try:\n",
    "                result = join_jamos_char(*new_queue)\n",
    "            except (ValueError, KeyError):\n",
    "                # Invalid jamo combination\n",
    "                if not ignore_err:\n",
    "                    raise ValueError(f\"invalid jamo characters: {new_queue}\")\n",
    "                result = \"\".join(new_queue)\n",
    "        else:\n",
    "            result = None\n",
    "        return result\n",
    "\n",
    "    for c in s:\n",
    "        if c == '_':  #jeonghui add\n",
    "            continue  #jeonghui add\n",
    "        if c not in CHARSET:\n",
    "            if queue:\n",
    "                new_c = flush() + c\n",
    "            else:\n",
    "                new_c = c\n",
    "            last_t = 0\n",
    "        else:\n",
    "            t = get_jamo_type(c)\n",
    "            new_c = None\n",
    "            if t & FINAL == FINAL:\n",
    "                if not (last_t == MEDIAL):\n",
    "                    new_c = flush()\n",
    "            elif t == INITIAL:\n",
    "                new_c = flush()\n",
    "            elif t == MEDIAL:\n",
    "                if last_t & INITIAL == INITIAL:\n",
    "                    new_c = flush(1)\n",
    "                else:\n",
    "                    new_c = flush()\n",
    "            last_t = t\n",
    "            queue.insert(0, c)\n",
    "        if new_c:\n",
    "            new_string += new_c\n",
    "    if queue:\n",
    "        new_string += flush()\n",
    "    return new_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297d3bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from khaiii import KhaiiiApi\n",
    "from collections import deque\n",
    "api = KhaiiiApi()\n",
    "\n",
    "da_low= ['다', 'ㄴ다', '는다', '느냐다', '단다', '서다', '란다', 'ㄴ단다'] \n",
    "da_case1 = ['더다', '느냐다', '서다', '어서다', '세다', '는지다', '냐다', '라다', '드다', 'ㄹ지다', 'ㄴ가다', '매다', '대다', '가다', '어다', 'ㅂ세다', 'ㄴ지다', '거다', 'ㄹ다', '네다', '어라다', 'ㄹ트다', '뫼다', '는가다', '을지다', '두다', '구다', '아야다', '조다', '아서다', '오다', '기다']\n",
    "da_case2 = ['ㄴ다', '단다', '란다', 'ㄴ단다', '더란다', '넌다', '냐이다', '건다', '으란다', '서란다', '나다', '는단다', '인다', '렌다', '은다', '련다', '차다', 'ㄴ거다', '프다', '올게다']\n",
    "da_case3 = ['는다', '잖다', '뵀다', '쫒는다', '더랬다', 'ㅂ다']\n",
    "da_tag_case1 = ['SL', 'SW', 'SS', 'NNP', 'NNG']\n",
    "da_tag_case2 = ['NNB', 'XSV', 'XSA', 'ETN', 'VCN', 'JKB', 'VCP', 'VV', 'VX', 'EP', 'VA', 'EC']\n",
    "\n",
    "yoo_low = ['을까', 'ㄹ까', '지', '으니까', '어', '는데', 'ㄴ가', 'ㄹ게', '래', '잖아', '네', '여', 'ㄹ래', '게', '나', '군', '을게', '다고', '지만', '은데', 'ㄴ지', '는지', '라고', 'ㄴ데', '는걸', '아서', '거든', '더라고', '어서', '려고', '을래', '대', 'ㄴ대', '던데', '더군', '여서', '건가', '어야지', 'ㄹ걸', 'ㄹ께', '아야지', '다면서', '는군', 'ㄴ다고', '은가', '다니', '다면', '실까', '가', '신가', '서', '까', '다니까', '데', '다던데', '다는데', '랄까', '거나', '라던데', '던가']\n",
    "\n",
    "an_low = ['아', '야', '어', '지', '자', '을까', 'ㄹ까', '어라']\n",
    "\n",
    "#아로 끝나는 친구들\n",
    "ah_low = ['하', '좋', '오', '같', '나오', '많', '앉', '막', '팔', '편하', '다녀오', '나', '만나', '보', '알', '바라', '말', '가', '귀찮', '들어가', '바르', '다르', '않', '아프', '내려가', '돌아오', '놀', '지나가', '받', '나타나', '나쁘', '남', '모르', '맞', '못하', '밝', '타', '들어오', '찾아오', '괜찮', '닫', '놓', '살', '춰', '다보', '지내', '그리워하', '높', '잡', '가보', '힘내', '내', '찾아보', '가져오', '사', '달', '내보', '라', '꽂', '돌아가', '프', '나가', '여받', '밀어내', '빛나', '생각나', '찾아가', '깨', '걷어오', '걷어가', '맡', '자', '빠르', '닿', '약하', '참', '끝나', '올라가', '찾', '일어나', '깨어나', '골', '잦', '보내', '싸', '닦', '똑같', '따라오', '볶', '날아가', '낫', '갚', '떠나', '빨', '돌', '알맞', '작', '옳', '깎', '낳', '떠나가', '낮', '보내보', '고르', '심하', '살아가', '비싸', '고프', '담', '뛰어오', '녹', '멀잖', '따르', '알아보', '사오', '주말', '급하', '사보', '뛰어보', '모으', '가져가', '내려오', '해오', '잖', '자르', '좁', '삼', '마시잖', '형편없잖', '짧', '올라오', '둘러보', '시하', '돌아보', '도망가', '나아가', '뒤따라오', '두르러보', '달려가', '바라보', '돕오', '구르러가',  '흘러나오', '삶', '다가오', '살펴보', '깨닫', '빠져나오', '내려보', '상하']\n",
    "\n",
    "\n",
    "def tohigh(input):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    analyzed = api.analyze(input)  \n",
    "    for data in analyzed:\n",
    "        lis_word = []\n",
    "        lis_tag = []\n",
    "        for morph in data.morphs:\n",
    "            lis_word.append(morph.lex)\n",
    "            lis_tag.append(morph.tag)\n",
    "#         print(lis_word)\n",
    "#         print(lis_tag)\n",
    "#         print(\"====================\")\n",
    "        try:\n",
    "            lis_tag.index('EF')\n",
    "            result.append(to_high(data.lex,lis_word,lis_tag))\n",
    "        except:\n",
    "            if len(lis_tag) == 2 and lis_tag[0] == \"NP\" and (\"JK\" in lis_tag[1] or \"JX\" == lis_tag[1]):\n",
    "                if lis_word[0] == \"나\":\n",
    "                    lis_word[0] = \"저\"\n",
    "                    if lis_word[1] == \"ㄴ\":\n",
    "                        result.append(\"전\")\n",
    "                    elif lis_word[1] == \"ㄹ\":\n",
    "                        result.append(\"절\")\n",
    "                    else:\n",
    "                        result.append(''.join(lis_word))\n",
    "                elif lis_word[0] == \"너\":\n",
    "                    print(lis_word[1])\n",
    "                    lis_word[0] = \"당신\"\n",
    "                    if lis_word[1] == \"ㄴ\":\n",
    "                        result.append(\"당신은\")\n",
    "                    elif lis_word[1] == \"ㄹ\":\n",
    "                        result.append(\"당신을\")\n",
    "                    elif lis_word[1] == \"랑\":\n",
    "                        result.append(\"당신이랑\")\n",
    "                    else:\n",
    "                        if lis_word[1] == \"는\":\n",
    "                            lis_word[1] = \"은\"\n",
    "                        elif lis_word[1] == \"와\":\n",
    "                            lis_word[1] == \"과\"\n",
    "                        elif lis_word[1] == \"가\":\n",
    "                            lis_word[1] == \"이\"\n",
    "                        elif lis_word[1] == \"를\":\n",
    "                            lis_word[1] == \"을\"\n",
    "                        result.append(''.join(lis_word))\n",
    "                elif data.lex == \"내가\":\n",
    "                    result.append(\"제가\")\n",
    "                elif data.lex == \"네가\":\n",
    "                    result.append(\"당신이\")\n",
    "                else:\n",
    "                    result.append(data.lex)\n",
    "            else:\n",
    "                result.append(data.lex)\n",
    "        \n",
    "    return ' '.join(result)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "def to_high(result, lis_word, lis_tag):\n",
    "#     print(lis_word)\n",
    "#     print(lis_tag)\n",
    "    EF_indexs = [pos for pos, char in enumerate(lis_tag) if char == \"EF\"]\n",
    "    EF_index = EF_indexs[-1]\n",
    "    EF = lis_word[EF_index]\n",
    "    EF_next = lis_word[EF_index+1]\n",
    "    EF_front = lis_word[EF_index-1]\n",
    "    if is_hangul(EF_next):\n",
    "        return result\n",
    "    \n",
    "    #다로 끝나는 친구들\n",
    "    if EF in da_case1:\n",
    "        result = result.replace('다'+EF_next, '입니다'+EF_next)\n",
    "    elif EF in da_case2:\n",
    "        if EF == 'ㄴ다':\n",
    "            result = join_jamos(split_syllables(result).replace('ㄴㄷㅏ_'+EF_next, 'ㅂㄴㅣ_ㄷㅏ_' + EF_next))\n",
    "        else:\n",
    "            jamo = split_syllables(EF[:-1])[-1]\n",
    "            result = join_jamos(split_syllables(result).replace(jamo + 'ㄷㅏ_' + EF_next, 'ㅂㄴㅣ_ㄷㅏ_' + EF_next))\n",
    "    elif EF in da_case3:\n",
    "        if '는다' in EF:\n",
    "            result = result.replace('는다'+EF_next, '습니다'+EF_next)\n",
    "        else:\n",
    "            result = result.replace('다'+EF_next, '습니다'+EF_next)\n",
    "    elif EF == '다':\n",
    "        if lis_tag[EF_index-1] in da_tag_case1:\n",
    "            result = result.replace('다'+EF_next, '입니다'+EF_next)\n",
    "        elif lis_tag[EF_index-1] in da_tag_case2:\n",
    "            jamo = split_syllables(EF_front)[-1]\n",
    "#             print(jamo)\n",
    "            #받침없는 경우(ㄹ,ㄴ포함)\n",
    "            if jamo == '_' or jamo == 'ㄹ' or jamo == 'ㄴ' :\n",
    "                if (lis_tag[EF_index-1] == 'VCP' and lis_word[EF_index-1] == '이') and lis_word[EF_index-1] != result[result.rfind('다'+EF_next)-1]:\n",
    "                    result = result.replace('다'+EF_next, '입니다'+EF_next)\n",
    "                else:\n",
    "                    result = join_jamos(split_syllables(result).replace(jamo+'ㄷㅏ_'+EF_next, 'ㅂㄴㅣ_ㄷㅏ_' + EF_next))\n",
    "            #받침있는 경우\n",
    "            else:\n",
    "                result = result.replace('다'+EF_next, '습니다'+EF_next)\n",
    "    #요로 끝나는 친구들 \n",
    "    elif EF in yoo_low:\n",
    "        if len(EF) == 1:\n",
    "            if lis_word[-2] == EF and (lis_word[-2] == '어' or lis_word[-2] == \"여\") and lis_word[-2] != result[-2]:\n",
    "                result = result.replace(EF_next, '요'+EF_next)\n",
    "            else:\n",
    "                result = result.replace(EF+EF_next, EF+'요'+EF_next)\n",
    "            \n",
    "        else:\n",
    "            result = join_jamos(split_syllables(result).replace(split_syllables(EF[1:])+EF_next, split_syllables(EF[1:]+'요')+EF_next))\n",
    "    #아\n",
    "    elif EF == '아':\n",
    "        if EF_front in ah_low:\n",
    "            result = result.replace(EF_next, '요'+EF_next)\n",
    "    #구나\n",
    "    elif '구나' in EF:\n",
    "        result = result.replace(EF+EF_next, '네요'+EF_next)\n",
    "    #야\n",
    "    elif EF == '야':\n",
    "        result = result.replace(EF+EF_next, '에요'+EF_next)\n",
    "    #니 냐 느냐 는가\n",
    "    elif EF == '니' or EF == '냐' or EF == '느냐' or EF == '는가':\n",
    "        result = result.replace(EF+EF_next, '나요'+EF_next)\n",
    "    #자\n",
    "    elif EF == '자':\n",
    "        result = result.replace(EF+EF_next, '지요'+EF_next)\n",
    "    #라\n",
    "    elif EF == '라':\n",
    "        jamo = split_syllables(EF_front)[-1]\n",
    "        if lis_tag[EF_index-1] == 'VX' or 'XSV':\n",
    "            if jamo == '_':\n",
    "                result = result.replace(EF+EF_next, '세요'+EF_next)\n",
    "            elif EF_front[-1] =='달':\n",
    "                result = result.replace(EF_front[-1]+EF+EF_next,'주세요'+EF_next)\n",
    "            else:\n",
    "                result = result.replace(EF+EF_next, EF+'요'+EF_next)\n",
    "    #아라, 어라\n",
    "    elif EF == '아라' or EF == '어라':\n",
    "        jamo = split_syllables(EF_front)[-1]\n",
    "        check = result.find(EF_front+EF+EF_next)\n",
    "        if check != -1:\n",
    "            if jamo == 'ㄹ':\n",
    "                result = result.replace(EF_front+EF+EF_next, join_jamos(split_syllables(EF_front)[:-1])+'세요'+EF_next)\n",
    "            elif jamo == '_':\n",
    "                result = result.replace(EF_front+EF+EF_next, EF_front+'세요'+EF_next)\n",
    "            else:\n",
    "                result = result.replace(EF_front+EF+EF_next, EF_front+'으세요'+EF_next)\n",
    "        else:\n",
    "            ra_index = result.find('라'+EF_next)\n",
    "            if result[ra_index-1:ra_index+1]=='라라':\n",
    "                result = result[:ra_index-len(EF_front)-1] + join_jamos(split_syllables(EF_front)[:-1])+'르세요' + result[ra_index+1:]\n",
    "            elif jamo == 'ㄹ':\n",
    "                result = result[:ra_index-len(EF_front)] + join_jamos(split_syllables(EF_front)[:-1])+'세요' + result[ra_index+1:]\n",
    "            elif jamo == '_':\n",
    "                result = result[:ra_index-len(EF_front)] + EF_front + '세요' + result[ra_index+1:]\n",
    "            else:\n",
    "                result = result[:ra_index-len(EF_front)] + EF_front + '으세요' + result[ra_index+1:]\n",
    "    elif EF == '더라' or EF == \"다더라\":\n",
    "        result = result.replace(EF+EF_next, EF+'고요'+EF_next)\n",
    "    elif EF == \"잖니\":\n",
    "        result = result.replace(EF+EF_next, EF[0]+'아요'+EF_next)\n",
    "    elif EF == \"야지\":\n",
    "        result = result.replace(EF+EF_next, EF[0]+'죠'+EF_next)\n",
    "    elif EF == \"자아\":\n",
    "        result = result.replace(EF_front + EF[0] + EF_next, '지냅시다'+EF_next)\n",
    "    elif EF == \"이다\":\n",
    "        result = result.replace(EF+EF_next, \"입니다\" + EF_next)\n",
    "\n",
    "        \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07c43dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는']\n",
      "['NP', 'JX']\n",
      "====================\n",
      "['네', '가']\n",
      "['NP', 'JKS']\n",
      "====================\n",
      "['얘기', '하', '였', '던']\n",
      "['NNG', 'XSV', 'EP', 'ETM']\n",
      "====================\n",
      "['모든']\n",
      "['MM']\n",
      "====================\n",
      "['것', '이']\n",
      "['NNB', 'JKS']\n",
      "====================\n",
      "['기억나', '요', '.']\n",
      "['VV', 'EF', 'SF']\n",
      "====================\n",
      "['기억나', '요', '.']\n",
      "['VV', 'EF', 'SF']\n",
      "나는 네가 얘기했던 모든 게 기억나요.\n"
     ]
    }
   ],
   "source": [
    "txt = \"나는 네가 얘기했던 모든 게 기억나요.\"\n",
    "print(Changer(txt))\n",
    "\n",
    "#니까\n",
    "#라니\n",
    "#으리라\n",
    "#이다\n",
    "#ㄴ다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625502fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9c8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1de8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d026d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e55014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b8381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3dd47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr = open('/Users/jeonghui/Desktop/aihub.kr.shuf', \"r\" , encoding = \"utf-8\")\n",
    "khaiii = open('/Users/jeonghui/Desktop/aihub.khaiii.shuf', \"w\" , encoding = \"utf-8\")\n",
    "\n",
    "text=kr.readline()\n",
    "\n",
    "while(text != ''):\n",
    "    check = 0\n",
    "    if text[-1]=='\\n':\n",
    "        text = text.replace('\\n','').strip()\n",
    "    if is_hangul(text[-1]):\n",
    "        text = text+\".\"\n",
    "        check = 1\n",
    "    text = Changer(text)\n",
    "    if check == 1:\n",
    "        text = text[:-1]\n",
    "    khaiii.write(text+\"\\n\")\n",
    "    text=kr.readline()\n",
    "    \n",
    "khaiii.close()\n",
    "kr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb96a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr = open('/Users/jeonghui/Desktop/hgu_clean.kr.shuf', \"r\" , encoding = \"utf-8\")\n",
    "khaiii = open('/Users/jeonghui/Desktop/hgu_clean.khaiii.shuf', \"w\" , encoding = \"utf-8\")\n",
    "\n",
    "text=kr.readline()\n",
    "\n",
    "while(text != ''):\n",
    "    check = 0\n",
    "    if text[-1]=='\\n':\n",
    "        text = text.replace('\\n','').strip()\n",
    "    if is_hangul(text[-1]):\n",
    "        text = text+\".\"\n",
    "        check = 1\n",
    "    text = Changer(text)\n",
    "    if check == 1:\n",
    "        text = text[:-1]\n",
    "    khaiii.write(text+\"\\n\")\n",
    "    text=kr.readline()\n",
    "    \n",
    "khaiii.close()\n",
    "kr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a9c6bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "khaiii = open('/Users/jeonghui/Desktop/aihub.khaiii.shuf', \"r\" , encoding = \"utf-8\")\n",
    "mecab = open('/Users/jeonghui/Desktop/aihub.mecab.shuf', \"r\" , encoding = \"utf-8\")\n",
    "diff = open('/Users/jeonghui/Desktop/두개비교', \"w\" , encoding = \"utf-8\")\n",
    "\n",
    "text1=khaiii.readline()\n",
    "text2=mecab.readline()\n",
    "\n",
    "high = ['니다', '니까', '요', '시다', '도다', '리다', '야']\n",
    "\n",
    "\n",
    "while(text1 != ''):\n",
    "    check = 0\n",
    "    text1_split = text1.split()\n",
    "    text2_split = text2.split()\n",
    "#     if text1_split[-1] != text2_split[-1] and len(text1) <= len(text2):\n",
    "#         if \"니다\" in text1_split[-1] or \"니까\" in text1_split[-1] or \"요\" in text1_split[-1] or \"시다\" in text1_split[-1] or \"도다\" in text1_split[-1] or \"리다\" in text1_split[-1] or \"야\" in text1_split[-1]:\n",
    "#             check = 1\n",
    "#         if text1 != text2 and check == 0:\n",
    "    \n",
    "    if text1 != text2:\n",
    "#         if \"니다\" not in text1_split[-1] and \"니까\" not in text1_split[-1] and \"요\" not in text1_split[-1] and \"시다\" not in text1_split[-1] and \"도다\" not in text1_split[-1] and \"리다\" not in text1_split[-1] and \"야\" not in text1_split[-1]:\n",
    "        diff.write(text1)\n",
    "        diff.write(text2)\n",
    "        diff.write('\\n')\n",
    "    \n",
    "    text1=khaiii.readline()\n",
    "    text2=mecab.readline()\n",
    "\n",
    "khaiii.close()\n",
    "mecab.close()\n",
    "diff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "43aebda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr = open('/Users/jeonghui/Desktop/hgu_clean.kr.shuf', \"r\" , encoding = \"utf-8\")\n",
    "khaiii = open('/Users/jeonghui/Desktop/hgu_clean.khaiii.shuf', \"w\" , encoding = \"utf-8\")\n",
    "\n",
    "text=kr.readline()\n",
    "\n",
    "while(text != ''):\n",
    "    check = 0\n",
    "    if text[-1]=='\\n':\n",
    "        text = text.replace('\\n','').strip()\n",
    "    if is_hangul(text[-1]):\n",
    "        text = text+\".\"\n",
    "        check = 1\n",
    "    text = Changer(text)\n",
    "    if check == 1:\n",
    "        text = text[:-1]\n",
    "    khaiii.write(text+\"\\n\")\n",
    "    text=kr.readline()\n",
    "    \n",
    "khaiii.close()\n",
    "kr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cd085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbaba98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006f4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37648c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##니다.\n",
    "##요\n",
    "##세요.\n",
    "#아요, 어요\n",
    "#선어말 어미 -시-\n",
    "\n",
    "#clear\n",
    "#ㅂ니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74617cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from khaiii import KhaiiiApi\n",
    "from collections import deque\n",
    "api = KhaiiiApi()\n",
    "\n",
    "#ㅂ니다\n",
    "q_nida2s_da = [\"VV\", \"VX\", \"XSV\", \"EP\"]\n",
    "q_nida2da = [\"XSA\", \"VCP\", \"VA\", \"VCN\"]\n",
    "#니다에 결합된 친구들\n",
    "#'ㅂ니다'를 'ㄴ다'로\n",
    "니다_결합1 = ['답니다', 'ㄴ답니다', '렙니다', '랍니다', '십니다', '읍니다', '더랍니다', '렵니다', '풉니다', '뜹니다', '툽니다', '춥니다', '찹니다', '앱니다', '옵니다', '챕니다', '귑니다', '줍니다', '합니다']\n",
    "#'ㅂ니다'를 '다'로\n",
    "니다_결합2 = ['입니다', '섭니다', '겁니다', 'ㄹ겁니다', '읩니다', '아입니다']\n",
    "\n",
    "yoo_low = ['을까', 'ㄹ까', '지', '으니까', '어', '는데', 'ㄴ가', 'ㄹ게', '래', '잖아', '네', '여', 'ㄹ래', '게', '나', '군', '을게', '다고', '지만', '은데', 'ㄴ지', '는지', '라고', 'ㄴ데', '는걸', '아서', '거든', '더라고', '어서', '려고', '을래', '대', 'ㄴ대', '던데', '더군', '여서', '건가', '어야지', 'ㄹ걸', 'ㄹ께', '아야지', '다면서', '는군', 'ㄴ다고', '은가', '다니', '다면', '실까', '가', '신가', '서', '까', '다니까', '데', '다던데', '다는데', '랄까', '거나', '라던데', '던가']\n",
    "\n",
    "\n",
    "def Changer(input):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    analyzed = api.analyze(input)  \n",
    "    for data in analyzed:\n",
    "        lis_word = []\n",
    "        lis_tag = []\n",
    "        for morph in data.morphs:\n",
    "            lis_word.append(morph.lex)\n",
    "            lis_tag.append(morph.tag)\n",
    "        print(lis_word)\n",
    "        print(lis_tag)\n",
    "        print(\"====================\")\n",
    "        try:\n",
    "            lis_tag.index('EF')\n",
    "            result.append(to_low(data.lex,lis_word,lis_tag))\n",
    "        except:\n",
    "            if len(lis_tag) == 2 and lis_tag[0] == \"NP\" and (\"JK\" in lis_tag[1] or \"JX\" == lis_tag[1]):\n",
    "                if lis_word[0] == \"저\":\n",
    "                    lis_word[0] = \"나\"\n",
    "                    if lis_word[1] == \"ㄴ\":\n",
    "                        result.append(\"난\")\n",
    "                    elif lis_word[1] == \"ㄹ\":\n",
    "                        result.append(\"날\")\n",
    "                    else:\n",
    "                        result.append(''.join(lis_word))\n",
    "                elif lis_word[0] == \"당신\":\n",
    "                    lis_word[0] = \"너\"\n",
    "                    if lis_word[1] == \"은\":\n",
    "                        result.append(\"너는\")\n",
    "                    elif lis_word[1] == \"을\":\n",
    "                        result.append(\"너를\")\n",
    "                    elif lis_word[1] == \"이랑\":\n",
    "                        result.append(\"너랑\")\n",
    "                    elif lis_word[1] == \"이\":\n",
    "                        result.append(\"너가\")\n",
    "                    else:\n",
    "                        if lis_word[1] == \"과\":\n",
    "                            lis_word[1] == \"와\"\n",
    "                        result.append(''.join(lis_word))\n",
    "                elif data.lex == \"제가\":\n",
    "                    result.append(\"내가\")\n",
    "                elif data.lex == \"당신이\":\n",
    "                    result.append(\"네가\")\n",
    "                else:\n",
    "                    result.append(data.lex)\n",
    "            else:\n",
    "                result.append(data.lex)\n",
    "        \n",
    "    return ' '.join(result)\n",
    "    \n",
    "def to_low(result, lis_word, lis_tag):\n",
    "    print(lis_word)\n",
    "    print(lis_tag)\n",
    "    EF_indexs = [pos for pos, char in enumerate(lis_tag) if char == \"EF\"]\n",
    "    EF_index = EF_indexs[-1]\n",
    "    EF = lis_word[EF_index]\n",
    "    EF_next = lis_word[EF_index+1]\n",
    "    EF_front = lis_word[EF_index-1]\n",
    "    tag_front = lis_tag[EF_index-1]\n",
    "    if is_hangul(EF_next):\n",
    "        return result\n",
    "    \n",
    "    #다로 끝나는 친구들\n",
    "    if EF == \"ㅂ니다\":\n",
    "        if tag_front in q_nida2s_da:\n",
    "            result = join_jamos(split_syllables(result).replace('ㅂㄴㅣ_ㄷㅏ_'+EF_next, 'ㄴㄷㅏ_'+EF_next))\n",
    "        if tag_front in q_nida2da:\n",
    "            if tag_front == 'VA' and (EF_front == \"하\" or EF_front == \"나\" or EF_front == \"지\" or EF_front == \"원하\"):\n",
    "                result = join_jamos(split_syllables(result).replace('ㅂㄴㅣ_ㄷㅏ_'+EF_next, 'ㄴㄷㅏ_'+EF_next))\n",
    "            else:\n",
    "                result = join_jamos(split_syllables(result).replace('ㅂㄴㅣ_ㄷㅏ_'+EF_next, '_ㄷㅏ_'+EF_next))\n",
    "    elif EF == \"습니다\":\n",
    "        result = result.replace(EF + EF_next, \"다\" + EF_next)\n",
    "    elif EF == \"뭅니다\":\n",
    "        result = join_jamos(split_syllables(result).replace('ㅂㄴㅣ_ㄷㅏ_'+EF_next, 'ㄹㄷㅏ_'+EF_next))\n",
    "    elif EF in 니다_결합1:\n",
    "        result = join_jamos(split_syllables(result).replace('ㅂㄴㅣ_ㄷㅏ_'+EF_next, 'ㄴㄷㅏ_'+EF_next))\n",
    "    elif EF in 니다_결합2:\n",
    "        result = join_jamos(split_syllables(result).replace('ㅂㄴㅣ_ㄷㅏ_'+EF_next, '_ㄷㅏ_'+EF_next))\n",
    "    elif EF[:-1] in yoo_low:\n",
    "        result = result.replace(\"요\" + EF_next, EF_next)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b182cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘']\n",
      "['NNG']\n",
      "====================\n",
      "['저녁', '에', '요', '?']\n",
      "['NNG', 'JKB', 'EF', 'SF']\n",
      "====================\n",
      "['저녁', '에', '요', '?']\n",
      "['NNG', 'JKB', 'EF', 'SF']\n",
      "오늘 저녁에요?\n"
     ]
    }
   ],
   "source": [
    "txt = \"오늘 저녁에요?\"\n",
    "print(Changer(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6deda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "==========\n",
      "64 512 None\n",
      "ConcatLinear(\n",
      "  (_layer): Linear(in_features=65, out_features=512, bias=True)\n",
      ")\n",
      "512 512 None\n",
      "ConcatLinear(\n",
      "  (_layer): Linear(in_features=513, out_features=512, bias=True)\n",
      ")\n",
      "512 64 None\n",
      "ConcatLinear(\n",
      "  (_layer): Linear(in_features=513, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConcatLinear(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ConcatLinear, self).__init__()\n",
    "        self._layer = nn.Linear(dim_in + 1, dim_out)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        tt = torch.ones_like(x[:, :1]) * t\n",
    "        ttx = torch.cat([tt, x], 1)\n",
    "        return self._layer(ttx)\n",
    "\n",
    "z_size = 64\n",
    "input_shape = (z_size,)\n",
    "hidden_shape = input_shape\n",
    "print(hidden_shape)\n",
    "dims = \"512-512\"\n",
    "hidden_dims = tuple(map(int, dims.split(\"-\")))\n",
    "strides = [None] * (len(hidden_dims) + 1)\n",
    "\n",
    "print(\"==========\")\n",
    "for dim_out, stride in zip(hidden_dims + (input_shape[0],), strides):\n",
    "    if stride is None:\n",
    "        layer_kwargs = {}\n",
    "    print(hidden_shape[0],dim_out, stride)\n",
    "    print(ConcatLinear(hidden_shape[0],dim_out,**layer_kwargs))\n",
    "    \n",
    "    hidden_shape = list(copy.copy(hidden_shape))\n",
    "    hidden_shape[0] = dim_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db155d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = [1,28,28]\n",
    "input_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e9fad3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ec3195e06b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mConcatLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden_s' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConcatLinear(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ConcatLinear, self).__init__()\n",
    "        self._layer = nn.Linear(dim_in + 1, dim_out)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        tt = torch.ones_like(x[:, :1]) * t\n",
    "        ttx = torch.cat([tt, x], 1)\n",
    "        return self._layer(ttx)\n",
    "    \n",
    "    \n",
    "ConcatLinear(hidden_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea8ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "519281d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from konlpy.tag import Hannanum, Mecab\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "from tqdm.auto import tqdm\n",
    "from kiwipiepy import Kiwi\n",
    "import re\n",
    "from pykospacing import Spacing\n",
    "#if you use window, import eungeon instand of konlpy\n",
    "#from eunjeon import Mecab\n",
    "\n",
    "han = Hannanum()\n",
    "mec = Mecab()\n",
    "\n",
    "number = 100\n",
    "\n",
    "# 초성 리스트. 00 ~ 18\n",
    "CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "# 중성 리스트. 00 ~ 20\n",
    "JUNGSUNG_LIST = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "# 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "JONGSUNG_LIST = ['_', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "##높임말 리스트. 다음에 해당하면 높임말로 판단한다.\n",
    "H_LIST = ['니다', '니까', '요', '시오', '죠']\n",
    "\n",
    "##높임말로 변환할 때 중성끼리 합치는 경우가 있다. 그러한 경우 합치기 위한 사전이다. \n",
    "con_dict = [\n",
    "    \n",
    "    ['ㅏㅣ','ㅐ'], ['ㅑㅣ','ㅒ'], ['ㅓㅣ','ㅔ'],\n",
    "    ['ㅕㅣ','ㅖ'], ['ㅗㅣ','ㅚ'], ['ㅗㅐ','ㅙ'],\n",
    "    ['ㅜㅓ','ㅝ'], ['ㅜㅔ','ㅞ'], ['ㅡㅣ','ㅢ'],\n",
    "    ['ㅣㅏ','ㅑ'], ['ㅣㅓ','ㅕ'], ['ㅣㅗ','ㅛ'],\n",
    "    ['ㅣㅜ','ㅠ'], ['ㅡㅓ','ㅓ']\n",
    "    \n",
    "]\n",
    "\n",
    "####high -> low Dictionary####\n",
    "\n",
    "##EF(종결어미): 형태소 분류 시 종결어미가 단독으로 분석 되는 경우\n",
    "EF_ONLY = [\n",
    "    \n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']], #ex)'습니다'-> '다'\n",
    "    [['ㄴ','ㅏ','ㅇ','ㅛ'],['ㄴ','ㅏ']],\n",
    "    [['ㄷ','ㅐ','ㅇ','ㅛ'],['ㄷ','ㅐ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄴ','ㅔ','ㅇ','ㅛ'],['ㄷ','ㅏ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅈ','ㅛ'],['ㅈ','ㅣ']],\n",
    "    [['ㅇ','ㅏ','ㅇ','ㅛ'],['ㅇ','ㅏ']],\n",
    "    [['ㅇ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㅇ','ㅡ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ','ㅇ','ㅛ'],['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ']],\n",
    "    #[['ㅎ','ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅎ','ㅇ','ㅏ']],\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅓ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅇ','ㅛ'],['']],\n",
    "    \n",
    "]\n",
    "\n",
    "#EP(선어말어미)+EF(종결어미)로 형태소가 분석될 경우\n",
    "EP_EF = [\n",
    "    \n",
    "    [['ㅅ','ㅔ','ㅇ','ㅛ'],['special']]\n",
    "    #-시오 family\n",
    "    ,[['ㅡ','ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㅓ']]\n",
    "    ,[['ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㄹ', 'ㅏ']],\n",
    "    [['ㅅ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅣ']],\n",
    "    [['ㅅ','ㅣ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ'],['ㄹ','ㄹ','ㅐ']],\n",
    "]\n",
    "\n",
    "#VCP+EF\n",
    "VCP_EF = [\n",
    "    \n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㅇ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅈ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅖ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄱ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ']],\n",
    "    \n",
    "]\n",
    "\n",
    "#XSA+EF\n",
    "XSA_EF = [\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "#XSV+EF\n",
    "XSV_EF = [\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅎ','ㅐ','ㅇ','ㅛ'],['ㅎ','ㅏ','ㅈ','ㅏ']],\n",
    "]\n",
    "\n",
    "#alpha+EF: 위의 경우를 제외한 나머지 경우를 의미한다. \n",
    "A_EF = [\n",
    "    [['ㄱ','ㅓ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㄱ','ㅖ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅆ','ㅇ','ㅓ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "##높임표현이 어말어미가 아닌 경우##\n",
    "# - 기존의 변환 방식이었다. 이제는 쓰지는 않지만, 코드의 오류가 발생할 가능성이 있기에 지우지 않았다. 따로 참고할 필요 없음.\n",
    "EF = [\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [[' ','ㅈ','ㅓ','ㄴ',' '],['ㄴ','ㅏ','_','ㄴ','ㅡ','ㄴ']],\n",
    "    [['ㅇ','ㅓ','_','ㅇ','ㅛ','_'],['ㄷ','ㅏ','_']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    #,[['ㅅ','ㅔ'],['ㅝ'],['ㅘ']]\n",
    "]\n",
    "\n",
    "NP = [\n",
    "    \n",
    "    [['ㅈ','ㅓ','ㄴ'],['ㄴ','ㅏ','ㄴ']],\n",
    "    [['ㅈ','ㅓ'],['ㄴ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "# 보조사\n",
    "JX = [\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "VX = [\n",
    "    \n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']]\n",
    "    \n",
    "]\n",
    "\n",
    "VV = [\n",
    "    \n",
    "    [['ㅇ','ㅗ'],['ㅇ','ㅗ'],['ㅇ','ㅘ']],\n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']],\n",
    "    [['ㅎ','ㅏ'],['ㅎ','ㅏ'],['ㅎ','ㅐ']]\n",
    "    \n",
    "]\n",
    "\n",
    "XR = [\n",
    "    [['ㅈ','ㅚ','ㅅ','ㅗ','ㅇ'],['ㅁ','ㅣ','ㅇ','ㅏ','ㄴ'] ]\n",
    "]\n",
    "\n",
    "NNG = [\n",
    "    [['ㅈ','ㅏ','ㅇ','ㅛ'],['ㅈ','ㅏ']],\n",
    "    [['ㄱ','ㅏ','ㅁ','ㅅ','ㅏ'],['ㅈ','ㅏ']],\n",
    "]\n",
    "\n",
    "#Not Use\n",
    "# EXC = [\n",
    "    \n",
    "#     ['ㅜ',1],\n",
    "#     ['ㅗ',2],\n",
    "#     ['ㅏ',3]\n",
    "    \n",
    "# ]\n",
    "\n",
    "# EXC_word = [\n",
    "    \n",
    "#     ['ㅅㅔ',2]\n",
    "#     ,['ㅅㅣㅂ',2]\n",
    "    \n",
    "# ]\n",
    "\n",
    "EXC_deal = [\n",
    "    \n",
    "    ['ㅅㅔㅇㅛ', ['ㅏ','ㅣ'],['ㅜ','ㅓ'],['ㅡ','ㅓ']]\n",
    "    \n",
    "]\n",
    "\n",
    "EXC_tags = [\n",
    "    \n",
    "    'EP',\n",
    "    'EF'\n",
    "    \n",
    "]\n",
    "\n",
    "####End of high -> low Dictionary####\n",
    "\n",
    "\n",
    "#### low -> high Dictionary####\n",
    "## 사전의 순서가 중요하다. 순서를 임의로 바꾸지 말 것\n",
    "## EF solo. EF 앞에 형태소가 결합형이 아닌 홀로 분석 될 경우 ex) /EP, /EF\n",
    "EF_ONLY_4S = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['special']],\n",
    "    [['ㅇ','ㅓ','ㄹ','ㅏ'],['ㅇ','ㅡ','ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅇ','ㅓ'],['ㅇ','ㅓ','ㅇ','ㅛ']],\n",
    "    #'-라' /EF\n",
    "    [['ㄷ','ㅓ','ㄹ','ㅏ'],['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    # -데 /EF\n",
    "    [['ㅇ','ㅡ','ㄴ','ㄷ','ㅔ'],['ㅇ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ'],['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "    [['ㅈ','ㅏ','ㄴ','ㅎ','ㅇ','ㅏ'],['ㅈ','ㅏ','ㄴ','ㅎ','ㅇ','ㅏ','ㅇ','ㅛ']], ## -잖아 -> -잖아요\n",
    "    \n",
    "]\n",
    "## EF 결합형\n",
    "## EF 앞에 형태소가 결합형인 경우 앞의 형태소도 고려해서 처리해야 한다. ex) /EP, /EF\n",
    "EF_ONLY_4C = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅓ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅓ','ㄸ','ㅐ'],['ㅇ','ㅓ','ㄸ','ㅐ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "\n",
    "VCP_EF_4 = [\n",
    "    \n",
    "    [['ㄱ','ㅓ','ㄹ'],['ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "\n",
    "EF_AFTER_VCP_4 = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "##add code_JH\n",
    "NNB_JKO_4 = [\n",
    "    [['ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "]\n",
    "\n",
    "#### End of low -> high Dictionary####\n",
    "\n",
    "#### Common Dictionary ####\n",
    "#Yes or No\n",
    "IC =[\n",
    "    [['ㄴ','ㅔ'],['ㅇ','ㅡ','ㅇ']],\n",
    "    [['ㅇ','ㅏ','ㄴ','ㅣ','ㅇ','ㅛ'],['ㅇ','ㅏ','ㄴ','ㅣ']],\n",
    "    [['ㄴ','ㅔ'],['ㄱ','ㅡ','ㄹ','ㅐ']],\n",
    "]\n",
    "\n",
    "#### End of Common Dictionary ####\n",
    "def unite(input, dict):\n",
    "    for i in dict:\n",
    "        input = re.sub(i[0],i[1],input)\n",
    "    return input\n",
    "    \n",
    "## 자모 단위로 문장을 나누고 합칠 때 쓰는 class ##\n",
    "class Jamodealer:\n",
    "    jamo = []\n",
    "    pp = ''\n",
    "    #각 단어들을 받아와서 자모단위로 나눈다.\n",
    "    def __init__(self,lis_word):\n",
    "    \n",
    "        self.jamo = []\n",
    "        for i in lis_word:\n",
    "            self.jamo.append(split_syllables(i))\n",
    "    \n",
    "    ##사전에서 변환된 자모단위로 분리된 문장을 합칠 때 쓰는 함수이다.     \n",
    "    def make_one(self):\n",
    "        #list 형태로 저장된 자모들의 집합을 하나의 string pp에 저장한다. \n",
    "        self.pp = ''\n",
    "        for i in self.jamo:\n",
    "             self.pp= self.pp+i\n",
    "        ##종성과 종성을 합쳐야 하는 경우가 있다면 합친다.        \n",
    "        self.pp = unite(self.pp, con_dict)\n",
    "        \n",
    "        #자모 단위의 string에서 자모 단위로 사전을 만들고 거기에 index를 부여한다.        \n",
    "        chars = list(set(self.pp))\n",
    "        char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "        ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "        #자모 단위로 분리되었던 문장을 다시 하나로 합친다.\n",
    "        jamo_numbers = [char_to_ix[x] for x in self.pp]\n",
    "        restored_jamo = ''.join([ix_to_char[x] for x in jamo_numbers])\n",
    "        #합쳐진 문장을 return 한다.\n",
    "        restored_text = join_jamos(restored_jamo)\n",
    "        return restored_text\n",
    "##End of Jamodealer class##\n",
    "\n",
    "def tojamo(korean_word):\n",
    "    r_lst = []\n",
    "    for w in list(korean_word.strip()):\n",
    "        ## 영어인 경우 구분해서 작성함. \n",
    "        if '가'<=w<='힣':\n",
    "            ## 588개 마다 초성이 바뀜. \n",
    "            ch1 = (ord(w) - ord('가'))//588\n",
    "            ## 중성은 총 28가지 종류\n",
    "            ch2 = ((ord(w) - ord('가')) - (588*ch1)) // 28\n",
    "            ch3 = (ord(w) - ord('가')) - (588*ch1) - 28*ch2\n",
    "            r_lst.append([CHOSUNG_LIST[ch1], JUNGSUNG_LIST[ch2], JONGSUNG_LIST[ch3]])\n",
    "        else:\n",
    "            r_lst.append([w])\n",
    "    return r_lst\n",
    "\n",
    "#Use in makestrdict\n",
    "#Convert list to String\n",
    "def li2str(input):\n",
    "    st = \"\"\n",
    "    for i in input:\n",
    "        st = st+i\n",
    "    return st\n",
    "\n",
    "##Used when make dictionaries\n",
    "def makestrdict(input):\n",
    "    result = []\n",
    "    for i in input:\n",
    "        bullet = []\n",
    "        for j in range(len(i)):\n",
    "            gre = li2str(i[j])\n",
    "            bullet.append(gre)\n",
    "        result.append(bullet)\n",
    "    return result\n",
    "\n",
    "### *추가한 사전에 대한 str 사전을 생성, mapping 시키는 부분* ###\n",
    "\n",
    "# * 기존의 방식은 다음과 같다. 어말어미는 어말어미 변환 방식 코드를 참고하면 된다.\n",
    "# - 앞으로  사전을 추가하고 싶으면 여기서 코드를 추가하고 수정하면 된다.\n",
    "# - dictionary를 만들고 해당 형태소에 해당하는 dictionary를 추가하면 된다.\n",
    "#   예를 들어, EP(선어말어미)에 대한 사전을 만들고 싶다면 EP_dict = makestrdict(EP)를 선언하고\n",
    "#   Dict_list에 'EP'를 추가하면 된다. 그 후 Mapping이 되도록 Dict_map에도 생성한 EP_dict를 추가하면 된다.\n",
    "\n",
    "#EP_dict = makestrdict(EP)\n",
    "EF_dict = makestrdict(EF)\n",
    "NP_dict = makestrdict(NP)\n",
    "JX_dict = makestrdict(JX)\n",
    "VX_dict = makestrdict(VX)\n",
    "VV_dict = makestrdict(VV)\n",
    "XR_dict = makestrdict(XR)\n",
    "NNG_dict = makestrdict(NNG)\n",
    "\n",
    "Dict_list=['EF','NP','JX','VX','VV','XR','NNG']\n",
    "\n",
    "Dict_map = [EF_dict,NP_dict,JX_dict,VX_dict, VV_dict, XR_dict, NNG_dict]\n",
    "\n",
    "##현재의 어말어미 변환방식은 밑에 코드를 추가, 변경하면 된다. \n",
    "#high->low of string dictionary\n",
    "EF_ONLY_dict = makestrdict(EF_ONLY)\n",
    "EP_EF_dict = makestrdict(EP_EF)\n",
    "VCP_EF_dict = makestrdict(VCP_EF)\n",
    "A_EF_dict = makestrdict(A_EF)\n",
    "XSA_EF_dict = makestrdict(XSA_EF)\n",
    "XSV_EF_dict = makestrdict(XSV_EF)\n",
    "\n",
    "#low->high of string dictionary\n",
    "EF_ONLY_4S_dict = makestrdict(EF_ONLY_4S)\n",
    "EF_ONLY_4C_dict = makestrdict(EF_ONLY_4C)\n",
    "EF_AFTER_VCP_4_dict = makestrdict(EF_AFTER_VCP_4)\n",
    "VCP_EF_4_dict = makestrdict(VCP_EF_4)\n",
    "\n",
    "NNB_JKO_4_dict = makestrdict(NNB_JKO_4)##add code_JH\n",
    "\n",
    "##Use in Changer\n",
    "def to2lists(input):\n",
    "    lis_word = []\n",
    "    lis_tag = []\n",
    "    #data = han.pos(input,ntags=22,flatten=True, join=False)\n",
    "    data = mec.pos(input)\n",
    "    for i in data:\n",
    "        lis_word.append(i[0])\n",
    "        lis_tag.append(i[1])\n",
    "    return lis_word, lis_tag\n",
    "\n",
    "#add in 2021.09.26\n",
    "\n",
    "#space의 index 찾는다.\n",
    "#indee와 ind_lili는 문장의 space를 찾아 변환하고 그 위치에 다시 space를 넣기 위한 함수이다.\n",
    "def indee(lis, input):\n",
    "    \n",
    "    rlis = []\n",
    "    \n",
    "    for i in range(len(lis)):\n",
    "        if lis[i]==input:\n",
    "            rlis.append(i)\n",
    "            \n",
    "    for i in range(len(rlis)):\n",
    "        rlis[i] = rlis[i]-i      \n",
    "    return rlis\n",
    "\n",
    "def ind_lili(lis_space,lis_lis):\n",
    "    \n",
    "    rlis = []\n",
    "    k=0\n",
    "    for i in range(len(lis_lis)):\n",
    "        \n",
    "        if k in lis_space:\n",
    "            rlis.append(i)\n",
    "            \n",
    "        k = k+len(lis_lis[i])\n",
    "        \n",
    "    #print(rlis)  \n",
    "    return rlis\n",
    "\n",
    "def union(lis, lis_lis):\n",
    "    \n",
    "    k = 0\n",
    "    for i in lis:\n",
    "        lis_lis.insert(i+k,' ')\n",
    "        k = k+1\n",
    "\n",
    "## Main Class ## \n",
    "class Changer(object):\n",
    "    \n",
    "    ## High -> Low ##    \n",
    "    def high_low(self, stc):\n",
    "        result = stc\n",
    "        ##remember space\n",
    "        space_list = indee(stc,' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = ind_lili(space_list, lis_word)\n",
    "        #자모 단위로 분리\n",
    "        #split to Jamo(morphology)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        lis = []\n",
    "        key = -1\n",
    "        #높임말인지 확인-> 문장 끝 어말 어미를 보고 판단\n",
    "        for i in H_LIST:\n",
    "            if i in lis_word[-2]:\n",
    "                key = 1\n",
    "        #if key>0:\n",
    "        if key>0 or key<0:  ##반말은 안 건드리도록 설정이 되어있다.    \n",
    "            for i in range(len(lis_tag)):\n",
    "                res = jam.jamo[i]\n",
    "                #해당하는 높임말 사전을 dic에 저장\n",
    "                for k in range(len(Dict_list)):\n",
    "                    dic = []\n",
    "                    if 'EF' in lis_tag[i]:\n",
    "                        if 'EF' == lis_tag[i]:\n",
    "                            dic = EF_ONLY_dict\n",
    "                        elif 'EP' in lis_tag[i]:\n",
    "                            dic = EP_EF_dict\n",
    "                        elif 'VCP' in lis_tag[i]:\n",
    "                            dic = VCP_EF_dict\n",
    "                        else:\n",
    "                            dic = A_EF_dict\n",
    "                        \n",
    "                    elif Dict_list[k] in lis_tag[i]:\n",
    "                        dic = Dict_map[Dict_list.index(Dict_list[k])]\n",
    "                        #res = jam.jamo[i]\n",
    "                    for j in range(len(dic)):\n",
    "                        if self.isExcept(dic[j])==1:\n",
    "                            #ind = self.indicator(i,jam.jamo,lis_tag,EXC_word, EXC_tags)\n",
    "                            #예외처리를 해야하는 종결 어미라면 예외처리 사전을 참고한다. EXC_deal 참고\n",
    "                            for q in range(len(EXC_deal)):\n",
    "                                if dic[j][0]==EXC_deal[q][0]:\n",
    "                                    for r in range(1,len(EXC_deal[q])):\n",
    "                                        if jam.jamo[i-1][-1]==EXC_deal[q][r][0]:\n",
    "                                            res = re.sub(dic[j][0],EXC_deal[q][r][1],res);\n",
    "                            #res = re.sub(dic[j][0],dic[j][ind],res)\n",
    "                        else:\n",
    "                            #print('tt')\n",
    "                            res = re.sub(dic[j][0],dic[j][1],res)\n",
    "                            \n",
    "                        #jam.jamo[i] = res\n",
    "                lis.append(res)\n",
    "            \n",
    "            \n",
    "            #print(jam.jamo[i])\n",
    "        \n",
    "        union(space_location, lis)\n",
    "        jam.jamo = []\n",
    "        for i in range(len(lis)):\n",
    "            jam.jamo.append(lis[i])\n",
    "            #print(lis[i])\n",
    "        \n",
    "        #union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "    \n",
    "    def low_high(self, stc):\n",
    "        result = stc\n",
    "        \n",
    "        space_list = indee(stc, ' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = ind_lili(space_list, lis_word)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        lis = []\n",
    "        key = -1\n",
    "        \n",
    "        for i in H_LIST:\n",
    "            if i not in lis_word[-2]: # 종성이 높임말 리스트와 일치하지 않다면 key는 1이 된다.\n",
    "                key = 1        \n",
    "\n",
    "        #if key>0:\n",
    "        #if key>0 or key<0: # **!edit\n",
    "        if key >0:\n",
    "            res = jam.jamo[-2]\n",
    "            dic = []\n",
    "            if 'EF' in lis_tag[-2]:\n",
    "                \n",
    "                if 'EF' == lis_tag[-2]:\n",
    "                    if '+' in lis_tag[-3]:\n",
    "                        dic = EF_ONLY_4C_dict\n",
    "                    elif lis_tag[-3]=='VCP':\n",
    "                        dic = EF_AFTER_VCP_4_dict\n",
    "                    else:\n",
    "                        dic = EF_ONLY_4S_dict\n",
    "                elif 'EP' in lis_tag[-2]:\n",
    "                    dic = EP_EF_dict\n",
    "                elif 'VCP' in lis_tag[-2]:\n",
    "                    dic = VCP_EF_4_dict\n",
    "                else:\n",
    "                    dic = A_EF_dict\n",
    "                    \n",
    "            for i in range(len(dic)):\n",
    "                if len(dic[i])>2:\n",
    "                    res = re.sub(dic[i][0],dic[i][1],res)\n",
    "                else:\n",
    "                    res = re.sub(dic[i][0],dic[i][1],res)\n",
    "            jam.jamo[-2] = res\n",
    "            \n",
    "        union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    def isExcept(self, input):\n",
    "        if input[1]=='special':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def indicator(self, ind, lis, tag, ex_word, exc_tags):\n",
    "        re = 1\n",
    "        for j in range(len(ex_word)):\n",
    "            if exc_tags[j] in tag[ind+1]:\n",
    "                for i in range(len(ex_word)):\n",
    "                    if ex_word[i][0] in lis[ind+1]:\n",
    "                       \n",
    "                        re = ex_word[i][1]\n",
    "                        break\n",
    "                        \n",
    "                        print(lis[ind-1])\n",
    "        return re\n",
    "        \n",
    "        \n",
    "    def processText(self,stc):\n",
    "        result = stc\n",
    "        res = self.high_low(result)\n",
    "        #spacing = Spacing()\n",
    "        #res = spacing(res)\n",
    "        return res\n",
    "    ##change function name\n",
    "    def processText_convertHigh(self,stc):\n",
    "        result = stc\n",
    "        res = self.low_high(result)\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df86f61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "밥이 식기 전에 어서 먹어.\n",
      "다들 알겠는데요.\n"
     ]
    }
   ],
   "source": [
    "## Test convertion\n",
    "#txt = '전 그것이 맞다고 생각합니다.'\n",
    "tx = '밥이 식기 전에 어서 먹으세요.'\n",
    "ch = Changer()\n",
    "#tt = ch.processText(txt)\n",
    "ttt = ch.processText(tx)\n",
    "text_low = '다들 알겠는데.'\n",
    "\n",
    "converted_txt = ch.processText_convertHigh(text_low)\n",
    "print(ttt)\n",
    "print(converted_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ffa0983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27일은 괜찮나요?\n",
      "중단시켜서 죄송해.\n",
      "중단시켜서 죄송해.\n",
      "아, 이런! 도저히 생각이 안 나는걸.\n",
      "Joe's Café 라는 레스토랑에 가고 싶은데, 알고 있어?\n",
      "보다 나은 건강과 생활 회사의 글렌 토마스입니다.\n",
      "스타워즈는 어때?\n",
      "데이터 코디네이터나 데이터 매니저가 어떨까요?\n",
      "화성에서 온 로봇이요! 좋아요! 특수 효과가 대단하대요.\n",
      "팩스를 보내줘서 감사한다.\n",
      "11월30일 날짜로 팩스를 보내줘서 감사한다.\n",
      "자격을 취득하기 위해 공부 중이에요.\n",
      "간호사 자격을 취득하기 위해 공부 중이에요.\n",
      "국가시험을 향해 공부 중이에요.\n",
      "공무원에 되기 위한 국가시험을 향해 공부 중이에요.\n",
      "잘 됐어요. 그럼 이제 집에 가도 되나요?\n",
      "죄송합니다. 그녀는 안에 없네요. 메모 남겨 드릴까?\n",
      "내려 줄래.\n",
      "올려 줄래.\n",
      "작은 목소리\n",
      "스미스 선생님. 저 화장실에 가야겠는데요요.\n",
      "화장실이 정말 급해!\n",
      "그럼 총수입의 얼마나 되는 거죠?\n",
      "0136521798이에요.\n",
      "1,199달러예요?\n",
      "100그램에 비타민C의 함유량은 레몬보다 높습니습니다.\n",
      "100미터 더 가서 좌회전해.\n",
      "105번이 그 근처에 서는 것 같은데, 확실하진 않아요.\n",
      "낸시에게 물어 보세요. 낸시는 나보다 더 자주 그 버스를 이용하거든요.\n",
      "105편의 탑승게이트는 변경되었습니까?\n",
      "10분 정도 후에 다시 걸어주special.\n",
      "10분 후에 다시 걸죠.\n",
      "10분 후에 와.\n",
      "10분정도 기다리실 수 있습니까?\n",
      "10세 여자 아이의 선물로는 무엇이 좋을 것 같습니까?\n",
      "10시 정각이에요.\n",
      "10시 정각이에요.\n",
      "10시쯤에 목욕해.\n",
      "10일에는 바쁘니?\n",
      "11번가와 브로드웨이가 만나는 모퉁이로 가는 버스가 있나요?\n",
      "123호실 좀 대 주special?\n",
      "123호실이오.\n",
      "125쪽입니다.\n",
      "12시부터 1시까지예요.\n",
      "12시쯤에 자요.\n",
      "12일 월요일에 뉴욕에서 필라델피아로 가는 표를 구하려고 하는데요요.\n",
      "12페이지 밖에 안 돼요. 인쇄하는데 오래 걸리지 않을 거예요.\n",
      "14달러 47센트입니다. 정말 죄송한다.\n",
      "15분 쯤 뒤에 내 방으로 와 줄래?\n",
      "15세이기때문에 술은 마실 수 없습니습니다.\n",
      "15일이에요.\n",
      "17일은 몇 요일이에요?\n",
      "1981년에 태어났습니다요.\n",
      "1990년에 동화대학에 입학을 했습니다요.\n",
      "1995년에 고등학교를 졸업했습니다요.\n",
      "1개월 있을 예정입니다.\n",
      "1달러 50센트에요.\n",
      "1달러25센트예요.\n",
      "1박에 12달러밖에 안 돼.\n",
      "1번 전철을 타요.\n",
      "1시간 반정도 걸리나.\n",
      "1시간예요.\n",
      "1시반부터 3시까지예요.\n",
      "1주일정도 전부터 입니다.\n",
      "1킬로미터정도 되돌아가봐.\n",
      "2, 3시간이면 돌아올 것이라 생각이 되요.\n",
      "2,3개월 전이야.\n",
      "2,3년 전이야.\n",
      "2,3일 전부터 귀 울림이 있었습니습니다.\n",
      "2,3일 전부터 눈이 굉장히 가렵습니습니다.\n",
      "2,3일 전이야.\n",
      "2,3주일 전이야.\n",
      "2007년 6월이에요.\n",
      "20달러.\n",
      "20달러짜리 지폐 좀 잔돈으로 바꿔 주시겠어요요?\n",
      "20분 정도입니다.\n",
      "20분 후에 문 닫습니습니다.\n",
      "20센트자리 우표 3장이랑 50센트짜리 우표 2장 주special.\n",
      "20센트짜리 우표 5장 주special.\n",
      "20일의 오전 중이에요.\n",
      "20일의 오후예요.\n",
      "20일이에요.\n",
      "21퍼센트가 약간 안 되죠.\n",
      "23달러 92센트 되겠습니습니다.\n",
      "23달러 92센트라. 그 금액이 확실한가?\n",
      "2개 살 테니까 조금 깎아 주special.\n",
      "2달러 20센트요, 허클베리 핀과 미국 단편 소설을 대출했군요.\n",
      "2달러 90센트입니다.\n",
      "2번 전철에 타요.\n",
      "2번이나 3번 계산대를 이용하라.\n",
      "2블럭을 걸어가요.\n",
      "2시 10분입니다.\n",
      "2시 조금 넘었어요요.\n",
      "2시10분 조금 넘었어요요.\n",
      "2시10분이에요.\n",
      "2시15분이에요.\n",
      "2시30분이에요.\n",
      "2시간이에요.\n",
      "2시간정도예요.\n",
      "2천달러입니다.\n",
      "2층이니까 에스컬레이터로 가도 되잖아.\n",
      "30분 내로 될 거요. 식탁이나 차리지 그래?\n",
      "30분 정도예요.\n",
      "30분정도입니다.\n",
      "30분쯤이요. 출발합니다. 안전벨트 매special.\n",
      "30세의 생일 축하해!\n",
      "30일은 괜찮아요.\n",
      "32달러 78센트입니다.\n",
      "38도 정도의 열이 있어요요.\n",
      "3교대로 운영하는 건 어떨까요?\n",
      "3년 전에 재혼했습니다요.\n",
      "3년 전이야.\n",
      "3년만인가요?\n",
      "3년전에 위궤양으로 입원했습니습니다.\n",
      "3시 몇 분 전이에요.\n",
      "3시5분 전이에요.\n",
      "3시가 어때?\n",
      "3시에서 5시까지 시간이 있어요요.\n",
      "3시쯤에 오세요. 아무것도 안 가져와도 되요. 구워 먹을 음식이 많이 있거든요.\n",
      "3일 빌리고 싶은데요요.\n",
      "3일 전이야.\n",
      "3일간 금연했지만, 담배를 피우지 못하니 죽을 것 같았어요요.\n",
      "3일날 셀러스 박사님 진료 예약을 할 수 있을까요?\n",
      "3일에 한 번 데이트를 해.\n",
      "3일정도 머무를 겁니다.\n",
      "3주 연휴는 어떻게 지냈습니다요?\n",
      "3주일 전이야.\n",
      "3주정도 된다.\n",
      "3층까지는 에스컬레이터로 가자.\n",
      "4년쯤 됐어요. 처음에는 텔레마케터로 시작했는데, 지금은 뉴잉글랜드 지역 담당 영업 대리예요.\n",
      "4명이에요.\n",
      "4번에서 8시부터하는 이 프로그램은 어때?\n",
      "4월25일이에요.\n",
      "500달러요.\n",
      "500달러짜리 여행자 수표를 사용할 수 있습니까?\n",
      "50달러짜리 10장, 10달러짜리 50장 부탁한다.\n",
      "50세 여성에게는 어떤 것이 좋습니까?\n",
      "555-3401입니다.\n",
      "555-8765입니다.\n",
      "55달러입니다.\n",
      "5갤런 부탁한다.\n",
      "5년전에 결혼했습니다요.\n",
      "5년전에 김 전기에 입사했습니다요.\n",
      "5달러75센트가 되겠습니습니다.\n",
      "5달러의 수수료가 듭니다.\n",
      "5달러짜리 두 개랑 나머지는 전부 1달러짜리로 주special?\n",
      "5대4라고요? 5대5인줄 알았는데요.\n",
      "5박을 했으면 하는데.\n",
      "5번 전철에 타요.\n",
      "5분 간격으로 와.\n",
      "5분만 더 잘게.\n",
      "5분후면 8시야.\n",
      "5시20분에 와.\n",
      "5시까지 도착해야 돼.\n",
      "5시반쯤에 만나요.\n",
      "5월초에 필기시험을 본다.\n",
      "5일간 정도예요.\n",
      "5일은 몇 요일이었어요요?\n",
      "600달러는 너무 싸요! 800달러가 어때?\n",
      "600달러만 좀 빌려줄래?\n",
      "6살짜리 딸이 천식이어서, 금연하기로 했습니습니다.\n",
      "6시 30분에 사무실 앞에서 만나요. 화랑은 여기서 조금만 걸어가면 돼.\n",
      "6시까지이구요. 내일 아침 8시에 다시 문을 열어요요.\n",
      "6시반에 일어나요.\n",
      "6시에 끝나요.\n",
      "6시요. 잘됐네요. 그럼 5시 30분쯤에 들를게요. 감사한다.\n",
      "6시인데, 저녁 먹으러 갑시다.\n",
      "6시쯤 약간의 지진이 일어났습니다.\n",
      "6시쯤에 끝나요.\n",
      "6월 21일 샌디이고 공항에서요.\n",
      "6일간이에요.\n",
      "76에 128이로군요. 그것도 좋습니습니다.\n",
      "798-092입니다.\n",
      "7과 1/2사이즈 정도 신을 거예요.\n",
      "7번 버스에 타요.\n",
      "7시 15분에 극장 앞에서 봐.\n",
      "7시 이후엔 시간이 있어요요.\n",
      "7시반에 집에서 나와.\n",
      "7시부터 8시까지 1시간입니다.\n",
      "7시에 아침밥을 먹어요요.\n",
      "7시예요.\n",
      "8사이즈도 한번 입어 봐야 될 것 같아요.\n",
      "8시 전에 집에 도착해.\n",
      "8월 3일부터 10일까지 사용할 방 있어요요?\n",
      "90026이에요.\n",
      "911에 전화 해주special.\n",
      "9년이요. 처음에는 아동 도서를 편집하는 준 편집 직원으로 시작해서 결국 젊은 독자부 편집장이 됐습니다요.\n",
      "9달러 95센트입니다.\n",
      "9시 25분 라 과르디아 공항을 출발하는 항공편이 있는데, 코네티컷 주의 하트 포드에 잠시 들렀다가 나서 11시 15분에 보스턴의 로건 공항에 도착한다.\n",
      "9시? 9시 15분에 병원 예약이 있는데. 좀 태워다 줄 수 있니?\n",
      "9시반부터 6시까지예요.\n",
      "9시반부터예요.\n",
      "9시부터 드라마를 봐도 되?\n",
      "9시부터입니다.\n",
      "9시에 약속이 있는데 늦으면 안 되거든.\n",
      "9월 20일 7872편, 인천행을 예약했습니습니다.\n",
      "이코노미 트리뷴 지에서 ABC 기업이 곧 생산을 증가시킬 거라던데요.\n",
      "ABC사는 힘든 상대라고 들었어요요.\n",
      "A열 10번 자리를 찾고 있는데요요.\n",
      "B 애비뉴에 있는 그 스테이크 식당 어때요? 전부터 거기에 가 보고 싶었거든요.\n"
     ]
    }
   ],
   "source": [
    "## For test sample convertion\n",
    "\n",
    "import pandas as pd\n",
    "number = 200\n",
    "texts = pd.read_table('./data/hgu_clean.kr', sep ='\\n')[:number]\n",
    "texts = texts['26일이요?']\n",
    "\n",
    "ch = Changer()\n",
    "\n",
    "for i in range(0, number):\n",
    "    tt = ch.processText_convertHigh(texts[i])\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89c4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Sample Data file ##\n",
    "\n",
    "number = 1858355\n",
    "texts = pd.read_table('./data/hgu_clean.kr', sep ='\\n')\n",
    "\n",
    "new_data = {\n",
    "    \n",
    "    '26일이요?':'26일이요?'\n",
    "    \n",
    "}\n",
    "\n",
    "idx = 0\n",
    "\n",
    "temp1 = texts[texts.index < idx]\n",
    "temp2 = texts[texts.index>= idx]\n",
    "\n",
    "texts = temp1.append(new_data,ignore_index=True).append(temp2, ignore_index=True)\n",
    "\n",
    "texts = texts['26일이요?']\n",
    "\n",
    "num = len(texts)\n",
    "\n",
    "ch = Changer()\n",
    "f = open('./hgu_clean.low.kr', 'w',encoding = 'utf-8')\n",
    "for i in range(0,num):\n",
    "    if texts[i][-1] !='?'and texts[i][-1] !='.' and texts[i][-1] !='!':\n",
    "        texts[i] = texts[i]+'.'\n",
    "    tt = ch.processText(texts[i])\n",
    "    f.write(tt)\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b63d5401",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2812b5e44662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;32mand\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ec5bb257d1b4>\u001b[0m in \u001b[0;36mprocessText\u001b[0;34m(self, stc)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocessText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_low\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0;31m#spacing = Spacing()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m#res = spacing(res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ec5bb257d1b4>\u001b[0m in \u001b[0;36mhigh_low\u001b[0;34m(self, stc)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mlis_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto2lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mspace_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_lili\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mjam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJamodealer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0mlis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ec5bb257d1b4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lis_word)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjamo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlis_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jh/lib/python3.9/site-packages/hangul_utils/unicode.py\u001b[0m in \u001b[0;36msplit_syllables\u001b[0;34m(s, ignore_err, pad)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jh/lib/python3.9/site-packages/hangul_utils/unicode.py\u001b[0m in \u001b[0;36mtry_split\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtry_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msplit_syllable_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mignore_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jh/lib/python3.9/site-packages/hangul_utils/unicode.py\u001b[0m in \u001b[0;36msplit_syllable_char\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mFINAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCHAR_INDICES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINITIAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "## Make Data file ##\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "texts1 = pd.read_table('./data/hgu_clean.kr.shuf', sep ='\\n')\n",
    "\n",
    "new_data = {\n",
    "    \n",
    "    '그것은 가솔린 수소 또는 전기 모터로 움직일 수 있다':'그것은 가솔린 수소 또는 전기 모터로 움직일 수 있다'\n",
    "    \n",
    "}\n",
    "\n",
    "idx = 0\n",
    "\n",
    "temp1 = texts1[texts1.index < idx]\n",
    "temp2 = texts1[texts1.index>= idx]\n",
    "\n",
    "texts1 = temp1.append(new_data,ignore_index=True).append(temp2, ignore_index=True)\n",
    "\n",
    "texts1 = texts1['그것은 가솔린 수소 또는 전기 모터로 움직일 수 있다']\n",
    "\n",
    "num = len(texts1)\n",
    "a = len(texts1)\n",
    "#print(a)\n",
    "ch = Changer()\n",
    "f = open('./hgu_clean.low.kr.shuf', 'w',encoding = 'utf-8')\n",
    "for i in range(0,num):\n",
    "    if texts1[i][-1] !='?'and texts1[i][-1] !='.' and texts1[i][-1] !='!':\n",
    "        texts1[i] = texts1[i]+'.'\n",
    "    tt = ch.processText(texts1[i])\n",
    "    f.write(tt)\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98918efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3e8026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from konlpy.tag import Hannanum\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "from tqdm.auto import tqdm\n",
    "from kiwipiepy import Kiwi\n",
    "import re\n",
    "from eunjeon import Mecab\n",
    "\n",
    "#import sys\n",
    "#import io\n",
    "#sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding = 'utf-8')\n",
    "#sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding = 'utf-8')\n",
    "\n",
    "han = Hannanum()\n",
    "mec = Mecab()\n",
    "\n",
    "number = 100\n",
    "\n",
    "# 초성 리스트. 00 ~ 18\n",
    "CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "# 중성 리스트. 00 ~ 20\n",
    "JUNGSUNG_LIST = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "# 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "JONGSUNG_LIST = ['_', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "H_LIST = ['니다', '니까', '요', '시오', '죠']\n",
    "\n",
    "con_dict = [\n",
    "    \n",
    "    ['ㅏㅣ','ㅐ'], ['ㅑㅣ','ㅒ'], ['ㅓㅣ','ㅔ'],\n",
    "    ['ㅕㅣ','ㅖ'], ['ㅗㅣ','ㅚ'], ['ㅗㅐ','ㅙ'],\n",
    "    ['ㅜㅓ','ㅝ'], ['ㅜㅔ','ㅞ'], ['ㅡㅣ','ㅢ'],\n",
    "    ['ㅣㅏ','ㅑ'], ['ㅣㅓ','ㅕ'], ['ㅣㅗ','ㅛ'],\n",
    "    ['ㅣㅜ','ㅠ'], ['ㅡㅓ','ㅓ']\n",
    "    \n",
    "]\n",
    "\n",
    "#high -> low 사전\n",
    "####high -> low Dictionary####\n",
    "\n",
    "##EF(종결어미): 형태소 분류 시 종결어미가 단독으로 분석 되는 경우\n",
    "EF_ONLY = [\n",
    "    \n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']], #ex)'습니다'-> '다'\n",
    "    [['ㄴ','ㅏ','ㅇ','ㅛ'],['ㄴ','ㅏ']],\n",
    "    [['ㄷ','ㅐ','ㅇ','ㅛ'],['ㄷ','ㅐ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄴ','ㅔ','ㅇ','ㅛ'],['ㄷ','ㅏ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅈ','ㅛ'],['ㅈ','ㅣ']],\n",
    "    [['ㅇ','ㅏ','ㅇ','ㅛ'],['ㅇ','ㅏ']],\n",
    "    [['ㅇ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㅇ','ㅡ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅓ']],\n",
    "    [['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ','ㅇ','ㅛ'],['ㄱ','ㅓ','ㄷ','ㅡ','ㄴ']],\n",
    "    #[['ㅎ','ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅎ','ㅇ','ㅏ']],\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅓ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ']],\n",
    "    [['ㅇ','ㅛ'],['']],\n",
    "    \n",
    "]\n",
    "\n",
    "#EP(선어말어미)+EF(종결어미)로 형태소가 분석될 경우\n",
    "EP_EF = [\n",
    "    \n",
    "    [['ㅅ','ㅔ','ㅇ','ㅛ'],['special']]\n",
    "    #-시오 family\n",
    "    ,[['ㅡ','ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㅓ']]\n",
    "    ,[['ㅅ','ㅣ','ㅂ','ㅅ','ㅣ','ㅇ','ㅗ'],['ㄹ', 'ㅏ']],\n",
    "    [['ㅅ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅣ']],\n",
    "    [['ㅅ','ㅣ','ㄹ','ㄹ','ㅐ','ㅇ','ㅛ'],['ㄹ','ㄹ','ㅐ']],\n",
    "]\n",
    "\n",
    "#VCP+EF\n",
    "VCP_EF = [\n",
    "    \n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㅇ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅣ','ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅈ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅖ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄱ','ㅓ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ'],['ㄹ','ㅏ','ㄷ','ㅓ','ㄴ','ㄷ','ㅔ']],\n",
    "    \n",
    "]\n",
    "\n",
    "#XSA+EF\n",
    "XSA_EF = [\n",
    "    [['ㅎ','ㅏ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㅎ','ㅏ','ㄷ','ㅏ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "#XSV+EF\n",
    "XSV_EF = [\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅎ','ㅐ','ㅇ','ㅛ'],['ㅎ','ㅏ','ㅈ','ㅏ']],\n",
    "]\n",
    "\n",
    "#alpha+EF: 위의 경우를 제외한 나머지 경우를 의미한다. \n",
    "A_EF = [\n",
    "    [['ㄱ','ㅓ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㄱ','ㅖ','ㅅ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅆ','ㅇ','ㅓ']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄲ','ㅏ'],['ㄴ','ㅏ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "##높임표현이 어말어미가 아닌 경우##\n",
    "# - 기존의 변환 방식이었다. 이제는 쓰지는 않지만, 코드의 오류가 발생할 가능성이 있기에 지우지 않았다. 따로 참고할 필요 없음.\n",
    "EF = [\n",
    "    [['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄷ','ㅏ']],\n",
    "    [[' ','ㅈ','ㅓ','ㄴ',' '],['ㄴ','ㅏ','_','ㄴ','ㅡ','ㄴ']],\n",
    "    [['ㅇ','ㅓ','_','ㅇ','ㅛ','_'],['ㄷ','ㅏ','_']],\n",
    "    [['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['ㄴ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅔ','ㅇ','ㅛ'],['ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "    #,[['ㅅ','ㅔ'],['ㅝ'],['ㅘ']]\n",
    "]\n",
    "\n",
    "NP = [\n",
    "    \n",
    "    #[['ㅈ','ㅓ','ㄴ','ㅈ','ㅜ'],[]]\n",
    "    [['ㅈ','ㅓ','ㄴ'],['special-']],\n",
    "    [['ㅈ','ㅓ'],['ㄴ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "# 보조사\n",
    "JX = [\n",
    "    [['ㅇ','ㅣ','ㅇ','ㅛ'],['ㅇ','ㅣ','ㅇ','ㅑ']],\n",
    "    [['ㅇ','ㅛ'],['']]\n",
    "]\n",
    "\n",
    "VX = [\n",
    "    \n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']]\n",
    "    \n",
    "]\n",
    "\n",
    "VV = [\n",
    "    \n",
    "    [['ㅇ','ㅗ'],['ㅇ','ㅗ'],['ㅇ','ㅘ']],\n",
    "    [['ㅈ','ㅜ'],['ㅈ','ㅜ'],['ㅈ','ㅝ']],\n",
    "    [['ㅎ','ㅏ'],['ㅎ','ㅏ'],['ㅎ','ㅐ']]\n",
    "    \n",
    "]\n",
    "\n",
    "XR = [\n",
    "    [['ㅈ','ㅚ','ㅅ','ㅗ','ㅇ'],['ㅁ','ㅣ','ㅇ','ㅏ','ㄴ'] ]\n",
    "]\n",
    "\n",
    "NNG = [\n",
    "    [['ㅈ','ㅏ','ㅇ','ㅛ'],['ㅈ','ㅏ']],\n",
    "    [['ㄱ','ㅏ','ㅁ','ㅅ','ㅏ'],['ㅈ','ㅏ']],\n",
    "]\n",
    "\n",
    "NNP = [\n",
    "    \n",
    "    [[],[]]\n",
    "    \n",
    "]\n",
    "\n",
    "#Not Use\n",
    "# EXC = [\n",
    "    \n",
    "#     ['ㅜ',1],\n",
    "#     ['ㅗ',2],\n",
    "#     ['ㅏ',3]\n",
    "    \n",
    "# ]\n",
    "\n",
    "# EXC_word = [\n",
    "    \n",
    "#     ['ㅅㅔ',2]\n",
    "#     ,['ㅅㅣㅂ',2]\n",
    "    \n",
    "# ]\n",
    "\n",
    "EXC_deal = [\n",
    "    \n",
    "    ['ㅅㅔㅇㅛ', ['ㅏ','ㅣ'],['ㅜ','ㅓ'],['ㅡ','ㅓ']],\n",
    "    ['ㅈㅓㄴ','ㅈㅓㄴ','ㄴㅏㄴ']\n",
    "    \n",
    "]\n",
    "\n",
    "EXC_tags = [\n",
    "    \n",
    "    'EP',\n",
    "    'EF'\n",
    "    \n",
    "]\n",
    "\n",
    "####End of high -> low Dictionary####\n",
    "\n",
    "\n",
    "#### low -> high Dictionary####\n",
    "## 사전의 순서가 중요하다. 순서를 임의로 바꾸지 말 것\n",
    "## EF solo. EF 앞에 형태소가 결합형이 아닌 홀로 분석 될 경우 ex) /EP, /EF\n",
    "\n",
    "EF_ONLY_4S = [\n",
    "    # -고 /EF\n",
    "    [['ㄹ','ㅏ','ㄱ','ㅗ'],['ㄹ','ㅏ','ㄱ','ㅗ','ㅇ','ㅛ']], ##-라고-> 라고요\n",
    "    [['ㄷ','ㅓ','ㄹ','ㅏ','ㄱ','ㅗ'],['ㄷ','ㅓ','ㄹ','ㅏ','ㄱ','ㅗ','ㅇ','ㅛ']],\n",
    "    [['ㄷ','ㅏ','ㄱ','ㅗ'],['ㄷ','ㅏ','ㄱ','ㅗ','ㅇ','ㅛ']],\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ'],['special']],\n",
    "    [['ㅇ','ㅓ','ㄹ','ㅏ'],['ㅇ','ㅡ','ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅇ','ㅓ'],['ㅇ','ㅓ','ㅇ','ㅛ']],\n",
    "    #'-라' /EF\n",
    "    [['ㄷ','ㅓ','ㄹ','ㅏ'],['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄹ','ㅏ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    # -데 /EF\n",
    "    [['ㅇ','ㅡ','ㄴ','ㄷ','ㅔ'],['ㅇ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ'],['ㄴ','ㅡ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ'],['ㄷ','ㅓ','ㄴ','ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    # -걸 /EF\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ'],['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ','ㅇ','ㅛ']],\n",
    "    \n",
    "    [['ㅈ','ㅏ','ㄶ','ㅇ','ㅏ'],['ㅈ','ㅏ','ㄶ','ㅇ','ㅏ','ㅇ','ㅛ']], ## -잖아 -> -잖아요\n",
    "    \n",
    "    #-오 /EF\n",
    "    [['ㅇ','ㅗ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    #-자 /EF\n",
    "    [['ㅈ','ㅏ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "## EF 결합형\n",
    "## EF 앞에 형태소가 결합형인 경우 앞의 형태소도 고려해서 처리해야 한다. ex) /EP, /EF\n",
    "EF_ONLY_4C = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅓ'],['ㅅ','ㅡ','ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    [['ㅇ','ㅓ','ㄸ','ㅐ'],['ㅇ','ㅓ','ㄸ','ㅐ','ㅇ','ㅛ']],\n",
    "    \n",
    "    # -걸 /EF\n",
    "    [['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ'],['ㄴ','ㅡ','ㄴ','ㄱ','ㅓ','ㄹ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "\n",
    "#/VCP+EF\n",
    "VCP_EF_4 = [\n",
    "    \n",
    "    [['ㄱ','ㅓ','ㄹ'],['ㄷ','ㅔ','ㅇ','ㅛ']],\n",
    "    [['ㅇ','ㅑ'],['ㅇ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "\n",
    "#/VA+EF added code_JH\n",
    "VA_EF_4 = [\n",
    "    [['ㅇ','ㅓ','ㄸ','ㅐ'],['ㅇ','ㅓ','ㄸ','ㅐ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "## /VCP, /EF\n",
    "EF_AFTER_VCP_4 = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']],\n",
    "    #-오 /EF\n",
    "    [['ㅇ','ㅗ'],['ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "    \n",
    "]\n",
    "\n",
    "EF_AFTER_XSA_4 = [\n",
    "    \n",
    "    [['ㄷ','ㅏ'],['ㅂ','ㄴ','ㅣ','ㄷ','ㅏ']]\n",
    "    \n",
    "]\n",
    "\n",
    "VV_EF_4 = [\n",
    "    [['ㄱ','ㅓ','ㄹ'],['ㄱ','ㅓ','ㄹ','ㅇ','ㅛ']],\n",
    "    [['ㅎ','ㅐ','ㄹ','ㅏ'],['ㅎ','ㅏ','ㅅ','ㅔ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "##added code_JH\n",
    "XSV_EF_4 = [\n",
    "    [['ㅎ','ㅐ'],['ㅎ','ㅐ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "VX_EF_4 = [\n",
    "    [['ㅎ','ㅐ'],['ㅎ','ㅐ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "NNB_JKO_4 = [\n",
    "    [['ㄱ','ㅓ','ㄹ'],['ㄱ','ㅓ','ㄹ','ㅇ','ㅛ']],\n",
    "]\n",
    "\n",
    "#### End of low -> high Dictionary####\n",
    "\n",
    "#### Common Dictionary ####\n",
    "#Yes or No\n",
    "IC =[\n",
    "    [['ㄴ','ㅔ'],['ㅇ','ㅡ','ㅇ']],\n",
    "    [['ㅇ','ㅏ','ㄴ','ㅣ','ㅇ','ㅛ'],['ㅇ','ㅏ','ㄴ','ㅣ']],\n",
    "    [['ㄴ','ㅔ'],['ㄱ','ㅡ','ㄹ','ㅐ']],\n",
    "]\n",
    "\n",
    "#### End of Common Dictionary ####\n",
    "\n",
    "def unite(input, dict):\n",
    "    for i in dict:\n",
    "        input = re.sub(i[0],i[1],input)\n",
    "    return input\n",
    "    \n",
    "\n",
    "class Jamodealer:\n",
    "    jamo = []\n",
    "    pp = ''\n",
    "    def __init__(self,lis_word):\n",
    "        \n",
    "        #print('the jamo starts!')\n",
    "        self.jamo = []\n",
    "        for i in lis_word:\n",
    "            self.jamo.append(split_syllables(i))\n",
    "        \n",
    "    def make_one(self):\n",
    "        self.pp = ''\n",
    "        for i in self.jamo:\n",
    "             self.pp= self.pp+i\n",
    "                \n",
    "        self.pp = unite(self.pp, con_dict)\n",
    "                \n",
    "        chars = list(set(self.pp))\n",
    "        char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "        ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "        jamo_numbers = [char_to_ix[x] for x in self.pp]\n",
    "        restored_jamo = ''.join([ix_to_char[x] for x in jamo_numbers])\n",
    "        restored_text = join_jamos(restored_jamo)\n",
    "        return restored_text\n",
    "\n",
    "def tojamo(korean_word):\n",
    "    r_lst = []\n",
    "    for w in list(korean_word.strip()):\n",
    "        ## 영어인 경우 구분해서 작성함. \n",
    "        if '가'<=w<='힣':\n",
    "            ## 588개 마다 초성이 바뀜. \n",
    "            ch1 = (ord(w) - ord('가'))//588\n",
    "            ## 중성은 총 28가지 종류\n",
    "            ch2 = ((ord(w) - ord('가')) - (588*ch1)) // 28\n",
    "            ch3 = (ord(w) - ord('가')) - (588*ch1) - 28*ch2\n",
    "            r_lst.append([CHOSUNG_LIST[ch1], JUNGSUNG_LIST[ch2], JONGSUNG_LIST[ch3]])\n",
    "        else:\n",
    "            r_lst.append([w])\n",
    "    return r_lst\n",
    "\n",
    "def toword(arr):\n",
    "    print('wow')\n",
    "    \n",
    "\n",
    "def to1dim(input):\n",
    "    result=[]\n",
    "    for i in input:\n",
    "        for j in i:\n",
    "            result.append(j)\n",
    "    return result\n",
    "\n",
    "def to2dim(input):\n",
    "    result = []\n",
    "    li = []\n",
    "    for i in input:\n",
    "        if i == ' ':\n",
    "            result.append([' '])\n",
    "        else:\n",
    "            li.append(i)\n",
    "        if len(li)==3:\n",
    "            result.append(li)\n",
    "            li = []\n",
    "    return result\n",
    "\n",
    "def makeone(input):\n",
    "    result = ''\n",
    "    li = ''\n",
    "    for i in input:\n",
    "        if i[0]==' ':\n",
    "            result = result+' '\n",
    "        else:\n",
    "            ind = ord('가')\n",
    "            ind +=CHOSUNG_LIST.index(i[0])*588\n",
    "            ind +=JUNGSUNG_LIST.index(i[1])*28\n",
    "            ind +=JONGSUNG_LIST.index(i[2])\n",
    "            result = result+chr(ind)\n",
    "    return result\n",
    "        \n",
    "def li2str(input):\n",
    "    st = \"\"\n",
    "    for i in input:\n",
    "        st = st+i\n",
    "    return st\n",
    "\n",
    "def str2li(input):\n",
    "    li = []\n",
    "    for i in range(len(input)):\n",
    "        li.append(input[i])\n",
    "    return li\n",
    "\n",
    "def makejamodict(input):\n",
    "    result = []\n",
    "    for i in input:\n",
    "        bullet = []\n",
    "        one = []\n",
    "        two = []\n",
    "        gre1 = tojamo(i[0])\n",
    "        for j in gre1:\n",
    "            for k in j:\n",
    "                one.append(k)\n",
    "        bullet.append(one)\n",
    "        gre2 = tojamo(i[1])\n",
    "        for j in gre2:\n",
    "            for k in j:\n",
    "                two.append(k)\n",
    "        bullet.append(two)\n",
    "        result.append(bullet)\n",
    "    return result\n",
    "\n",
    "def makestrdict(input):\n",
    "    result = []\n",
    "    for i in input:\n",
    "        bullet = []\n",
    "        for j in range(len(i)):\n",
    "            gre = li2str(i[j])\n",
    "            bullet.append(gre)\n",
    "        #gre1 = li2str(i[0])\n",
    "        #gre2 = li2str(i[1])\n",
    "        #bullet.append(gre1)\n",
    "        #bullet.append(gre2)\n",
    "        result.append(bullet)\n",
    "    return result\n",
    "\n",
    "#strlis = makestrdict(lis)\n",
    "\n",
    "#strlis = makejamodict(lili)\n",
    "#strlis = makestrdict(strlis)\n",
    "\n",
    "#추가한 사전에 대한 str 사전을 생성, mapping 시키는 부분\n",
    "#EP_dict = makestrdict(EP)\n",
    "EF_dict = makestrdict(EF)\n",
    "NP_dict = makestrdict(NP)\n",
    "JX_dict = makestrdict(JX)\n",
    "VX_dict = makestrdict(VX)\n",
    "VV_dict = makestrdict(VV)\n",
    "XR_dict = makestrdict(XR)\n",
    "NNG_dict = makestrdict(NNG)\n",
    "NNP_dict = makestrdict(NNP)\n",
    "\n",
    "Dict_list=['NNP','NP','JX','VX','VV','XR','NNG']\n",
    "\n",
    "Dict_map = [NNP_dict,NP_dict,JX_dict,VX_dict, VV_dict, XR_dict, NNG_dict]\n",
    "\n",
    "EF_ONLY_dict = makestrdict(EF_ONLY)\n",
    "EP_EF_dict = makestrdict(EP_EF)\n",
    "VCP_EF_dict = makestrdict(VCP_EF)\n",
    "A_EF_dict = makestrdict(A_EF)\n",
    "XSA_EF_dict = makestrdict(XSA_EF)\n",
    "XSV_EF_dict = makestrdict(XSV_EF)\n",
    "\n",
    "#여기까지\n",
    "\n",
    "#str dict의 low->high \n",
    "EF_ONLY_4S_dict = makestrdict(EF_ONLY_4S)\n",
    "EF_ONLY_4C_dict = makestrdict(EF_ONLY_4C)\n",
    "EF_AFTER_VCP_4_dict = makestrdict(EF_AFTER_VCP_4)\n",
    "VCP_EF_4_dict = makestrdict(VCP_EF_4)\n",
    "EF_AFTER_XSA_4_dict = makestrdict(EF_AFTER_XSA_4)\n",
    "VA_EF_4_dict = makestrdict(VA_EF_4)\n",
    "VV_EF_4_dict = makestrdict(VV_EF_4)\n",
    "VX_EF_4_dict = makestrdict(VX_EF_4)\n",
    "XSV_EF_4_dict = makestrdict(XSV_EF_4)\n",
    "NNB_JKO_4_dict = makestrdict(NNB_JKO_4)##add code_JH\n",
    "\n",
    "def to2lists(input):\n",
    "    lis_word = []\n",
    "    lis_tag = []\n",
    "    #data = han.pos(input,ntags=22,flatten=True, join=False)\n",
    "    data = mec.pos(input)\n",
    "    for i in data:\n",
    "        lis_word.append(i[0])\n",
    "        lis_tag.append(i[1])\n",
    "    return lis_word, lis_tag\n",
    "\n",
    "#add in 2021.09.26\n",
    "\n",
    "def indee(lis, input):\n",
    "    \n",
    "    rlis = []\n",
    "    \n",
    "    for i in range(len(lis)):\n",
    "        if lis[i]==input:\n",
    "            rlis.append(i)\n",
    "            \n",
    "    for i in range(len(rlis)):\n",
    "        rlis[i] = rlis[i]-i\n",
    "            \n",
    "    return rlis\n",
    "\n",
    "def ind_lili(lis_space,lis_lis):\n",
    "    \n",
    "    rlis = []\n",
    "    k=0\n",
    "    for i in range(len(lis_lis)):\n",
    "        \n",
    "        if k in lis_space:\n",
    "            rlis.append(i)\n",
    "            \n",
    "        k = k+len(lis_lis[i])\n",
    "        \n",
    "    \n",
    "    return rlis\n",
    "\n",
    "def union(lis, lis_lis):\n",
    "    \n",
    "    k = 0\n",
    "    for i in lis:\n",
    "        lis_lis.insert(i+k,' ')\n",
    "        k = k+1\n",
    "\n",
    "#find_ind_of_trans\n",
    "\n",
    "def indoftr(input, word):\n",
    "    \n",
    "    i=0\n",
    "    lis = []\n",
    "    for j in range(len(input)):\n",
    "        if word in input[j]:\n",
    "            lis.append(j)\n",
    "            \n",
    "    return lis\n",
    "\n",
    "class Changer(object):\n",
    "    #def __init__(self):\n",
    "        #print('the changer starts!')\n",
    "        \n",
    "    def high_low(self, stc):\n",
    "        result = stc\n",
    "        \n",
    "        space_list = indee(stc,' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = ind_lili(space_list, lis_word)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        lis = []\n",
    "        key = -1\n",
    "        for i in H_LIST:\n",
    "            if i in lis_word[-2]:\n",
    "                key = 1\n",
    "        #if key>0:\n",
    "        if key>0 or key<0:     \n",
    "            for i in range(len(lis_tag)):\n",
    "                res = jam.jamo[i]\n",
    "                #for k in range(len(Dict_list)):\n",
    "                dic = []\n",
    "                if 'EF' in lis_tag[i]:\n",
    "                    if 'EF' == lis_tag[i]:\n",
    "                        dic = EF_ONLY_dict\n",
    "                    elif 'EP' in lis_tag[i]:\n",
    "                        dic = EP_EF_dict\n",
    "                    elif 'VCP' in lis_tag[i]:\n",
    "                        dic = VCP_EF_dict\n",
    "                    elif 'XSA' in lis_tag[i]:\n",
    "                        dic = XSA_EF_dict\n",
    "                    else:\n",
    "                        dic = A_EF_dict\n",
    "                        \n",
    "                #else Dict_list[k] in lis_tag[i]:\n",
    "                else:\n",
    "                    for k in range(len(Dict_list)):\n",
    "                        if Dict_list[k] in lis_tag[i]:\n",
    "                            dic = Dict_map[Dict_list.index(Dict_list[k])]\n",
    "                            break\n",
    "                    #res = jam.jamo[i]\n",
    "                        \n",
    "                flag = 0    \n",
    "                for j in range(len(dic)):\n",
    "                    if dic[j][0] in res:\n",
    "                        flag = 1\n",
    "                            \n",
    "                    if self.isExcept(dic[j])==1:\n",
    "                        #ind = self.indicator(i,jam.jamo,lis_tag,EXC_word, EXC_tags)\n",
    "                        for q in range(len(EXC_deal)):\n",
    "                            if dic[j][0]==EXC_deal[q][0]:\n",
    "                                for r in range(1,len(EXC_deal[q])):\n",
    "                                    if jam.jamo[i-1][-1]==EXC_deal[q][r][0]:\n",
    "                                        res = re.sub(dic[j][0],EXC_deal[q][r][1],res)\n",
    "                        #res = re.sub(dic[j][0],dic[j][ind],res)\n",
    "                    elif self.isExcept(dic[j])==2:\n",
    "                        for q in range(len(EXC_deal)):\n",
    "                            if dic[j][0]==EXC_deal[q][0]:\n",
    "                                if i+1 in space_location:\n",
    "                                    res = re.sub(dic[j][0], EXC_deal[q][2], res)\n",
    "                                else:\n",
    "                                    res = re.sub(dic[j][0], EXC_deal[q][1], res)\n",
    "                    else:\n",
    "                        #print('tt')\n",
    "                        res = re.sub(dic[j][0],dic[j][1],res)\n",
    "                            \n",
    "                    if flag==1:\n",
    "                        break\n",
    "                            \n",
    "                        #jam.jamo[i] = res\n",
    "                lis.append(res)\n",
    "            \n",
    "            \n",
    "            #print(jam.jamo[i])\n",
    "        \n",
    "        union(space_location, lis)\n",
    "        jam.jamo = []\n",
    "        for i in range(len(lis)):\n",
    "            jam.jamo.append(lis[i])\n",
    "            #print(lis[i])\n",
    "        \n",
    "        #union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "    \n",
    "    def low_high(self, stc):\n",
    "        result = stc\n",
    "        \n",
    "        space_list = indee(stc, ' ')\n",
    "        \n",
    "        lis_word, lis_tag = to2lists(result)\n",
    "        space_location = ind_lili(space_list, lis_word)\n",
    "        jam = Jamodealer(lis_word)\n",
    "        lis = []\n",
    "        \n",
    "        ind_trans_ef = indoftr(lis_tag, 'EF')\n",
    "        \n",
    "        for ind in ind_trans_ef:#modified_2021.10.31\n",
    "        \n",
    "            key = -1\n",
    "        \n",
    "            for i in H_LIST:\n",
    "                if i not in lis_word[ind]:\n",
    "                    key = 1\n",
    "                else:\n",
    "                    key = -1\n",
    "                if key==-1:\n",
    "                    break\n",
    "            #if key>0:\n",
    "            if key>0:    \n",
    "                res = jam.jamo[ind]\n",
    "                dic = []\n",
    "                if 'EF' in lis_tag[ind]:\n",
    "                \n",
    "                    if 'EF' == lis_tag[ind]:\n",
    "                        if '+' in lis_tag[ind-1]:\n",
    "                            dic = EF_ONLY_4C_dict\n",
    "                        elif lis_tag[ind-1]=='VCP':\n",
    "                            dic = EF_AFTER_VCP_4_dict\n",
    "                        elif lis_tag[ind-1]=='XSA':\n",
    "                            dic = EF_AFTER_XSA_4_dict\n",
    "                        else:\n",
    "                            dic = EF_ONLY_4S_dict\n",
    "                    elif 'EP' in lis_tag[ind-1]:\n",
    "                        dic = EP_EF_dict\n",
    "                    elif 'VCP' in lis_tag[ind-1]:\n",
    "                        dic = VCP_EF_4_dict\n",
    "                    elif 'VA' in lis_tag[ind]:\n",
    "                        dic = VA_EF_4_dict\n",
    "                    elif 'VV' in lis_tag[ind]:\n",
    "                        dic = VV_EF_4_dict\n",
    "                    elif 'VX' in lis_tag[ind]:\n",
    "                        dic = VX_EF_4_dict\n",
    "                    elif 'XSV' in lis_tag[ind]:\n",
    "                        dic = XSV_EF_4_dict\n",
    "                    else:\n",
    "                        dic = A_EF_dict\n",
    "                #JKO      \n",
    "                elif 'JKO' in lis_tag[ind]:\n",
    "                    dic = NNB_JKO_4_dict\n",
    "                \n",
    "                flag = 0\n",
    "                for i in range(len(dic)):\n",
    "                    if dic[i][0] in res:\n",
    "                        flag = 1\n",
    "                        \n",
    "                    if len(dic[i])>2:\n",
    "                    \n",
    "                        #if lis_tag[-3] =='VCP':\n",
    "                        #    lis_tag[-3] = ''\n",
    "                        #    res = re.sub(dic[i][0],dic[i][1],res)\n",
    "                        #else: \n",
    "                        #    res = re.sub(dic[i][0],dic[i][1],res)\n",
    "                        res = re.sub(dic[i][0],dic[i][1],res)\n",
    "                    else:\n",
    "                        res = re.sub(dic[i][0],dic[i][1],res)\n",
    "                        \n",
    "                    if flag==1:\n",
    "                        break\n",
    "                    \n",
    "                jam.jamo[ind] = res\n",
    "        \n",
    "        \n",
    "        \n",
    "        union(space_location, jam.jamo)\n",
    "        \n",
    "        return jam.make_one()\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    def isExcept(self, input):\n",
    "        if input[1]=='special':\n",
    "            return 1\n",
    "        elif input[1]=='special-':\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def indicator(self, ind, lis, tag, ex_word, exc_tags):\n",
    "        re = 1\n",
    "        for j in range(len(ex_word)):\n",
    "            if exc_tags[j] in tag[ind+1]:\n",
    "                for i in range(len(ex_word)):\n",
    "                    if ex_word[i][0] in lis[ind+1]:\n",
    "                       \n",
    "                        re = ex_word[i][1]\n",
    "                        break\n",
    "                        \n",
    "                        print(lis[ind-1])\n",
    "        return re\n",
    "        \n",
    "        \n",
    "    def processText(self,stc):\n",
    "        result = stc\n",
    "        \n",
    "        flag = 0\n",
    "        if result[-1]=='\\n':\n",
    "            result = result.replace('\\n','')\n",
    "        if result[-1] =='?' or result[-1] =='.' or result[-1] =='!' or result[-1] =='\\\"':\n",
    "            result = result\n",
    "        else:\n",
    "            result = result+'.'\n",
    "            flag = 1\n",
    "        \n",
    "        res = self.high_low(result)\n",
    "        \n",
    "        if flag ==1:\n",
    "            res = res[:-1]\n",
    "        \n",
    "        #spacing = Spacing()\n",
    "        #res = spacing(res)\n",
    "        return res\n",
    "    \n",
    "    def processText_0(self,stc):\n",
    "        result = stc\n",
    "        \n",
    "        flag = 0\n",
    "        if result[-1]=='\\n':\n",
    "            result = result.replace('\\n','')\n",
    "        if result[-1] =='?' or result[-1] =='.' or result[-1] =='!' or result[-1] =='\\\"':\n",
    "            result = result\n",
    "        else:\n",
    "            result = result+'.'\n",
    "            flag = 1\n",
    "        \n",
    "        res = self.low_high(result)\n",
    "        \n",
    "        if flag ==1:\n",
    "            res = res[:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19b63280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전주로 가자\n"
     ]
    }
   ],
   "source": [
    "#txt = '전 그것이 맞다고 생각합니다.'\n",
    "tx = '전 주로 가자'\n",
    "ch = Changer()\n",
    "#tt = ch.processText(txt)\n",
    "ttt = ch.processText(tx)\n",
    "#print(tt)\n",
    "print(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523a960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08fb79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95681e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2837e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./aihub.low.kr.shuf', 'w',encoding = 'utf-8')\n",
    "f0 = open('./aihub.kr.shuf', 'r', encoding = 'utf-8')\n",
    "\n",
    "flag = 0\n",
    "\n",
    "while True:\n",
    "    flag = 0\n",
    "    line = f0.readline()\n",
    "    if not line: break\n",
    "    if line[-1]=='\\n':\n",
    "        line = line.replace('\\n','')\n",
    "    if line[-1] =='?' or line[-1] =='.' or line[-1] =='!' or line[-1] =='\\\"':\n",
    "        line = line\n",
    "    else:\n",
    "        line = line+'.'\n",
    "        flag = 1\n",
    "    tt = ch.processText(line)\n",
    "    if flag ==1:\n",
    "        tt[-1] = ''\n",
    "    f.write(tt)\n",
    "    f.write('\\n')\n",
    "f0.close()\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
